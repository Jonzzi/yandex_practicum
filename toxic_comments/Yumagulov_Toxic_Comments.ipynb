{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» c BERT (и без BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\e.yumagulov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\e.yumagulov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\e.yumagulov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import roc_curve \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from nltk.corpus import stopwords as nltk_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Константы\n",
    "RS = 12345 # random state\n",
    "TS = .25 # test size\n",
    "FR_DOWNSAMPLE = 0.1 # fraction downsample\n",
    "FR_DOWNSAMPLE_CLASS = 0.1 # fraction downsample for class\n",
    "MAX_WORDS = 100 # maximum words in sentences\n",
    "CRIT_F1 = .75\n",
    "MXL = 512 # max lenght BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  toxic\n",
       "6        COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "12  Hey... what is it..\\n@ | talk .\\nWhat is it......      1\n",
       "16  Bye! \\n\\nDon't look, come or think of comming ...      1\n",
       "42  You are gay or antisemmitian? \\n\\nArchangel WH...      1\n",
       "43           FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.101679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.302226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic\n",
       "count  159571.000000\n",
       "mean        0.101679\n",
       "std         0.302226\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_comm = pd.read_csv(r'c:\\Users\\e.yumagulov\\datasets\\toxic_comments.csv')\n",
    "df_comm.info()\n",
    "display(df_comm.head())\n",
    "display(df_comm.query('toxic==1').head()) # А что насчет токсичных комментов?\n",
    "display(df_comm.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер комментариев (в символах): 6 - 5000\n",
      "Количество токсичных комментариев 16225 из общего числа 159571 (10.17%)\n"
     ]
    }
   ],
   "source": [
    "df_comm['len'] = df_comm['text'].apply(len)\n",
    "print('Размер комментариев (в символах):', df_comm['len'].min(),'-',df_comm['len'].max())\n",
    "df_comm = df_comm.drop('len', axis=1)\n",
    "cnt = df_comm[df_comm['toxic']==1]['toxic'].count()\n",
    "all = df_comm.shape[0]\n",
    "print(f'Количество токсичных комментариев {cnt} из общего числа {all} ({np.round(100 * cnt / all, 2)}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Надо сбалансировать классы - т.к. мы предсказываем токсичность, то уменьшим количество нетоксичных комментов в выборке\n",
    "\n",
    "def downsample(df_in, ftr, trg, fraction):\n",
    "    features_zeros = df_in[df_in[trg] == 0][ftr]\n",
    "    features_ones = df_in[df_in[trg] == 1][ftr]\n",
    "    target_zeros = df_in[df_in[trg] == 0][trg]\n",
    "    target_ones = df_in[df_in[trg] == 1][trg]\n",
    "\n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=RS)] + [features_ones]) \n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=RS)] + [target_ones]) \n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=RS)\n",
    "    \n",
    "    df_out = pd.DataFrame()\n",
    "    df_out[ftr] = features_downsampled\n",
    "    df_out[trg] = target_downsampled\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер выборки ДО: (159571, 2)\n",
      "Размер выборки ПОСЛЕ: (30560, 2)\n"
     ]
    }
   ],
   "source": [
    "# Удаляем нетоксичные комментарии\n",
    "print('Размер выборки ДО:', df_comm.shape)\n",
    "\n",
    "df_comm = downsample(df_in=df_comm, ftr='text', trg='toxic', fraction=FR_DOWNSAMPLE_CLASS)\n",
    "\n",
    "print('Размер выборки ПОСЛЕ:',df_comm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мы удалили 10% нетоксичных комментариев. Проверяем что получилось:\n",
      "Количество токсичных комментариев 16225 из общего числа 30560 (53.0%)\n",
      "Выборка сбалансирована!\n"
     ]
    }
   ],
   "source": [
    "print(f'Мы удалили {round(FR_DOWNSAMPLE_CLASS*100)}% нетоксичных комментариев. Проверяем что получилось:')\n",
    "cnt = df_comm[df_comm['toxic']==1]['toxic'].count()\n",
    "all = df_comm.shape[0]\n",
    "prc = np.round(100 * cnt / all, 0)\n",
    "print(f'Количество токсичных комментариев {cnt} из общего числа {all} ({prc}%)')\n",
    "ppp = int(np.round(prc / 10, 0))\n",
    "if ppp == 5:\n",
    "    print('Выборка сбалансирована!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для исследования берем 10% от сбалансированной выборки.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3056 entries, 0 to 3055\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    3056 non-null   object\n",
      " 1   toxic   3056 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 47.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Сначала потренируемся на малом объеме данных\n",
    "print(f'Для исследования берем {round(FR_DOWNSAMPLE*100)}% от сбалансированной выборки.')\n",
    "df_comm = df_comm.sample(frac=FR_DOWNSAMPLE, random_state=RS).reset_index(drop=True)\n",
    "df_comm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверим как изменился % токсичных комментарив после уменьшения выборки:\n",
      "Количество токсичных комментариев 1624 из общего числа 3056 (53.14%)\n",
      "Выборка сбалансирована!\n"
     ]
    }
   ],
   "source": [
    "print('Проверим как изменился % токсичных комментарив после уменьшения выборки:')\n",
    "cnt = df_comm[df_comm['toxic']==1]['toxic'].count()\n",
    "all = df_comm.shape[0]\n",
    "print(f'Количество токсичных комментариев {cnt} из общего числа {all} ({np.round(100 * cnt / all, 2)}%)')\n",
    "ppp = int(np.round(prc / 10, 0))\n",
    "if ppp == 5:\n",
    "    print('Выборка сбалансирована!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вариант с BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "#tokenizer = transformers.BertTokenizer(vocab_file='/datasets/ds_bert/vocab.txt')\n",
    "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "tokenized = df_comm['text'].apply(lambda x: tokenizer.encode(x, truncation=True, max_length=MXL, add_special_tokens=True))\n",
    "\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values]) \n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "#config = transformers.BertConfig.from_json_file('/datasets/ds_bert/bert_config.json')\n",
    "#model = transformers.BertModel.from_pretrained('/datasets/ds_bert/rubert_model.bin', config=config)\n",
    "model = transformers.DistilBertModel.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка доступности CUDA: False\n",
      "Выбрано устройство: cpu\n"
     ]
    }
   ],
   "source": [
    "print('Проверка доступности CUDA:', torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print('Выбрано устройство:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fcb5c30eefd49d69b8e981f0b66b375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "#for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "#    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "#    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "\n",
    "\n",
    "\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "#    embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Размер выборки features: 3000\n",
      "Размер выборки target: 3056\n",
      "Что-то пошло не так - куда-то подевалась часть признаков. Отбрасываем лишние таргеты.\n",
      "Размер выборки target (cut): 3000\n",
      "Разделяем выборку на обучающую и тестовую:\n",
      "-- размер обучающей выборки: 2250 признаков и 2250 таргетов\n",
      "-- размер тестовой выборки: 750 признаков и 750 таргетов\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "bert_features = np.concatenate(embeddings)\n",
    "l1 = len(bert_features)\n",
    "print('Размер выборки features:', l1)\n",
    "bert_target = df_comm['toxic']\n",
    "l2 = len(bert_target)\n",
    "print('Размер выборки target:', l2)\n",
    "\n",
    "if l1 < l2:\n",
    "    print('Что-то пошло не так - куда-то подевалась часть признаков. Отбрасываем лишние таргеты.')\n",
    "    bert_target = bert_target[:l1]\n",
    "    print('Размер выборки target (cut):',len(bert_target))\n",
    "elif l1 > l2:\n",
    "    print('Что-то пошло не так - куда-то подевалась часть таргетов. Отбрасываем лишние признаки.')\n",
    "    bert_features = bert_features[:l2]\n",
    "    print('Размер выборки features target (cut):',len(bert_features))\n",
    "\n",
    "print('Разделяем выборку на обучающую и тестовую:')\n",
    "#bert_features_train, bert_features_test, bert_target_train, bert_target_test = train_test_split(bert_features, bert_target, stratify=bert_target, test_size=0.25, random_state=RS)\n",
    "bert_features_train, bert_features_test, bert_target_train, bert_target_test = train_test_split(bert_features, bert_target, stratify=bert_target, test_size=0.25, random_state=RS)\n",
    "print('-- размер обучающей выборки:', bert_features_train.shape[0], 'признаков и', len(bert_target_train), 'таргетов')\n",
    "print('-- размер тестовой выборки:', bert_features_test.shape[0], 'признаков и', len(bert_target_test), 'таргетов')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вариант без BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверяем работу Mystem (с POS):\n",
      "Исходная фраза: The striped bats are hanging on their feet for best\n",
      "Лемматизированная Mystem: The striped bats are hanging on their feet for best\n",
      "\n",
      "Проверяем работу очистки текста:\n",
      "Исходная фраза: @Joe1977 Don't be silly!!! Не тупи, Buy semi-conductor...\n",
      "Очищенная фраза: Joe Don't be silly Buy semi-conductor\n"
     ]
    }
   ],
   "source": [
    "m = Mystem()\n",
    "\n",
    "def lemmatize_m(text):\n",
    "    lemm_list = m.lemmatize(text)\n",
    "    lemm_text = \"\".join(lemm_list)\n",
    "    return lemm_text\n",
    "\n",
    "ttt = \"The striped bats are hanging on their feet for best\"\n",
    "print('Проверяем работу Mystem (с POS):')\n",
    "print('Исходная фраза:', ttt)\n",
    "print('Лемматизированная Mystem:', lemmatize_m(ttt))\n",
    "\n",
    "def clear_text_eng(text):\n",
    "    clear_text = re.sub(r'[^a-zA-Z\\'\\- ]', ' ', text) \n",
    "    clear_text = \" \".join(clear_text.split())\n",
    "    return clear_text\n",
    "\n",
    "ttt = \"@Joe1977 Don't be silly!!! Не тупи, Buy semi-conductor...\"\n",
    "print('Проверяем работу очистки текста:')\n",
    "print('Исходная фраза:', ttt)\n",
    "print('Очищенная фраза:', clear_text_eng(ttt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:\n",
    "Mystem не подходит для лемматизации английских текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверяем работу nltk (с POS):\n",
      "Исходная фраза: The striped bats are hanging on their feet for best\n",
      "Лемматизированная nltk (с POS): The strip bat be hang on their foot for best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\e.yumagulov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_eng_nltk(sentence):\n",
    "    word_list = nltk.word_tokenize(sentence)\n",
    "# ограничиваем максимум анализируемых слов в комментарии      \n",
    "    l = MAX_WORDS\n",
    "    if len(word_list)<MAX_WORDS:\n",
    "        l = len(word_list)\n",
    "    word_list = word_list[:l] \n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in word_list])\n",
    "#    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    return lemmatized_output\n",
    "\n",
    "ttt = \"The striped bats are hanging on their feet for best\"\n",
    "print('Проверяем работу nltk (с POS):')\n",
    "print('Исходная фраза:', ttt)\n",
    "print('Лемматизированная nltk (с POS):', lemmatize_eng_nltk(ttt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Очищаем комментарии...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "      <th>nltk_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liar \\n\\nThis guy is such a thief and a liar! ...</td>\n",
       "      <td>1</td>\n",
       "      <td>liar This guy is such a thief and a liar He sh...</td>\n",
       "      <td>liar This guy be such a thief and a liar He sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"\\n\\nOf course, of course, Pharos, I am famili...</td>\n",
       "      <td>0</td>\n",
       "      <td>Of course of course Pharos I am familiar with ...</td>\n",
       "      <td>Of course of course Pharos I be familiar with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My Thoughts \\n\\nYou're a jackass.\\n\\nDoes this...</td>\n",
       "      <td>1</td>\n",
       "      <td>My Thoughts You're a jackass Does this look fa...</td>\n",
       "      <td>My Thoughts You re a jackass Does this look fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>. I should become a detective for figuring all...</td>\n",
       "      <td>1</td>\n",
       "      <td>I should become a detective for figuring all t...</td>\n",
       "      <td>I should become a detective for figure all tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GIMME GIMME \\n\\nI wanted all of you BASTARDS t...</td>\n",
       "      <td>1</td>\n",
       "      <td>GIMME GIMME I wanted all of you BASTARDS to kn...</td>\n",
       "      <td>GIM ME GIM ME I want all of you BASTARDS to kn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  liar \\n\\nThis guy is such a thief and a liar! ...      1   \n",
       "1  \"\\n\\nOf course, of course, Pharos, I am famili...      0   \n",
       "2  My Thoughts \\n\\nYou're a jackass.\\n\\nDoes this...      1   \n",
       "3  . I should become a detective for figuring all...      1   \n",
       "4  GIMME GIMME \\n\\nI wanted all of you BASTARDS t...      1   \n",
       "\n",
       "                                          clear_text  \\\n",
       "0  liar This guy is such a thief and a liar He sh...   \n",
       "1  Of course of course Pharos I am familiar with ...   \n",
       "2  My Thoughts You're a jackass Does this look fa...   \n",
       "3  I should become a detective for figuring all t...   \n",
       "4  GIMME GIMME I wanted all of you BASTARDS to kn...   \n",
       "\n",
       "                                           nltk_text  \n",
       "0  liar This guy be such a thief and a liar He sh...  \n",
       "1  Of course of course Pharos I be familiar with ...  \n",
       "2  My Thoughts You re a jackass Does this look fa...  \n",
       "3  I should become a detective for figure all tha...  \n",
       "4  GIM ME GIM ME I want all of you BASTARDS to kn...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лемматизируем комментарии с nltk...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "      <th>nltk_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liar \\n\\nThis guy is such a thief and a liar! ...</td>\n",
       "      <td>1</td>\n",
       "      <td>liar This guy is such a thief and a liar He sh...</td>\n",
       "      <td>liar This guy be such a thief and a liar He sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"\\n\\nOf course, of course, Pharos, I am famili...</td>\n",
       "      <td>0</td>\n",
       "      <td>Of course of course Pharos I am familiar with ...</td>\n",
       "      <td>Of course of course Pharos I be familiar with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My Thoughts \\n\\nYou're a jackass.\\n\\nDoes this...</td>\n",
       "      <td>1</td>\n",
       "      <td>My Thoughts You're a jackass Does this look fa...</td>\n",
       "      <td>My Thoughts You 're a jackass Does this look f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>. I should become a detective for figuring all...</td>\n",
       "      <td>1</td>\n",
       "      <td>I should become a detective for figuring all t...</td>\n",
       "      <td>I should become a detective for figure all tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GIMME GIMME \\n\\nI wanted all of you BASTARDS t...</td>\n",
       "      <td>1</td>\n",
       "      <td>GIMME GIMME I wanted all of you BASTARDS to kn...</td>\n",
       "      <td>GIM ME GIM ME I want all of you BASTARDS to kn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  liar \\n\\nThis guy is such a thief and a liar! ...      1   \n",
       "1  \"\\n\\nOf course, of course, Pharos, I am famili...      0   \n",
       "2  My Thoughts \\n\\nYou're a jackass.\\n\\nDoes this...      1   \n",
       "3  . I should become a detective for figuring all...      1   \n",
       "4  GIMME GIMME \\n\\nI wanted all of you BASTARDS t...      1   \n",
       "\n",
       "                                          clear_text  \\\n",
       "0  liar This guy is such a thief and a liar He sh...   \n",
       "1  Of course of course Pharos I am familiar with ...   \n",
       "2  My Thoughts You're a jackass Does this look fa...   \n",
       "3  I should become a detective for figuring all t...   \n",
       "4  GIMME GIMME I wanted all of you BASTARDS to kn...   \n",
       "\n",
       "                                           nltk_text  \n",
       "0  liar This guy be such a thief and a liar He sh...  \n",
       "1  Of course of course Pharos I be familiar with ...  \n",
       "2  My Thoughts You 're a jackass Does this look f...  \n",
       "3  I should become a detective for figure all tha...  \n",
       "4  GIM ME GIM ME I want all of you BASTARDS to kn...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "print('Очищаем комментарии...')\n",
    "df_comm['clear_text'] = df_comm['text'].apply(clear_text_eng)\n",
    "display(df_comm.head())\n",
    "print('Лемматизируем комментарии с nltk...')\n",
    "df_comm['nltk_text'] = df_comm['clear_text'].apply(lemmatize_eng_nltk)\n",
    "display(df_comm.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Проверяем работу spacy:\n",
      "Исходная фраза: The striped bats are hanging on their feet for best\n",
      "Лемматизированная spacy: the stripe bat be hang on their foot for good\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemmatize_eng_spacy(sentence):\n",
    "    doc = nlp(sentence)\n",
    "# ограничиваем максимум анализируемых слов в комментарии    \n",
    "    l = MAX_WORDS\n",
    "    if len(doc)<MAX_WORDS:\n",
    "        l = len(doc)\n",
    "    doc = doc[0:l]\n",
    "    txt = \" \".join([token.lemma_ for token in doc])\n",
    "    return txt\n",
    "\n",
    "print('Проверяем работу spacy:')\n",
    "print('Исходная фраза:', ttt)\n",
    "print('Лемматизированная spacy:', lemmatize_eng_spacy(ttt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Лемматизируем комментарии со spacy...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "      <th>nltk_text</th>\n",
       "      <th>spacy_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liar \\n\\nThis guy is such a thief and a liar! ...</td>\n",
       "      <td>1</td>\n",
       "      <td>liar This guy is such a thief and a liar He sh...</td>\n",
       "      <td>liar This guy be such a thief and a liar He sh...</td>\n",
       "      <td>liar this guy be such a thief and a liar he sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"\\n\\nOf course, of course, Pharos, I am famili...</td>\n",
       "      <td>0</td>\n",
       "      <td>Of course of course Pharos I am familiar with ...</td>\n",
       "      <td>Of course of course Pharos I be familiar with ...</td>\n",
       "      <td>of course of course Pharos I be familiar with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My Thoughts \\n\\nYou're a jackass.\\n\\nDoes this...</td>\n",
       "      <td>1</td>\n",
       "      <td>My Thoughts You're a jackass Does this look fa...</td>\n",
       "      <td>My Thoughts You 're a jackass Does this look f...</td>\n",
       "      <td>my Thoughts you be a jackass do this look fami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>. I should become a detective for figuring all...</td>\n",
       "      <td>1</td>\n",
       "      <td>I should become a detective for figuring all t...</td>\n",
       "      <td>I should become a detective for figure all tha...</td>\n",
       "      <td>I should become a detective for figure all tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GIMME GIMME \\n\\nI wanted all of you BASTARDS t...</td>\n",
       "      <td>1</td>\n",
       "      <td>GIMME GIMME I wanted all of you BASTARDS to kn...</td>\n",
       "      <td>GIM ME GIM ME I want all of you BASTARDS to kn...</td>\n",
       "      <td>GIMME GIMME I want all of you BASTARDS to know...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  liar \\n\\nThis guy is such a thief and a liar! ...      1   \n",
       "1  \"\\n\\nOf course, of course, Pharos, I am famili...      0   \n",
       "2  My Thoughts \\n\\nYou're a jackass.\\n\\nDoes this...      1   \n",
       "3  . I should become a detective for figuring all...      1   \n",
       "4  GIMME GIMME \\n\\nI wanted all of you BASTARDS t...      1   \n",
       "\n",
       "                                          clear_text  \\\n",
       "0  liar This guy is such a thief and a liar He sh...   \n",
       "1  Of course of course Pharos I am familiar with ...   \n",
       "2  My Thoughts You're a jackass Does this look fa...   \n",
       "3  I should become a detective for figuring all t...   \n",
       "4  GIMME GIMME I wanted all of you BASTARDS to kn...   \n",
       "\n",
       "                                           nltk_text  \\\n",
       "0  liar This guy be such a thief and a liar He sh...   \n",
       "1  Of course of course Pharos I be familiar with ...   \n",
       "2  My Thoughts You 're a jackass Does this look f...   \n",
       "3  I should become a detective for figure all tha...   \n",
       "4  GIM ME GIM ME I want all of you BASTARDS to kn...   \n",
       "\n",
       "                                          spacy_text  \n",
       "0  liar this guy be such a thief and a liar he sh...  \n",
       "1  of course of course Pharos I be familiar with ...  \n",
       "2  my Thoughts you be a jackass do this look fami...  \n",
       "3  I should become a detective for figure all tha...  \n",
       "4  GIMME GIMME I want all of you BASTARDS to know...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "print('Лемматизируем комментарии со spacy...')\n",
    "df_comm['spacy_text'] = df_comm['clear_text'].apply(lemmatize_eng_spacy)\n",
    "display(df_comm.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cначала детально пройдемся по spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сначала детально пройдемся по spacy\n",
    "#spacy_text = df_comm['spacy_text'].values.astype('U')\n",
    "spacy_text = df_comm['spacy_text']\n",
    "target = df_comm['toxic']\n",
    ", \n",
    "#spacy_text_train, spacy_text_test, target_spacy_train, target_spacy_test = train_test_split(spacy_text, target, test_size=TS, random_state=RS)\n",
    "spacy_text_train, spacy_text_test, target_spacy_train, target_spacy_test = train_test_split(spacy_text,\n",
    "                                                                                            target,\n",
    "                                                                                            stratify=target,\n",
    "                                                                                            test_size=TS,\n",
    "                                                                                            random_state=RS\n",
    "                                                                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "features_spacy_train = count_tf_idf.fit_transform(spacy_text_train) \n",
    "features_spacy_test = count_tf_idf.transform(spacy_text_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "accuracy_score: 0.8507853403141361\n",
      "f1_score: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "#solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "#class_weight='balanced'\n",
    "model_spacy = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=100, class_weight=None, random_state=RS, C=10) #т.к. классы несбалансированы\n",
    "model_spacy.fit(features_spacy_train, target_spacy_train)\n",
    "\n",
    "pred_spacy = model_spacy.predict(features_spacy_test)\n",
    "print('accuracy_score:', accuracy_score(target_spacy_test, pred_spacy))\n",
    "print('f1_score:', f1_score(target_spacy_test, pred_spacy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примечание:\n",
    "А до балансировки классов (с class_weight='balanced') было:\n",
    "* accuracy_score: 0.93\n",
    "* f1_score: 0.46153846153846156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вероятности отрицательного и положительного (токсичного) результатов:\n",
      "[[0.19031894 0.80968106]\n",
      " [0.4405455  0.5594545 ]\n",
      " [0.88011827 0.11988173]\n",
      " [0.8774597  0.1225403 ]\n",
      " [0.47334573 0.52665427]\n",
      " [0.03072619 0.96927381]\n",
      " [0.52167094 0.47832906]\n",
      " [0.00856679 0.99143321]\n",
      " [0.14862003 0.85137997]\n",
      " [0.60846277 0.39153723]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = model_spacy.predict_proba(features_spacy_test) \n",
    "print('Вероятности отрицательного и положительного (токсичного) результатов:')\n",
    "print(probabilities[:10])  \n",
    "\n",
    "probabilities_one = probabilities[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.00 | Точность = 0.531, Полнота = 1.000\n",
      "Порог = 0.02 | Точность = 0.542, Полнота = 1.000\n",
      "Порог = 0.04 | Точность = 0.561, Полнота = 0.998\n",
      "Порог = 0.06 | Точность = 0.575, Полнота = 0.995\n",
      "Порог = 0.08 | Точность = 0.594, Полнота = 0.993\n",
      "Порог = 0.10 | Точность = 0.614, Полнота = 0.988\n",
      "Порог = 0.12 | Точность = 0.633, Полнота = 0.978\n",
      "Порог = 0.14 | Точность = 0.657, Полнота = 0.970\n",
      "Порог = 0.16 | Точность = 0.671, Полнота = 0.966\n",
      "Порог = 0.18 | Точность = 0.684, Полнота = 0.961\n",
      "Порог = 0.20 | Точность = 0.698, Полнота = 0.956\n",
      "Порог = 0.22 | Точность = 0.708, Полнота = 0.946\n",
      "Порог = 0.24 | Точность = 0.727, Полнота = 0.943\n",
      "Порог = 0.26 | Точность = 0.739, Полнота = 0.933\n",
      "Порог = 0.28 | Точность = 0.759, Полнота = 0.929\n",
      "Порог = 0.30 | Точность = 0.778, Полнота = 0.921\n",
      "Порог = 0.32 | Точность = 0.785, Полнота = 0.916\n",
      "Порог = 0.34 | Точность = 0.800, Полнота = 0.909\n",
      "Порог = 0.36 | Точность = 0.809, Полнота = 0.906\n",
      "Порог = 0.38 | Точность = 0.818, Полнота = 0.897\n",
      "Порог = 0.40 | Точность = 0.822, Полнота = 0.884\n",
      "Порог = 0.42 | Точность = 0.832, Полнота = 0.879\n",
      "Порог = 0.44 | Точность = 0.833, Полнота = 0.874\n",
      "Порог = 0.46 | Точность = 0.845, Полнота = 0.862\n",
      "Порог = 0.48 | Точность = 0.856, Полнота = 0.850\n",
      "Порог = 0.50 | Точность = 0.872, Полнота = 0.842\n",
      "Порог = 0.52 | Точность = 0.877, Полнота = 0.828\n",
      "Порог = 0.54 | Точность = 0.882, Полнота = 0.808\n",
      "Порог = 0.56 | Точность = 0.888, Полнота = 0.783\n",
      "Порог = 0.58 | Точность = 0.898, Полнота = 0.778\n",
      "Порог = 0.60 | Точность = 0.902, Полнота = 0.771\n",
      "Порог = 0.62 | Точность = 0.916, Полнота = 0.754\n",
      "Порог = 0.64 | Точность = 0.918, Полнота = 0.741\n",
      "Порог = 0.66 | Точность = 0.927, Полнота = 0.722\n",
      "Порог = 0.68 | Точность = 0.929, Полнота = 0.704\n",
      "Порог = 0.70 | Точность = 0.937, Полнота = 0.692\n",
      "Порог = 0.72 | Точность = 0.942, Полнота = 0.677\n",
      "Порог = 0.74 | Точность = 0.944, Полнота = 0.665\n",
      "Порог = 0.76 | Точность = 0.949, Полнота = 0.645\n",
      "Порог = 0.78 | Точность = 0.955, Полнота = 0.626\n",
      "Порог = 0.80 | Точность = 0.957, Полнота = 0.603\n",
      "Порог = 0.82 | Точность = 0.968, Полнота = 0.591\n",
      "Порог = 0.84 | Точность = 0.975, Полнота = 0.571\n",
      "Порог = 0.86 | Точность = 0.973, Полнота = 0.534\n",
      "Порог = 0.88 | Точность = 0.972, Полнота = 0.510\n",
      "Порог = 0.90 | Точность = 0.974, Полнота = 0.461\n",
      "Порог = 0.92 | Точность = 0.977, Полнота = 0.416\n",
      "Порог = 0.94 | Точность = 0.974, Полнота = 0.372\n",
      "Порог = 0.96 | Точность = 0.985, Полнота = 0.320\n",
      "Порог = 0.98 | Точность = 0.990, Полнота = 0.244\n"
     ]
    }
   ],
   "source": [
    "for threshold in np.arange(0, 1, 0.02):\n",
    "    predicted_test = probabilities_one > threshold \n",
    "    precision = precision_score(target_spacy_test, predicted_test)\n",
    "    recall = recall_score(target_spacy_test, predicted_test)\n",
    "\n",
    "    print(\"Порог = {:.2f} | Точность = {:.3f}, Полнота = {:.3f}\".format(\n",
    "        threshold, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(target_spacy_test, probabilities_one)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.step(recall, precision, where='post')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Кривая Precision-Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(target_spacy_test, probabilities_one) \n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-кривая')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка в численном виде: 0.9189256130115311\n"
     ]
    }
   ],
   "source": [
    "auc_roc = roc_auc_score(target_spacy_test, probabilities_one) \n",
    "print('Оценка в численном виде:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примечания:\n",
    "1. А до балансировки классов (с class_weight='balanced') было: 0.8056120965396918\n",
    "2. А без стратификации было чуть больше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Воочию посмотрим как совпадают с истиной результаты предсказаний:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>toxic</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>harass and threaten people</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>yeah do you spit or swallow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>that be ok Latvian be not the most usual langu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>many of these be principale</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>it be my religious view that she will burn in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>ps also guy I know we be lazy as fuck but come...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>nope I be afraid it be up to you today Libsey ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>Bishonen so be you his lackey or just a sycoph...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>a beating hello Shovon I see you 've take quit...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>the problem be not your use of mixed spelling ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    txt  toxic  pred\n",
       "2521                         harass and threaten people      1     1\n",
       "2750                        yeah do you spit or swallow      1     1\n",
       "2225  that be ok Latvian be not the most usual langu...      0     0\n",
       "1699                        many of these be principale      0     0\n",
       "2624  it be my religious view that she will burn in ...      1     1\n",
       "1874  ps also guy I know we be lazy as fuck but come...      1     1\n",
       "1226  nope I be afraid it be up to you today Libsey ...      1     0\n",
       "2355  Bishonen so be you his lackey or just a sycoph...      1     1\n",
       "93    a beating hello Shovon I see you 've take quit...      1     1\n",
       "398   the problem be not your use of mixed spelling ...      1     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "А теперь только токсичные:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>toxic</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>harass and threaten people</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>yeah do you spit or swallow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>it be my religious view that she will burn in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>ps also guy I know we be lazy as fuck but come...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>nope I be afraid it be up to you today Libsey ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    txt  toxic  pred\n",
       "2521                         harass and threaten people      1     1\n",
       "2750                        yeah do you spit or swallow      1     1\n",
       "2624  it be my religious view that she will burn in ...      1     1\n",
       "1874  ps also guy I know we be lazy as fuck but come...      1     1\n",
       "1226  nope I be afraid it be up to you today Libsey ...      1     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Воочию посмотрим как совпадают с истиной результаты предсказаний:')\n",
    "tst = pd.DataFrame()\n",
    "tst['txt'] = spacy_text_test\n",
    "tst['toxic'] = np.array(target_spacy_test)\n",
    "tst['pred'] = pred_spacy\n",
    "display(tst.head(10))\n",
    "print('А теперь только токсичные:')\n",
    "display(tst.query('toxic==1').head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы:\n",
    "1. Осталась довольно большая доля ложно-отрицательных (FN) предсказаний. Часть токсичных комментариев не будет распознана."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Несовпадений 114 из 764\n",
      "Из них ложно-отрицательных (FN): 64 (8.38%)\n",
      "А ложно-положительных (FP): 50 (6.54%)\n"
     ]
    }
   ],
   "source": [
    "sh = tst.shape[0]\n",
    "print('Несовпадений', tst.query('toxic!=pred')['txt'].count(), 'из', sh)\n",
    "fn = tst.query('toxic==1 and pred==0')['txt'].count()\n",
    "print(f'Из них ложно-отрицательных (FN): {fn} ({np.round(100*fn/sh, 2)}%)')\n",
    "fp = tst.query('toxic==0 and pred==1')['txt'].count()      \n",
    "print(f'А ложно-положительных (FP): {fp} ({np.round(100*fp/sh, 2)}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь сделаем обзор по всем остальным вариантам представления текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для модели LogisticRegression определенные GridSearchCV: {'C': 1, 'class_weight': 'balanced', 'max_iter': 50, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {'max_iter': [50, 100, 200],\n",
    "          'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
    "          'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "          'class_weight': [None, 'balanced'], \n",
    "          'C': [1, 10]}\n",
    "\n",
    "lr = LogisticRegression(multi_class='auto', random_state=RS)\n",
    "lr_model = GridSearchCV(lr, params, scoring='f1', cv=5)\n",
    "lr_model.fit(features_spacy_train, target_spacy_train)\n",
    "\n",
    "print(\"Лучшие параметры для модели LogisticRegression определенные GridSearchCV:\", lr_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Исследуем модель LogisticRegression на значениях столбца: clear_text\n",
      "-- модель обучена\n",
      "-- есть предсказания\n",
      "-- accuracy_score: 0.839\n",
      "-- f1_score: 0.8367\n",
      "\n",
      "Исследуем модель LogisticRegression на значениях столбца: nltk_text\n",
      "-- модель обучена\n",
      "-- есть предсказания\n",
      "-- accuracy_score: 0.8429\n",
      "-- f1_score: 0.84\n",
      "\n",
      "Исследуем модель LogisticRegression на значениях столбца: spacy_text\n",
      "-- модель обучена\n",
      "-- есть предсказания\n",
      "-- accuracy_score: 0.8495\n",
      "-- f1_score: 0.8473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "# пройдемся по всем типам текстов\n",
    "\n",
    "text_type = ['clear', 'nltk', 'spacy']\n",
    "res = []\n",
    "\n",
    "for iii in range(len(text_type)):\n",
    "    exam_clmn = '{}_text'.format(text_type[iii])\n",
    "    print('Исследуем модель LogisticRegression на значениях столбца:', exam_clmn)\n",
    "    exam_text = df_comm[exam_clmn].values.astype('U')\n",
    "    target = df_comm['toxic']\n",
    "\n",
    "    text_train, text_test, target_train, target_test = train_test_split(exam_text, target, test_size=TS, random_state=RS)\n",
    "\n",
    "    features_train = count_tf_idf.fit_transform(text_train) \n",
    "    features_test = count_tf_idf.transform(text_test) \n",
    "    \n",
    "#    model_exam = LogisticRegression(multi_class='auto', solver='saga', penalty='l2', max_iter=50, class_weight=None, random_state=RS, C=10) #т.к. классы несбалансированы\n",
    "    model_exam = LogisticRegression(multi_class='auto', solver='lbfgs', penalty='none', max_iter=50, class_weight='balanced', random_state=RS, C=1)\n",
    "    model_exam.fit(features_train, target_train)\n",
    "    print('-- модель обучена')\n",
    "    \n",
    "    pred = model_exam.predict(features_test)\n",
    "    print('-- есть предсказания')\n",
    "    \n",
    "    acc = np.round(accuracy_score(target_test, pred), 4)\n",
    "    f1 = np.round(f1_score(target_test, pred), 4)\n",
    "    print('-- accuracy_score:', acc)\n",
    "    print('-- f1_score:', f1)\n",
    "    res.append({'Тип текста': text_type[iii], \n",
    "                'accuracy_score': acc,\n",
    "                'f1_score': f1}) \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Тип текста</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clear</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>0.8367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nltk</td>\n",
       "      <td>0.8429</td>\n",
       "      <td>0.8400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spacy</td>\n",
       "      <td>0.8495</td>\n",
       "      <td>0.8473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Тип текста  accuracy_score  f1_score\n",
       "0      clear          0.8390    0.8367\n",
       "1       nltk          0.8429    0.8400\n",
       "2      spacy          0.8495    0.8473"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = pd.DataFrame(res)\n",
    "display(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы:\n",
    "1. <s>NLTK дал самый лучший результат.</s> Результат нестабилен - в этот раз лучший результат у spacy.\n",
    "2. Лемматизация дает незначительный прирост качества модели по сравнению с очищенным текстом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение\n",
    "### Вариант с BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Сначала наугад протестируем модель CatBoostClassifier (параметры отличаются от тех, что будут использованы далее):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x15715a98850>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "print('Сначала наугад протестируем модель CatBoostClassifier (параметры отличаются от тех, что будут использованы далее):')\n",
    "\n",
    "model_cb = CatBoostClassifier(bootstrap_type='MVS', depth=4, grow_policy='Depthwise', iterations=100, learning_rate=0.03, silent=True, random_seed=RS)\n",
    "model_cb.fit(bert_features_train, bert_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "cross_val_score: [0.848 0.852 0.856]\n",
      "accuracy_score: 0.8506666666666667\n",
      "f1_score: 0.8578680203045685\n",
      "{'iterations': 100, 'learning_rate': 0.03, 'depth': 4, 'random_seed': 12345, 'silent': True, 'bootstrap_type': 'MVS', 'grow_policy': 'Depthwise'}\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "pred_cb = model_cb.predict(bert_features_test)\n",
    "print('cross_val_score:', cross_val_score(model_cb, bert_features_test, bert_target_test, cv=3))\n",
    "print('accuracy_score:', accuracy_score(bert_target_test, pred_cb))\n",
    "print('f1_score:', f1_score(bert_target_test, pred_cb))\n",
    "print(model_cb.get_params(deep=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> В предыдущий раз (с RuBERT) было:\n",
    "<li> cross_val_score: [0.756 0.784 0.752]\n",
    "<li> accuracy_score: 0.76\n",
    "<li> f1_score: 0.7721518987341771\n",
    "<div> <b>Результат значительно улучшился! F1=0.8578680203045685 (а без стратификации было 0.864321608040201)</b></div>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для модели RandomForestClassifier определенные GridSearchCV: {'max_depth': 10, 'min_samples_leaf': 2, 'n_estimators': 80}\n",
      "Wall time: 3min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {'max_depth': [4, 8, 10],\n",
    "          'n_estimators': range(80, 240, 40),\n",
    "         'min_samples_leaf': [1, 2]}\n",
    "\n",
    "rf = RandomForestClassifier(class_weight=None, random_state=RS)\n",
    "rf_model = GridSearchCV(rf, params, scoring='f1', cv=3)\n",
    "rf_model.fit(bert_features_train, bert_target_train)\n",
    "\n",
    "print(\"Лучшие параметры для модели RandomForestClassifier определенные GridSearchCV:\", rf_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Идут вычисления по модели LogisticRegression: {'C': 10, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 50, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 12345, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.8867\n",
      "-- f1_score: 0.8928\n",
      "\n",
      "Идут вычисления по модели DecisionTreeClassifier: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 12345, 'splitter': 'best'}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.784\n",
      "-- f1_score: 0.7955\n",
      "\n",
      "Идут вычисления по модели RandomForestClassifier: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False, 'random_state': 12345, 'verbose': 0, 'warm_start': False}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.8453\n",
      "-- f1_score: 0.852\n",
      "\n",
      "Идут вычисления по модели CatBoostClassifier: {'iterations': 200, 'learning_rate': 0.15, 'depth': 16, 'random_seed': 12345, 'silent': True, 'bootstrap_type': 'MVS', 'grow_policy': 'Lossguide'}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.8627\n",
      "-- f1_score: 0.8688\n",
      "\n",
      "Идут вычисления по модели LGBMClassifier: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.856\n",
      "-- f1_score: 0.8605\n",
      "\n",
      "Идут вычисления по модели XGBClassifier: {'objective': 'binary:logistic', 'use_label_encoder': True, 'base_score': None, 'booster': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'enable_categorical': False, 'gamma': None, 'gpu_id': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_delta_step': None, 'max_depth': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': None, 'num_parallel_tree': None, 'predictor': None, 'random_state': None, 'reg_alpha': None, 'reg_lambda': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
      "[18:16:00] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.8707\n",
      "-- f1_score: 0.8752\n",
      "\n",
      "Идут вычисления по модели DummyClassifier: {'constant': None, 'random_state': 12345, 'strategy': 'prior'}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.532\n",
      "-- f1_score: 0.6945\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>Время_обучения</th>\n",
       "      <th>Время_предсказания</th>\n",
       "      <th>Гиперпараметры</th>\n",
       "      <th>Модель_пригодна</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.8867</td>\n",
       "      <td>0.8928</td>\n",
       "      <td>1.81s</td>\n",
       "      <td>0.01s</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'dual': False,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.7840</td>\n",
       "      <td>0.7955</td>\n",
       "      <td>1.35s</td>\n",
       "      <td>0.0s</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.8453</td>\n",
       "      <td>0.8520</td>\n",
       "      <td>6.78s</td>\n",
       "      <td>0.05s</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.8627</td>\n",
       "      <td>0.8688</td>\n",
       "      <td>74.22s</td>\n",
       "      <td>0.02s</td>\n",
       "      <td>{'iterations': 200, 'learning_rate': 0.15, 'de...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.8560</td>\n",
       "      <td>0.8605</td>\n",
       "      <td>5.03s</td>\n",
       "      <td>0.0s</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.8707</td>\n",
       "      <td>0.8752</td>\n",
       "      <td>8.82s</td>\n",
       "      <td>0.01s</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>0.5320</td>\n",
       "      <td>0.6945</td>\n",
       "      <td>0.0s</td>\n",
       "      <td>0.0s</td>\n",
       "      <td>{'constant': None, 'random_state': 12345, 'str...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Модель  accuracy_score  f1_score Время_обучения  \\\n",
       "0      LogisticRegression          0.8867    0.8928          1.81s   \n",
       "1  DecisionTreeClassifier          0.7840    0.7955          1.35s   \n",
       "2  RandomForestClassifier          0.8453    0.8520          6.78s   \n",
       "3      CatBoostClassifier          0.8627    0.8688         74.22s   \n",
       "4          LGBMClassifier          0.8560    0.8605          5.03s   \n",
       "5           XGBClassifier          0.8707    0.8752          8.82s   \n",
       "6         DummyClassifier          0.5320    0.6945           0.0s   \n",
       "\n",
       "  Время_предсказания                                     Гиперпараметры  \\\n",
       "0              0.01s  {'C': 10, 'class_weight': None, 'dual': False,...   \n",
       "1               0.0s  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...   \n",
       "2              0.05s  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...   \n",
       "3              0.02s  {'iterations': 200, 'learning_rate': 0.15, 'de...   \n",
       "4               0.0s  {'boosting_type': 'gbdt', 'class_weight': None...   \n",
       "5              0.01s  {'objective': 'binary:logistic', 'use_label_en...   \n",
       "6               0.0s  {'constant': None, 'random_state': 12345, 'str...   \n",
       "\n",
       "   Модель_пригодна  \n",
       "0             True  \n",
       "1             True  \n",
       "2             True  \n",
       "3             True  \n",
       "4             True  \n",
       "5             True  \n",
       "6            False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "models = [LogisticRegression(multi_class='auto', solver='saga', penalty='l2', max_iter=50, class_weight=None, random_state=RS, C=10),          \n",
    "          DecisionTreeClassifier(class_weight=None, max_depth=8, random_state=RS),\n",
    "          RandomForestClassifier(class_weight=None, n_estimators=200, max_depth=10, min_samples_leaf=2, random_state=RS),\n",
    "          CatBoostClassifier(bootstrap_type='MVS', depth=16, grow_policy='Lossguide', iterations=200, learning_rate=0.15, silent=True, random_seed=RS),\n",
    "          LGBMClassifier(),\n",
    "          XGBClassifier(),\n",
    "          DummyClassifier(strategy='prior', random_state=RS)]\n",
    "\n",
    "bert_results = []\n",
    "\n",
    "for md in models:\n",
    "    print(f'Идут вычисления по модели {md.__class__.__name__}:', md.get_params(deep=False))\n",
    "    t1 = datetime.now() # Засекли время начала обучения\n",
    "    md.fit(bert_features_train, bert_target_train)\n",
    "    t2 = datetime.now() # Время окончания обучения и начала предсказания\n",
    "    print('-- модель обучена')\n",
    "    bert_pred = md.predict(bert_features_test)\n",
    "    t3 = datetime.now() # Время окончания предсказания\n",
    "    print('-- получены предсказания')\n",
    "    t4 = t2 - t1 # Время обучения\n",
    "    t5 = t3 - t2 # Время предсказания\n",
    "    dt1 = str(np.round(t4.total_seconds(), 2))+'s' # Время обучения в секундах\n",
    "    dt2 = str(np.round(t5.total_seconds(), 2))+'s' # Время предсказания в секундах\n",
    "    \n",
    "    md_acc = np.round(accuracy_score(bert_target_test, bert_pred), 4)\n",
    "    md_f1 = np.round(f1_score(bert_target_test, bert_pred), 4)\n",
    "    \n",
    "    print('-- accuracy_score:', md_acc)\n",
    "    print('-- f1_score:', md_f1)\n",
    "    bert_results.append({'Модель': md.__class__.__name__, \n",
    "                         'accuracy_score': md_acc,\n",
    "                         'f1_score': md_f1,\n",
    "                         'Время_обучения': dt1,\n",
    "                         'Время_предсказания': dt2,                    \n",
    "                         'Гиперпараметры': md.get_params(deep=False),\n",
    "                         'Модель_пригодна': md_f1>=CRIT_F1,\n",
    "                         'pred': bert_pred}) \n",
    "    print('')\n",
    "              \n",
    "bert_results = pd.DataFrame(bert_results)\n",
    "display(bert_results.drop('pred', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель (при работе с BERT): LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "bert_best_mod = bert_results.sort_values(by = 'f1_score', ascending = False).reset_index(drop=True).head(1)\n",
    "print('Лучшая модель (при работе с BERT):', bert_best_mod.loc[0, 'Модель'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вариант без BERT (на данных NLTK+TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "nltk_text = df_comm['nltk_text'].values.astype('U')\n",
    "nltk_target = df_comm['toxic']\n",
    "\n",
    "nltk_text_train, nltk_text_test, nltk_target_train, nltk_target_test = train_test_split(nltk_text, nltk_target, test_size=TS, random_state=RS)\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords) \n",
    "nltk_features_train = count_tf_idf.fit_transform(nltk_text_train) \n",
    "nltk_features_test = count_tf_idf.transform(nltk_text_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Идут вычисления по модели LogisticRegression: {'C': 10, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 50, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 12345, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.8416\n",
      "-- f1_score: 0.8389\n",
      "\n",
      "Идут вычисления по модели DecisionTreeClassifier: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 12345, 'splitter': 'best'}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.6479\n",
      "-- f1_score: 0.7111\n",
      "\n",
      "Идут вычисления по модели RandomForestClassifier: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False, 'random_state': 12345, 'verbose': 0, 'warm_start': False}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.6832\n",
      "-- f1_score: 0.7436\n",
      "\n",
      "Идут вычисления по модели CatBoostClassifier: {'iterations': 200, 'learning_rate': 0.15, 'depth': 16, 'random_seed': 12345, 'silent': True, 'bootstrap_type': 'MVS', 'grow_policy': 'Lossguide'}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.8115\n",
      "-- f1_score: 0.7972\n",
      "\n",
      "Идут вычисления по модели LGBMClassifier: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.7945\n",
      "-- f1_score: 0.7942\n",
      "\n",
      "Идут вычисления по модели XGBClassifier: {'objective': 'binary:logistic', 'use_label_encoder': True, 'base_score': None, 'booster': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'enable_categorical': False, 'gamma': None, 'gpu_id': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_delta_step': None, 'max_depth': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': None, 'num_parallel_tree': None, 'predictor': None, 'random_state': None, 'reg_alpha': None, 'reg_lambda': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
      "[10:06:00] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.8063\n",
      "-- f1_score: 0.8068\n",
      "\n",
      "Идут вычисления по модели DummyClassifier: {'constant': None, 'random_state': 12345, 'strategy': 'prior'}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.4921\n",
      "-- f1_score: 0.6596\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>Время_обучения</th>\n",
       "      <th>Время_предсказания</th>\n",
       "      <th>Гиперпараметры</th>\n",
       "      <th>Модель_пригодна</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.8416</td>\n",
       "      <td>0.8389</td>\n",
       "      <td>0.07s</td>\n",
       "      <td>0.0s</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'dual': False,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.6479</td>\n",
       "      <td>0.7111</td>\n",
       "      <td>0.05s</td>\n",
       "      <td>0.0s</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.6832</td>\n",
       "      <td>0.7436</td>\n",
       "      <td>0.45s</td>\n",
       "      <td>0.05s</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.8115</td>\n",
       "      <td>0.7972</td>\n",
       "      <td>48.45s</td>\n",
       "      <td>0.03s</td>\n",
       "      <td>{'iterations': 200, 'learning_rate': 0.15, 'de...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.7945</td>\n",
       "      <td>0.7942</td>\n",
       "      <td>0.26s</td>\n",
       "      <td>0.0s</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.8063</td>\n",
       "      <td>0.8068</td>\n",
       "      <td>0.56s</td>\n",
       "      <td>0.0s</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>0.4921</td>\n",
       "      <td>0.6596</td>\n",
       "      <td>0.0s</td>\n",
       "      <td>0.0s</td>\n",
       "      <td>{'constant': None, 'random_state': 12345, 'str...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Модель  accuracy_score  f1_score Время_обучения  \\\n",
       "0      LogisticRegression          0.8416    0.8389          0.07s   \n",
       "1  DecisionTreeClassifier          0.6479    0.7111          0.05s   \n",
       "2  RandomForestClassifier          0.6832    0.7436          0.45s   \n",
       "3      CatBoostClassifier          0.8115    0.7972         48.45s   \n",
       "4          LGBMClassifier          0.7945    0.7942          0.26s   \n",
       "5           XGBClassifier          0.8063    0.8068          0.56s   \n",
       "6         DummyClassifier          0.4921    0.6596           0.0s   \n",
       "\n",
       "  Время_предсказания                                     Гиперпараметры  \\\n",
       "0               0.0s  {'C': 10, 'class_weight': None, 'dual': False,...   \n",
       "1               0.0s  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...   \n",
       "2              0.05s  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...   \n",
       "3              0.03s  {'iterations': 200, 'learning_rate': 0.15, 'de...   \n",
       "4               0.0s  {'boosting_type': 'gbdt', 'class_weight': None...   \n",
       "5               0.0s  {'objective': 'binary:logistic', 'use_label_en...   \n",
       "6               0.0s  {'constant': None, 'random_state': 12345, 'str...   \n",
       "\n",
       "   Модель_пригодна  \n",
       "0             True  \n",
       "1            False  \n",
       "2            False  \n",
       "3             True  \n",
       "4             True  \n",
       "5             True  \n",
       "6            False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 50 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "models = [LogisticRegression(multi_class='auto', solver='saga', penalty='l2', max_iter=50, class_weight=None, random_state=RS, C=10),          \n",
    "          DecisionTreeClassifier(class_weight=None, max_depth=8, random_state=RS),\n",
    "          RandomForestClassifier(class_weight=None, n_estimators=200, max_depth=10, min_samples_leaf=2, random_state=RS),\n",
    "          CatBoostClassifier(bootstrap_type='MVS', depth=16, grow_policy='Lossguide', iterations=200, learning_rate=0.15, silent=True, random_seed=RS),\n",
    "          LGBMClassifier(),\n",
    "          XGBClassifier(),\n",
    "          DummyClassifier(strategy='prior', random_state=RS)]\n",
    "\n",
    "tf_idf_results = []\n",
    "\n",
    "for md in models:\n",
    "    print(f'Идут вычисления по модели {md.__class__.__name__}:', md.get_params(deep=False))\n",
    "    t1 = datetime.now() # Засекли время начала обучения\n",
    "    md.fit(nltk_features_train, nltk_target_train)\n",
    "    t2 = datetime.now() # Время окончания обучения и начала предсказания\n",
    "    print('-- модель обучена')\n",
    "    nltk_pred = md.predict(nltk_features_test)\n",
    "    t3 = datetime.now() # Время окончания предсказания\n",
    "    print('-- получены предсказания')\n",
    "    t4 = t2 - t1 # Время обучения\n",
    "    t5 = t3 - t2 # Время предсказания\n",
    "    dt1 = str(np.round(t4.total_seconds(), 2))+'s' # Время обучения в секундах\n",
    "    dt2 = str(np.round(t5.total_seconds(), 2))+'s' # Время предсказания в секундах\n",
    "    \n",
    "    md_acc = np.round(accuracy_score(nltk_target_test, nltk_pred), 4)\n",
    "    md_f1 = np.round(f1_score(nltk_target_test, nltk_pred), 4)\n",
    "    \n",
    "    print('-- accuracy_score:', md_acc)\n",
    "    print('-- f1_score:', md_f1)\n",
    "    tf_idf_results.append({'Модель': md.__class__.__name__, \n",
    "                           'accuracy_score': md_acc,\n",
    "                           'f1_score': md_f1,\n",
    "                           'Время_обучения': dt1,\n",
    "                           'Время_предсказания': dt2,                    \n",
    "                           'Гиперпараметры': md.get_params(deep=False),\n",
    "                           'Модель_пригодна': md_f1>=CRIT_F1,\n",
    "                           'pred': nltk_pred}) \n",
    "    print('')\n",
    "              \n",
    "tf_idf_results = pd.DataFrame(tf_idf_results)\n",
    "display(tf_idf_results.drop('pred', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель (при работе с TF-IDF): LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "tf_idf_best_mod = tf_idf_results.sort_values(by = 'f1_score', ascending = False).reset_index(drop=True).head(1)\n",
    "print('Лучшая модель (при работе с TF-IDF):', tf_idf_best_mod.loc[0, 'Модель'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сравним результаты BERT и TF-IDF:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>f1_score_NLTK_TF_IDF</th>\n",
       "      <th>f1_score_BERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.8389</td>\n",
       "      <td>0.8928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.7111</td>\n",
       "      <td>0.7955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.7436</td>\n",
       "      <td>0.8520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.7972</td>\n",
       "      <td>0.8688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.7942</td>\n",
       "      <td>0.8605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.8068</td>\n",
       "      <td>0.8752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>0.6596</td>\n",
       "      <td>0.6945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Модель  f1_score_NLTK_TF_IDF  f1_score_BERT\n",
       "0      LogisticRegression                0.8389         0.8928\n",
       "1  DecisionTreeClassifier                0.7111         0.7955\n",
       "2  RandomForestClassifier                0.7436         0.8520\n",
       "3      CatBoostClassifier                0.7972         0.8688\n",
       "4          LGBMClassifier                0.7942         0.8605\n",
       "5           XGBClassifier                0.8068         0.8752\n",
       "6         DummyClassifier                0.6596         0.6945"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Сравним результаты BERT и TF-IDF:')\n",
    "delta = tf_idf_results.drop(['pred', 'Модель_пригодна', 'Гиперпараметры', 'Время_предсказания', 'Время_обучения', 'accuracy_score'], axis=1)\n",
    "delta = delta.rename(columns={\"f1_score\": \"f1_score_NLTK_TF_IDF\"})\n",
    "delta['f1_score_BERT'] = bert_results['f1_score']\n",
    "display(delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "1. Балансировка классов оказала решающее действие на качество модели - метрика f1 подросла примерно в 2 раза.\n",
    "2. <s>При заданных параметрах метод TF-IDF дает признаки для предсказания немного лучше чем в результате работы BERT. Возможно, дело в том, что для BERT используется ограничение длинны MXL=50.</s>После применения DistilBert метрика F1 стала чуть лучше (0.88 против 0.85) чем для метода TF-IDF, но скорость работы последнего выше.\n",
    "3. <s>Модель CatBoostClassifier на обоих типах признаков дала примерно одинаковые значения</s>Модель CatBoostClassifier дала лучшее значение на данных подготвленных BERT (F1=0.8814), а модель LogisticRegression на признаках подгтовленных spacy+TF-IDF дала самый лучший результат (F1=0.8556 на данных подготовленных spacy и 0.8367 на данных подгоовленных NLTK).\n",
    "4. Стратификация оказывает странный эффект - где-то она немного ухудшила качество, где-то улучшила. Думаю, что это все в пределах погрешности выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 4462,
    "start_time": "2022-05-25T11:14:49.856Z"
   },
   {
    "duration": 2134,
    "start_time": "2022-05-25T11:14:55.676Z"
   },
   {
    "duration": 781,
    "start_time": "2022-05-25T11:15:41.520Z"
   },
   {
    "duration": 26,
    "start_time": "2022-05-25T11:17:43.774Z"
   },
   {
    "duration": 530,
    "start_time": "2022-05-25T11:20:43.299Z"
   },
   {
    "duration": 713,
    "start_time": "2022-05-25T11:22:09.035Z"
   },
   {
    "duration": 7425,
    "start_time": "2022-05-25T11:23:04.848Z"
   },
   {
    "duration": 1800,
    "start_time": "2022-05-25T11:23:36.153Z"
   },
   {
    "duration": 1306,
    "start_time": "2022-05-25T11:23:47.086Z"
   },
   {
    "duration": 1286,
    "start_time": "2022-05-25T11:23:55.876Z"
   },
   {
    "duration": 3186,
    "start_time": "2022-05-25T11:24:13.361Z"
   },
   {
    "duration": 126,
    "start_time": "2022-05-25T11:26:20.040Z"
   },
   {
    "duration": 57,
    "start_time": "2022-05-25T11:26:46.450Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-25T11:27:26.552Z"
   },
   {
    "duration": 2196,
    "start_time": "2022-05-25T11:27:27.932Z"
   },
   {
    "duration": 24,
    "start_time": "2022-05-25T11:27:31.601Z"
   },
   {
    "duration": 16320,
    "start_time": "2022-05-25T11:27:32.713Z"
   },
   {
    "duration": 51,
    "start_time": "2022-05-25T11:27:53.682Z"
   },
   {
    "duration": 53,
    "start_time": "2022-05-25T11:28:34.498Z"
   },
   {
    "duration": 11811,
    "start_time": "2022-05-26T07:39:58.756Z"
   },
   {
    "duration": 2249,
    "start_time": "2022-05-26T07:40:10.569Z"
   },
   {
    "duration": 27,
    "start_time": "2022-05-26T07:40:12.820Z"
   },
   {
    "duration": 18469,
    "start_time": "2022-05-26T07:40:15.682Z"
   },
   {
    "duration": 53580,
    "start_time": "2022-05-26T07:40:34.153Z"
   },
   {
    "duration": 279,
    "start_time": "2022-05-26T07:41:34.431Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-26T07:42:05.748Z"
   },
   {
    "duration": 739,
    "start_time": "2022-05-26T08:00:36.487Z"
   },
   {
    "duration": 4095,
    "start_time": "2022-05-26T08:00:56.034Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-26T08:02:16.169Z"
   },
   {
    "duration": 2910,
    "start_time": "2022-05-26T08:02:23.422Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-26T08:20:34.871Z"
   },
   {
    "duration": 75,
    "start_time": "2022-05-26T08:24:00.083Z"
   },
   {
    "duration": 161,
    "start_time": "2022-05-26T08:24:11.743Z"
   },
   {
    "duration": 211,
    "start_time": "2022-05-26T08:24:36.362Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-26T08:24:41.229Z"
   },
   {
    "duration": 1259,
    "start_time": "2022-05-26T08:24:42.261Z"
   },
   {
    "duration": 888,
    "start_time": "2022-05-26T08:26:13.447Z"
   },
   {
    "duration": 33,
    "start_time": "2022-05-26T08:26:15.808Z"
   },
   {
    "duration": 807,
    "start_time": "2022-05-26T08:26:21.373Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-26T08:28:08.410Z"
   },
   {
    "duration": 845,
    "start_time": "2022-05-26T08:28:13.559Z"
   },
   {
    "duration": 27,
    "start_time": "2022-05-26T08:28:16.760Z"
   },
   {
    "duration": 210175,
    "start_time": "2022-05-26T08:28:21.420Z"
   },
   {
    "duration": 124776,
    "start_time": "2022-05-26T08:32:30.088Z"
   },
   {
    "duration": 503,
    "start_time": "2022-05-26T08:51:39.457Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-26T08:54:57.511Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-26T08:55:01.297Z"
   },
   {
    "duration": 48,
    "start_time": "2022-05-26T08:55:03.168Z"
   },
   {
    "duration": 1724,
    "start_time": "2022-05-26T08:55:39.250Z"
   },
   {
    "duration": 23,
    "start_time": "2022-05-26T08:56:49.296Z"
   },
   {
    "duration": 463,
    "start_time": "2022-05-26T08:57:13.020Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-26T08:57:14.827Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-26T08:57:16.138Z"
   },
   {
    "duration": 127,
    "start_time": "2022-05-26T08:57:17.552Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-26T08:57:49.055Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-26T08:58:24.951Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-26T09:00:52.286Z"
   },
   {
    "duration": 3307,
    "start_time": "2022-05-26T09:01:21.018Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-26T09:02:23.517Z"
   },
   {
    "duration": 635,
    "start_time": "2022-05-26T09:05:34.155Z"
   },
   {
    "duration": 201,
    "start_time": "2022-05-26T09:07:04.401Z"
   },
   {
    "duration": 509,
    "start_time": "2022-05-26T09:07:54.337Z"
   },
   {
    "duration": 28,
    "start_time": "2022-05-26T09:12:17.947Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-26T09:15:26.418Z"
   },
   {
    "duration": 871,
    "start_time": "2022-05-26T09:23:36.820Z"
   },
   {
    "duration": 26,
    "start_time": "2022-05-26T09:23:40.676Z"
   },
   {
    "duration": 3745,
    "start_time": "2022-05-26T09:23:55.055Z"
   },
   {
    "duration": 907,
    "start_time": "2022-05-26T09:24:04.747Z"
   },
   {
    "duration": 7365,
    "start_time": "2022-05-26T09:24:05.939Z"
   },
   {
    "duration": 246,
    "start_time": "2022-05-26T10:18:32.121Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-26T10:19:01.390Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-26T10:27:30.417Z"
   },
   {
    "duration": 88,
    "start_time": "2022-05-26T10:27:43.918Z"
   },
   {
    "duration": 84,
    "start_time": "2022-05-26T10:28:50.200Z"
   },
   {
    "duration": 82,
    "start_time": "2022-05-26T10:35:05.556Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-26T10:35:09.805Z"
   },
   {
    "duration": 79,
    "start_time": "2022-05-26T10:35:11.878Z"
   },
   {
    "duration": 80,
    "start_time": "2022-05-26T10:36:46.636Z"
   },
   {
    "duration": 76,
    "start_time": "2022-05-26T10:37:57.838Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-26T10:38:30.408Z"
   },
   {
    "duration": 68,
    "start_time": "2022-05-26T10:38:34.136Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-26T10:47:11.406Z"
   },
   {
    "duration": 76,
    "start_time": "2022-05-26T10:47:12.108Z"
   },
   {
    "duration": 75,
    "start_time": "2022-05-26T10:47:29.585Z"
   },
   {
    "duration": 58,
    "start_time": "2022-05-26T10:47:53.114Z"
   },
   {
    "duration": 26,
    "start_time": "2022-05-26T10:48:30.389Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-26T10:48:58.223Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-26T10:49:05.403Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-26T10:50:25.748Z"
   },
   {
    "duration": 34,
    "start_time": "2022-05-26T10:52:27.606Z"
   },
   {
    "duration": 40,
    "start_time": "2022-05-26T10:52:28.599Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-26T10:52:31.284Z"
   },
   {
    "duration": 66,
    "start_time": "2022-05-26T10:52:47.600Z"
   },
   {
    "duration": 38,
    "start_time": "2022-05-26T10:53:48.638Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-26T10:53:50.855Z"
   },
   {
    "duration": 3360,
    "start_time": "2022-05-27T08:12:35.478Z"
   },
   {
    "duration": 2488,
    "start_time": "2022-05-27T08:12:38.840Z"
   },
   {
    "duration": 25,
    "start_time": "2022-05-27T08:12:42.777Z"
   },
   {
    "duration": 21802,
    "start_time": "2022-05-27T08:12:46.857Z"
   },
   {
    "duration": 119818,
    "start_time": "2022-05-27T08:13:12.347Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T08:15:16.677Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T08:15:22.428Z"
   },
   {
    "duration": 813,
    "start_time": "2022-05-27T08:15:23.724Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T08:15:27.871Z"
   },
   {
    "duration": 1633,
    "start_time": "2022-05-27T08:15:29.201Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T08:15:30.836Z"
   },
   {
    "duration": 5661,
    "start_time": "2022-05-27T08:15:34.149Z"
   },
   {
    "duration": 1056,
    "start_time": "2022-05-27T08:15:44.356Z"
   },
   {
    "duration": 11968,
    "start_time": "2022-05-27T08:15:45.413Z"
   },
   {
    "duration": 24,
    "start_time": "2022-05-27T08:15:59.871Z"
   },
   {
    "duration": 91,
    "start_time": "2022-05-27T08:16:02.147Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-27T08:16:04.673Z"
   },
   {
    "duration": 1406,
    "start_time": "2022-05-27T08:16:13.472Z"
   },
   {
    "duration": 2711,
    "start_time": "2022-05-27T08:16:16.648Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-27T08:17:24.371Z"
   },
   {
    "duration": 123,
    "start_time": "2022-05-27T08:19:38.960Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-27T08:19:42.454Z"
   },
   {
    "duration": 4108,
    "start_time": "2022-05-27T08:19:53.355Z"
   },
   {
    "duration": 5942,
    "start_time": "2022-05-27T08:19:59.624Z"
   },
   {
    "duration": 543,
    "start_time": "2022-05-27T08:20:38.942Z"
   },
   {
    "duration": 313,
    "start_time": "2022-05-27T08:21:01.796Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T08:23:11.240Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T08:24:03.477Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T08:24:07.010Z"
   },
   {
    "duration": 306,
    "start_time": "2022-05-27T08:25:18.343Z"
   },
   {
    "duration": 322,
    "start_time": "2022-05-27T08:25:20.715Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T08:25:21.956Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T08:28:51.621Z"
   },
   {
    "duration": 416,
    "start_time": "2022-05-27T08:29:17.487Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-27T08:30:26.856Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T08:30:27.688Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T08:31:29.796Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T08:31:55.571Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-27T08:33:16.746Z"
   },
   {
    "duration": 116,
    "start_time": "2022-05-27T08:45:29.248Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-27T08:45:30.499Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-27T08:46:01.613Z"
   },
   {
    "duration": 27,
    "start_time": "2022-05-27T08:46:52.052Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T08:47:28.454Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-27T08:49:19.361Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T08:49:32.358Z"
   },
   {
    "duration": 21,
    "start_time": "2022-05-27T08:50:35.320Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-27T08:50:59.507Z"
   },
   {
    "duration": 47,
    "start_time": "2022-05-27T08:52:56.828Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-27T08:53:07.726Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-27T08:53:20.729Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-27T08:56:11.473Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-27T08:57:06.684Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-27T08:58:30.942Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-27T08:58:42.275Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-27T08:59:14.671Z"
   },
   {
    "duration": 717,
    "start_time": "2022-05-27T09:00:53.031Z"
   },
   {
    "duration": 12015,
    "start_time": "2022-05-27T09:00:56.428Z"
   },
   {
    "duration": 71,
    "start_time": "2022-05-27T09:01:21.770Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-27T09:01:42.702Z"
   },
   {
    "duration": 50,
    "start_time": "2022-05-27T09:04:57.502Z"
   },
   {
    "duration": 63,
    "start_time": "2022-05-27T09:05:16.256Z"
   },
   {
    "duration": 77,
    "start_time": "2022-05-27T09:05:35.052Z"
   },
   {
    "duration": 54,
    "start_time": "2022-05-27T09:05:52.556Z"
   },
   {
    "duration": 1197,
    "start_time": "2022-05-27T09:06:16.174Z"
   },
   {
    "duration": 12672,
    "start_time": "2022-05-27T09:06:18.853Z"
   },
   {
    "duration": 74,
    "start_time": "2022-05-27T09:06:36.058Z"
   },
   {
    "duration": 62,
    "start_time": "2022-05-27T09:38:06.778Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-27T09:38:16.310Z"
   },
   {
    "duration": 70,
    "start_time": "2022-05-27T09:38:39.334Z"
   },
   {
    "duration": 56,
    "start_time": "2022-05-27T09:38:55.985Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T09:41:59.574Z"
   },
   {
    "duration": 862,
    "start_time": "2022-05-27T09:42:00.217Z"
   },
   {
    "duration": 44,
    "start_time": "2022-05-27T09:42:03.842Z"
   },
   {
    "duration": 84,
    "start_time": "2022-05-27T09:42:54.525Z"
   },
   {
    "duration": 82,
    "start_time": "2022-05-27T09:43:04.207Z"
   },
   {
    "duration": 81,
    "start_time": "2022-05-27T09:43:34.036Z"
   },
   {
    "duration": 81,
    "start_time": "2022-05-27T09:44:32.239Z"
   },
   {
    "duration": 79,
    "start_time": "2022-05-27T09:44:49.752Z"
   },
   {
    "duration": 492,
    "start_time": "2022-05-27T10:12:04.854Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T10:12:16.944Z"
   },
   {
    "duration": 801,
    "start_time": "2022-05-27T10:12:17.731Z"
   },
   {
    "duration": 80,
    "start_time": "2022-05-27T10:12:18.694Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T10:12:21.078Z"
   },
   {
    "duration": 24,
    "start_time": "2022-05-27T10:12:21.680Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T10:12:29.534Z"
   },
   {
    "duration": 227,
    "start_time": "2022-05-27T10:12:30.142Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T10:12:31.332Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-27T10:12:32.197Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T10:12:34.911Z"
   },
   {
    "duration": 5894,
    "start_time": "2022-05-27T10:12:36.613Z"
   },
   {
    "duration": 604,
    "start_time": "2022-05-27T10:12:46.015Z"
   },
   {
    "duration": 11882,
    "start_time": "2022-05-27T10:12:48.183Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T10:13:03.743Z"
   },
   {
    "duration": 69,
    "start_time": "2022-05-27T10:13:04.783Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-27T10:13:52.760Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-27T10:14:25.311Z"
   },
   {
    "duration": 46,
    "start_time": "2022-05-27T10:16:57.591Z"
   },
   {
    "duration": 68,
    "start_time": "2022-05-27T10:17:10.326Z"
   },
   {
    "duration": 78,
    "start_time": "2022-05-27T10:17:27.207Z"
   },
   {
    "duration": 44,
    "start_time": "2022-05-27T10:18:15.399Z"
   },
   {
    "duration": 46,
    "start_time": "2022-05-27T10:18:19.671Z"
   },
   {
    "duration": 47,
    "start_time": "2022-05-27T10:18:23.671Z"
   },
   {
    "duration": 91,
    "start_time": "2022-05-27T10:19:52.103Z"
   },
   {
    "duration": 74,
    "start_time": "2022-05-27T10:20:05.655Z"
   },
   {
    "duration": 63,
    "start_time": "2022-05-27T10:20:12.458Z"
   },
   {
    "duration": 78,
    "start_time": "2022-05-27T10:20:20.503Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T11:26:48.915Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T11:31:13.489Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T11:32:17.771Z"
   },
   {
    "duration": 58,
    "start_time": "2022-05-27T11:32:35.330Z"
   },
   {
    "duration": 60,
    "start_time": "2022-05-27T11:33:04.516Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T11:33:12.154Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-27T11:34:33.512Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T11:34:49.348Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T11:35:03.197Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T11:35:11.371Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T11:35:42.683Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-27T11:37:37.692Z"
   },
   {
    "duration": 41,
    "start_time": "2022-05-27T11:38:38.748Z"
   },
   {
    "duration": 62,
    "start_time": "2022-05-27T11:39:19.543Z"
   },
   {
    "duration": 99,
    "start_time": "2022-05-27T11:39:44.498Z"
   },
   {
    "duration": 494,
    "start_time": "2022-05-27T11:40:59.273Z"
   },
   {
    "duration": 143,
    "start_time": "2022-05-27T11:41:41.951Z"
   },
   {
    "duration": 135,
    "start_time": "2022-05-27T11:44:31.784Z"
   },
   {
    "duration": 130,
    "start_time": "2022-05-27T11:45:18.982Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T11:46:29.831Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-27T11:53:45.290Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T11:53:50.838Z"
   },
   {
    "duration": 198,
    "start_time": "2022-05-27T11:53:56.910Z"
   },
   {
    "duration": 182,
    "start_time": "2022-05-27T11:54:11.298Z"
   },
   {
    "duration": 1164,
    "start_time": "2022-05-27T11:55:05.503Z"
   },
   {
    "duration": 3301,
    "start_time": "2022-05-27T11:55:07.481Z"
   },
   {
    "duration": 1104,
    "start_time": "2022-05-27T11:55:58.471Z"
   },
   {
    "duration": 2993,
    "start_time": "2022-05-27T11:56:00.883Z"
   },
   {
    "duration": 58,
    "start_time": "2022-05-27T11:58:34.260Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-27T11:58:48.960Z"
   },
   {
    "duration": 30,
    "start_time": "2022-05-27T12:01:53.371Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T12:02:23.144Z"
   },
   {
    "duration": 39,
    "start_time": "2022-05-27T12:02:32.291Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T12:03:23.954Z"
   },
   {
    "duration": 32,
    "start_time": "2022-05-27T12:03:43.895Z"
   },
   {
    "duration": 36,
    "start_time": "2022-05-27T12:05:02.674Z"
   },
   {
    "duration": 34,
    "start_time": "2022-05-27T12:05:16.921Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T12:06:22.143Z"
   },
   {
    "duration": 34,
    "start_time": "2022-05-27T12:06:30.717Z"
   },
   {
    "duration": 36,
    "start_time": "2022-05-27T12:09:32.772Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T12:10:11.147Z"
   },
   {
    "duration": 50,
    "start_time": "2022-05-27T12:10:17.421Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T12:10:44.571Z"
   },
   {
    "duration": 54,
    "start_time": "2022-05-27T12:11:01.143Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T12:15:00.973Z"
   },
   {
    "duration": 23,
    "start_time": "2022-05-27T12:15:09.072Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-27T12:15:58.071Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-27T12:16:06.113Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T12:24:59.910Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T12:26:49.007Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T12:26:50.555Z"
   },
   {
    "duration": 925,
    "start_time": "2022-05-27T12:26:51.774Z"
   },
   {
    "duration": 79,
    "start_time": "2022-05-27T12:26:53.784Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T12:27:02.995Z"
   },
   {
    "duration": 33,
    "start_time": "2022-05-27T12:27:04.220Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-27T12:27:15.585Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T12:27:35.251Z"
   },
   {
    "duration": 51,
    "start_time": "2022-05-27T12:27:35.889Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-27T12:27:59.952Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-27T12:28:16.383Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-27T12:28:41.745Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-27T12:29:55.755Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T12:30:57.421Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T12:30:58.090Z"
   },
   {
    "duration": 825,
    "start_time": "2022-05-27T12:30:58.992Z"
   },
   {
    "duration": 88,
    "start_time": "2022-05-27T12:31:02.670Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T12:31:05.053Z"
   },
   {
    "duration": 54,
    "start_time": "2022-05-27T12:31:11.305Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-27T12:31:14.474Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-27T12:31:34.288Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T12:31:35.371Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T12:32:06.011Z"
   },
   {
    "duration": 257,
    "start_time": "2022-05-27T12:32:07.052Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T12:32:08.386Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-27T12:32:11.104Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T12:32:13.703Z"
   },
   {
    "duration": 19057,
    "start_time": "2022-05-27T12:32:18.151Z"
   },
   {
    "duration": 635,
    "start_time": "2022-05-27T12:32:38.912Z"
   },
   {
    "duration": 43336,
    "start_time": "2022-05-27T12:32:41.443Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T12:33:28.741Z"
   },
   {
    "duration": 164,
    "start_time": "2022-05-27T12:33:31.300Z"
   },
   {
    "duration": 106,
    "start_time": "2022-05-27T12:33:33.174Z"
   },
   {
    "duration": 55,
    "start_time": "2022-05-27T12:33:42.650Z"
   },
   {
    "duration": 65,
    "start_time": "2022-05-27T12:34:41.285Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T12:35:28.121Z"
   },
   {
    "duration": 134,
    "start_time": "2022-05-27T12:35:38.947Z"
   },
   {
    "duration": 126,
    "start_time": "2022-05-27T12:35:50.231Z"
   },
   {
    "duration": 139,
    "start_time": "2022-05-27T12:35:59.217Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-27T12:36:02.930Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T12:52:32.598Z"
   },
   {
    "duration": 29,
    "start_time": "2022-05-27T12:53:17.795Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T12:56:12.304Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T12:56:15.446Z"
   },
   {
    "duration": 890,
    "start_time": "2022-05-27T12:56:17.232Z"
   },
   {
    "duration": 78,
    "start_time": "2022-05-27T12:56:21.073Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T12:56:21.872Z"
   },
   {
    "duration": 62,
    "start_time": "2022-05-27T12:56:23.676Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-27T12:56:26.031Z"
   },
   {
    "duration": 22,
    "start_time": "2022-05-27T12:56:27.390Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T12:56:30.035Z"
   },
   {
    "duration": 6699,
    "start_time": "2022-05-27T12:56:31.184Z"
   },
   {
    "duration": 515193,
    "start_time": "2022-05-27T12:56:40.893Z"
   },
   {
    "duration": 34,
    "start_time": "2022-05-27T13:05:38.346Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-27T13:06:47.851Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-27T13:11:13.512Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T13:11:48.109Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T13:11:49.394Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T13:11:51.276Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T13:11:54.387Z"
   },
   {
    "duration": 19710,
    "start_time": "2022-05-27T13:11:55.886Z"
   },
   {
    "duration": 699,
    "start_time": "2022-05-27T13:12:21.304Z"
   },
   {
    "duration": 44500,
    "start_time": "2022-05-27T13:12:24.943Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T13:14:54.701Z"
   },
   {
    "duration": 158,
    "start_time": "2022-05-27T13:14:56.330Z"
   },
   {
    "duration": 130,
    "start_time": "2022-05-27T13:15:01.154Z"
   },
   {
    "duration": 114,
    "start_time": "2022-05-27T13:15:02.642Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T13:15:16.945Z"
   },
   {
    "duration": 139,
    "start_time": "2022-05-27T13:15:20.410Z"
   },
   {
    "duration": 147,
    "start_time": "2022-05-27T13:15:25.374Z"
   },
   {
    "duration": 123,
    "start_time": "2022-05-27T13:15:28.682Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-27T13:15:32.504Z"
   },
   {
    "duration": 28,
    "start_time": "2022-05-27T13:16:10.490Z"
   },
   {
    "duration": 1356,
    "start_time": "2022-05-27T13:16:16.014Z"
   },
   {
    "duration": 5320,
    "start_time": "2022-05-27T13:16:18.852Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T13:16:39.554Z"
   },
   {
    "duration": 1281,
    "start_time": "2022-05-27T13:16:41.025Z"
   },
   {
    "duration": 1392,
    "start_time": "2022-05-27T13:16:49.140Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T13:17:06.475Z"
   },
   {
    "duration": 5650,
    "start_time": "2022-05-27T13:22:07.316Z"
   },
   {
    "duration": 1440,
    "start_time": "2022-05-27T13:22:20.152Z"
   },
   {
    "duration": 1420,
    "start_time": "2022-05-27T13:22:51.025Z"
   },
   {
    "duration": 1854,
    "start_time": "2022-05-27T13:23:33.225Z"
   },
   {
    "duration": 4529,
    "start_time": "2022-05-27T13:23:36.146Z"
   },
   {
    "duration": 2061,
    "start_time": "2022-05-27T13:23:57.507Z"
   },
   {
    "duration": 6309,
    "start_time": "2022-05-27T13:24:00.751Z"
   },
   {
    "duration": 22,
    "start_time": "2022-05-27T13:24:45.480Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-27T13:25:30.815Z"
   },
   {
    "duration": 3130,
    "start_time": "2022-05-27T13:26:22.052Z"
   },
   {
    "duration": 3656,
    "start_time": "2022-05-27T13:26:54.293Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T13:27:05.340Z"
   },
   {
    "duration": 23,
    "start_time": "2022-05-27T13:27:58.771Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T13:28:03.679Z"
   },
   {
    "duration": 3283,
    "start_time": "2022-05-27T13:28:48.709Z"
   },
   {
    "duration": 3885,
    "start_time": "2022-05-27T13:28:57.954Z"
   },
   {
    "duration": 46,
    "start_time": "2022-05-27T13:29:15.362Z"
   },
   {
    "duration": 3011,
    "start_time": "2022-05-27T13:29:19.824Z"
   },
   {
    "duration": 38,
    "start_time": "2022-05-27T13:29:23.480Z"
   },
   {
    "duration": 18052,
    "start_time": "2022-05-27T13:38:15.105Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T13:40:46.628Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T13:40:56.471Z"
   },
   {
    "duration": 24,
    "start_time": "2022-05-27T13:41:32.186Z"
   },
   {
    "duration": 57143,
    "start_time": "2022-05-27T13:47:17.047Z"
   },
   {
    "duration": 134249,
    "start_time": "2022-05-27T13:48:31.011Z"
   },
   {
    "duration": 33,
    "start_time": "2022-05-27T13:50:55.983Z"
   },
   {
    "duration": 59,
    "start_time": "2022-05-27T13:56:20.953Z"
   },
   {
    "duration": 461915,
    "start_time": "2022-05-27T13:56:59.254Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T14:05:31.755Z"
   },
   {
    "duration": 254,
    "start_time": "2022-05-27T14:07:48.978Z"
   },
   {
    "duration": 70,
    "start_time": "2022-05-27T14:13:00.257Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-27T14:15:11.512Z"
   },
   {
    "duration": 3436,
    "start_time": "2022-05-27T14:15:17.251Z"
   },
   {
    "duration": 3396,
    "start_time": "2022-05-27T14:16:02.173Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T14:16:15.651Z"
   },
   {
    "duration": 135248,
    "start_time": "2022-05-27T14:16:21.361Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-27T14:19:13.510Z"
   },
   {
    "duration": 134470,
    "start_time": "2022-05-27T14:20:36.087Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T14:25:12.059Z"
   },
   {
    "duration": 177,
    "start_time": "2022-05-27T14:29:42.890Z"
   },
   {
    "duration": 124,
    "start_time": "2022-05-27T14:29:44.519Z"
   },
   {
    "duration": 111,
    "start_time": "2022-05-27T14:29:45.453Z"
   },
   {
    "duration": 51,
    "start_time": "2022-05-27T14:50:55.582Z"
   },
   {
    "duration": 4699,
    "start_time": "2022-05-27T14:51:13.727Z"
   },
   {
    "duration": 5291,
    "start_time": "2022-05-27T14:54:36.326Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T14:54:45.422Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-27T14:55:11.503Z"
   },
   {
    "duration": 6545,
    "start_time": "2022-05-27T14:55:30.080Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-27T14:55:38.221Z"
   },
   {
    "duration": 5517,
    "start_time": "2022-05-27T14:55:55.105Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-27T14:56:21.790Z"
   },
   {
    "duration": 168,
    "start_time": "2022-05-27T15:49:04.010Z"
   },
   {
    "duration": 4310,
    "start_time": "2022-05-27T15:49:13.988Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T15:49:18.300Z"
   },
   {
    "duration": 2517,
    "start_time": "2022-05-27T15:49:18.307Z"
   },
   {
    "duration": 100,
    "start_time": "2022-05-27T15:49:20.826Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T15:49:20.928Z"
   },
   {
    "duration": 78,
    "start_time": "2022-05-27T15:49:20.935Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-27T15:49:21.017Z"
   },
   {
    "duration": 22,
    "start_time": "2022-05-27T15:49:21.027Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T15:49:21.059Z"
   },
   {
    "duration": 7371,
    "start_time": "2022-05-27T15:49:21.068Z"
   },
   {
    "duration": 360241,
    "start_time": "2022-05-27T15:49:28.441Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-27T15:55:28.759Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-27T15:55:28.771Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-27T15:55:28.786Z"
   },
   {
    "duration": 1500,
    "start_time": "2022-05-27T15:55:28.797Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T15:55:30.298Z"
   },
   {
    "duration": 17942,
    "start_time": "2022-05-27T15:55:30.303Z"
   },
   {
    "duration": 572,
    "start_time": "2022-05-27T15:55:48.247Z"
   },
   {
    "duration": 38402,
    "start_time": "2022-05-27T15:55:48.821Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T15:56:27.225Z"
   },
   {
    "duration": 68,
    "start_time": "2022-05-27T15:56:27.231Z"
   },
   {
    "duration": 146,
    "start_time": "2022-05-27T15:56:27.301Z"
   },
   {
    "duration": 113,
    "start_time": "2022-05-27T15:56:27.448Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T15:56:27.562Z"
   },
   {
    "duration": 135,
    "start_time": "2022-05-27T15:56:27.568Z"
   },
   {
    "duration": 139,
    "start_time": "2022-05-27T15:56:27.705Z"
   },
   {
    "duration": 134,
    "start_time": "2022-05-27T15:56:27.846Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-27T15:56:27.985Z"
   },
   {
    "duration": 29,
    "start_time": "2022-05-27T15:56:27.994Z"
   },
   {
    "duration": 6507,
    "start_time": "2022-05-27T15:56:28.025Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.534Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.535Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.536Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.537Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.538Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.539Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.540Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.541Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.558Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.559Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.560Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.560Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.564Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.565Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.567Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.568Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.569Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.570Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.571Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.572Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.573Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.574Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.575Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.576Z"
   },
   {
    "duration": 3942,
    "start_time": "2022-05-27T15:58:09.684Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-27T16:00:32.767Z"
   },
   {
    "duration": 29,
    "start_time": "2022-05-27T16:38:38.172Z"
   },
   {
    "duration": 298,
    "start_time": "2022-05-27T16:38:47.921Z"
   },
   {
    "duration": 854,
    "start_time": "2022-05-27T16:38:54.731Z"
   },
   {
    "duration": 83,
    "start_time": "2022-05-27T16:54:01.968Z"
   },
   {
    "duration": 361,
    "start_time": "2022-05-27T16:54:08.171Z"
   },
   {
    "duration": 36136,
    "start_time": "2022-05-27T16:54:13.525Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T16:56:58.819Z"
   },
   {
    "duration": 25,
    "start_time": "2022-05-27T16:58:08.372Z"
   },
   {
    "duration": 3206,
    "start_time": "2022-05-27T16:59:42.509Z"
   },
   {
    "duration": 30,
    "start_time": "2022-05-27T17:00:41.755Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-27T17:00:59.280Z"
   },
   {
    "duration": 26,
    "start_time": "2022-05-27T17:06:16.428Z"
   },
   {
    "duration": 162,
    "start_time": "2022-05-27T17:07:30.194Z"
   },
   {
    "duration": 4651,
    "start_time": "2022-05-27T17:35:19.125Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T17:35:23.778Z"
   },
   {
    "duration": 902,
    "start_time": "2022-05-27T17:35:23.784Z"
   },
   {
    "duration": 110,
    "start_time": "2022-05-27T17:35:24.689Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T17:35:24.801Z"
   },
   {
    "duration": 85,
    "start_time": "2022-05-27T17:35:24.808Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T17:35:24.897Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.905Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.906Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.907Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.909Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.910Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.911Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.912Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.913Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.913Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.914Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.916Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.916Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.917Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.918Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.919Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.920Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.921Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.959Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.960Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.961Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.962Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.963Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.965Z"
   },
   {
    "duration": 1,
    "start_time": "2022-05-27T17:35:24.965Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.966Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.968Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.969Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.970Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.972Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.974Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.975Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.976Z"
   },
   {
    "duration": 4506,
    "start_time": "2022-05-27T17:35:48.519Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T17:35:53.028Z"
   },
   {
    "duration": 861,
    "start_time": "2022-05-27T17:35:53.035Z"
   },
   {
    "duration": 99,
    "start_time": "2022-05-27T17:35:53.899Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T17:35:53.999Z"
   },
   {
    "duration": 77,
    "start_time": "2022-05-27T17:35:54.005Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-27T17:35:54.085Z"
   },
   {
    "duration": 23,
    "start_time": "2022-05-27T17:35:54.094Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T17:35:54.119Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.125Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.127Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.128Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.129Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.130Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.132Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.133Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.134Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.159Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.161Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.162Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.163Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.164Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.165Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.167Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.168Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.170Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.171Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.172Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.174Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.175Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.176Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.177Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.178Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.179Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.180Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.181Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.182Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.184Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.185Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-27T17:36:15.976Z"
   },
   {
    "duration": 6241,
    "start_time": "2022-05-27T17:36:19.923Z"
   },
   {
    "duration": 418900,
    "start_time": "2022-05-27T17:37:00.666Z"
   },
   {
    "duration": 359,
    "start_time": "2022-05-27T17:44:10.390Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-27T17:45:02.789Z"
   },
   {
    "duration": 927,
    "start_time": "2022-05-27T17:45:30.325Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T17:45:40.797Z"
   },
   {
    "duration": 55,
    "start_time": "2022-05-27T17:45:43.149Z"
   },
   {
    "duration": 38,
    "start_time": "2022-05-27T17:46:02.381Z"
   },
   {
    "duration": 1520,
    "start_time": "2022-05-27T17:46:28.410Z"
   },
   {
    "duration": 13373,
    "start_time": "2022-05-27T17:46:49.565Z"
   },
   {
    "duration": 685,
    "start_time": "2022-05-27T17:47:05.996Z"
   },
   {
    "duration": 38797,
    "start_time": "2022-05-27T17:47:09.266Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T17:47:48.065Z"
   },
   {
    "duration": 94,
    "start_time": "2022-05-27T17:47:48.070Z"
   },
   {
    "duration": 171,
    "start_time": "2022-05-27T17:47:52.598Z"
   },
   {
    "duration": 73,
    "start_time": "2022-05-27T17:47:53.782Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T17:48:11.887Z"
   },
   {
    "duration": 115,
    "start_time": "2022-05-27T17:48:14.386Z"
   },
   {
    "duration": 148,
    "start_time": "2022-05-27T17:48:17.557Z"
   },
   {
    "duration": 164,
    "start_time": "2022-05-27T17:48:20.387Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T17:48:22.017Z"
   },
   {
    "duration": 52,
    "start_time": "2022-05-27T17:48:35.688Z"
   },
   {
    "duration": 4599,
    "start_time": "2022-05-27T17:48:52.694Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-27T17:49:04.477Z"
   },
   {
    "duration": 19205,
    "start_time": "2022-05-27T17:50:48.576Z"
   },
   {
    "duration": 86343,
    "start_time": "2022-05-27T17:51:14.128Z"
   },
   {
    "duration": 399312,
    "start_time": "2022-05-27T17:53:55.584Z"
   },
   {
    "duration": 242105,
    "start_time": "2022-05-27T18:00:39.777Z"
   },
   {
    "duration": 425,
    "start_time": "2022-05-27T18:04:41.884Z"
   },
   {
    "duration": 503,
    "start_time": "2022-05-27T18:05:13.081Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T18:05:49.529Z"
   },
   {
    "duration": 230,
    "start_time": "2022-05-27T18:06:06.679Z"
   },
   {
    "duration": 60,
    "start_time": "2022-05-27T18:06:13.170Z"
   },
   {
    "duration": 209,
    "start_time": "2022-05-27T18:07:33.926Z"
   },
   {
    "duration": 46582,
    "start_time": "2022-05-27T18:07:36.812Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T18:08:30.591Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T18:08:49.588Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-27T18:08:54.816Z"
   },
   {
    "duration": 4497,
    "start_time": "2022-05-27T18:23:15.808Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T18:23:20.307Z"
   },
   {
    "duration": 908,
    "start_time": "2022-05-27T18:23:20.315Z"
   },
   {
    "duration": 105,
    "start_time": "2022-05-27T18:23:21.226Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T18:23:21.332Z"
   },
   {
    "duration": 75,
    "start_time": "2022-05-27T18:23:21.338Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-27T18:23:21.417Z"
   },
   {
    "duration": 41,
    "start_time": "2022-05-27T18:23:21.426Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T18:23:21.469Z"
   },
   {
    "duration": 6919,
    "start_time": "2022-05-27T18:23:21.479Z"
   },
   {
    "duration": 419787,
    "start_time": "2022-05-27T18:23:28.400Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-27T18:30:28.259Z"
   },
   {
    "duration": 954,
    "start_time": "2022-05-27T18:30:28.277Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T18:30:29.234Z"
   },
   {
    "duration": 1649,
    "start_time": "2022-05-27T18:30:29.240Z"
   },
   {
    "duration": 14016,
    "start_time": "2022-05-27T18:30:30.891Z"
   },
   {
    "duration": 616,
    "start_time": "2022-05-27T18:30:44.908Z"
   },
   {
    "duration": 39985,
    "start_time": "2022-05-27T18:30:45.526Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T18:31:25.512Z"
   },
   {
    "duration": 105,
    "start_time": "2022-05-27T18:31:25.517Z"
   },
   {
    "duration": 140,
    "start_time": "2022-05-27T18:31:25.623Z"
   },
   {
    "duration": 69,
    "start_time": "2022-05-27T18:31:25.765Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T18:31:25.836Z"
   },
   {
    "duration": 124,
    "start_time": "2022-05-27T18:31:25.858Z"
   },
   {
    "duration": 136,
    "start_time": "2022-05-27T18:31:25.983Z"
   },
   {
    "duration": 115,
    "start_time": "2022-05-27T18:31:26.121Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T18:31:26.238Z"
   },
   {
    "duration": 39,
    "start_time": "2022-05-27T18:31:26.260Z"
   },
   {
    "duration": 4200,
    "start_time": "2022-05-27T18:31:26.301Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-27T18:31:30.503Z"
   },
   {
    "duration": 17474,
    "start_time": "2022-05-27T18:31:30.513Z"
   },
   {
    "duration": 49392,
    "start_time": "2022-05-27T18:31:47.989Z"
   },
   {
    "duration": 351680,
    "start_time": "2022-05-27T18:32:37.383Z"
   },
   {
    "duration": 287312,
    "start_time": "2022-05-27T18:38:29.064Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T18:43:16.378Z"
   },
   {
    "duration": 224,
    "start_time": "2022-05-27T18:43:16.384Z"
   },
   {
    "duration": 46360,
    "start_time": "2022-05-27T18:43:16.610Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T18:44:02.971Z"
   },
   {
    "duration": 36,
    "start_time": "2022-05-27T18:44:02.978Z"
   },
   {
    "duration": 5218,
    "start_time": "2022-05-28T18:56:59.050Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-28T18:57:04.270Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-28T18:57:30.784Z"
   },
   {
    "duration": 1403,
    "start_time": "2022-05-28T18:57:52.079Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-28T18:57:56.344Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-28T18:58:02.944Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-28T18:59:20.480Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-28T18:59:30.014Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-28T18:59:40.203Z"
   },
   {
    "duration": 7285,
    "start_time": "2022-05-29T16:14:40.156Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T16:14:47.443Z"
   },
   {
    "duration": 3335,
    "start_time": "2022-05-29T16:14:47.450Z"
   },
   {
    "duration": 92,
    "start_time": "2022-05-29T16:14:53.710Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T16:14:57.071Z"
   },
   {
    "duration": 57,
    "start_time": "2022-05-29T16:15:00.504Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-29T16:15:02.570Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-29T16:15:05.114Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-29T16:15:07.056Z"
   },
   {
    "duration": 17242,
    "start_time": "2022-05-29T16:15:08.536Z"
   },
   {
    "duration": 301878,
    "start_time": "2022-05-29T16:15:37.513Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-29T16:21:54.317Z"
   },
   {
    "duration": 831,
    "start_time": "2022-05-29T16:22:00.004Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T16:22:04.293Z"
   },
   {
    "duration": 1710,
    "start_time": "2022-05-29T16:22:06.279Z"
   },
   {
    "duration": 16353,
    "start_time": "2022-05-29T16:22:12.986Z"
   },
   {
    "duration": 929,
    "start_time": "2022-05-29T16:22:31.809Z"
   },
   {
    "duration": 44487,
    "start_time": "2022-05-29T16:22:34.941Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T16:23:22.821Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T16:23:25.521Z"
   },
   {
    "duration": 143,
    "start_time": "2022-05-29T16:23:28.547Z"
   },
   {
    "duration": 76,
    "start_time": "2022-05-29T16:23:34.780Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-29T16:23:49.082Z"
   },
   {
    "duration": 127,
    "start_time": "2022-05-29T16:23:49.989Z"
   },
   {
    "duration": 155,
    "start_time": "2022-05-29T16:23:55.380Z"
   },
   {
    "duration": 158,
    "start_time": "2022-05-29T16:23:57.877Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T16:24:06.646Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-29T16:24:13.022Z"
   },
   {
    "duration": 16219,
    "start_time": "2022-05-29T16:24:19.855Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-29T16:24:36.079Z"
   },
   {
    "duration": 21388,
    "start_time": "2022-05-29T16:25:09.256Z"
   },
   {
    "duration": 62165,
    "start_time": "2022-05-29T16:26:09.065Z"
   },
   {
    "duration": 497,
    "start_time": "2022-05-29T16:54:07.954Z"
   },
   {
    "duration": 30,
    "start_time": "2022-05-29T17:04:56.506Z"
   },
   {
    "duration": 197522,
    "start_time": "2022-05-29T17:05:08.502Z"
   },
   {
    "duration": 44890,
    "start_time": "2022-05-29T17:08:45.729Z"
   },
   {
    "duration": 34379,
    "start_time": "2022-05-29T17:10:20.613Z"
   },
   {
    "duration": 53657,
    "start_time": "2022-05-29T17:12:27.831Z"
   },
   {
    "duration": 577837,
    "start_time": "2022-05-29T17:16:46.808Z"
   },
   {
    "duration": 961,
    "start_time": "2022-05-29T17:26:56.483Z"
   },
   {
    "duration": 716724,
    "start_time": "2022-05-29T17:27:18.602Z"
   },
   {
    "duration": 50499,
    "start_time": "2022-05-29T17:40:12.844Z"
   },
   {
    "duration": 760,
    "start_time": "2022-05-29T17:42:19.622Z"
   },
   {
    "duration": 4703,
    "start_time": "2022-05-29T17:42:45.544Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T17:42:50.249Z"
   },
   {
    "duration": 832,
    "start_time": "2022-05-29T17:42:50.256Z"
   },
   {
    "duration": 84,
    "start_time": "2022-05-29T17:42:51.090Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T17:42:51.176Z"
   },
   {
    "duration": 77,
    "start_time": "2022-05-29T17:42:51.182Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-29T17:42:51.263Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-29T17:42:51.274Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-29T17:42:51.293Z"
   },
   {
    "duration": 8971,
    "start_time": "2022-05-29T17:42:51.301Z"
   },
   {
    "duration": 208496,
    "start_time": "2022-05-29T17:43:00.274Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-29T17:46:28.771Z"
   },
   {
    "duration": 787,
    "start_time": "2022-05-29T17:46:28.789Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T17:46:29.579Z"
   },
   {
    "duration": 1436,
    "start_time": "2022-05-29T17:46:29.585Z"
   },
   {
    "duration": 12631,
    "start_time": "2022-05-29T17:46:31.022Z"
   },
   {
    "duration": 616,
    "start_time": "2022-05-29T17:46:43.654Z"
   },
   {
    "duration": 36099,
    "start_time": "2022-05-29T17:46:44.272Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-29T17:47:20.373Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-29T17:47:20.377Z"
   },
   {
    "duration": 93,
    "start_time": "2022-05-29T17:47:20.387Z"
   },
   {
    "duration": 66,
    "start_time": "2022-05-29T17:47:20.482Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T17:47:20.560Z"
   },
   {
    "duration": 127,
    "start_time": "2022-05-29T17:47:20.566Z"
   },
   {
    "duration": 130,
    "start_time": "2022-05-29T17:47:20.695Z"
   },
   {
    "duration": 113,
    "start_time": "2022-05-29T17:47:20.827Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T17:47:20.942Z"
   },
   {
    "duration": 26,
    "start_time": "2022-05-29T17:47:20.948Z"
   },
   {
    "duration": 51810,
    "start_time": "2022-05-29T17:47:20.975Z"
   },
   {
    "duration": 775,
    "start_time": "2022-05-29T17:48:12.787Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-29T17:48:13.563Z"
   },
   {
    "duration": 17326,
    "start_time": "2022-05-29T17:48:13.575Z"
   },
   {
    "duration": 48888,
    "start_time": "2022-05-29T17:48:30.903Z"
   },
   {
    "duration": 87613,
    "start_time": "2022-05-29T17:49:19.793Z"
   },
   {
    "duration": 413480,
    "start_time": "2022-05-29T17:50:47.408Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T17:57:40.890Z"
   },
   {
    "duration": 263,
    "start_time": "2022-05-29T17:57:40.898Z"
   },
   {
    "duration": 139906,
    "start_time": "2022-05-29T17:57:41.163Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T18:00:01.071Z"
   },
   {
    "duration": 40,
    "start_time": "2022-05-29T18:00:01.078Z"
   },
   {
    "duration": 312076,
    "start_time": "2022-05-29T18:00:01.124Z"
   },
   {
    "duration": 190579,
    "start_time": "2022-05-29T18:06:00.541Z"
   },
   {
    "duration": 173653,
    "start_time": "2022-05-29T18:09:38.966Z"
   },
   {
    "duration": 363499,
    "start_time": "2022-05-29T18:13:16.985Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T18:19:20.486Z"
   },
   {
    "duration": 218,
    "start_time": "2022-05-29T18:19:43.094Z"
   },
   {
    "duration": 89924,
    "start_time": "2022-05-29T18:19:47.485Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T18:21:50.665Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-29T18:23:09.446Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-29T18:23:57.012Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-29T18:24:39.425Z"
   },
   {
    "duration": 13879,
    "start_time": "2022-05-30T09:26:58.406Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-30T09:27:12.287Z"
   },
   {
    "duration": 3233,
    "start_time": "2022-05-30T09:27:12.295Z"
   },
   {
    "duration": 94,
    "start_time": "2022-05-30T09:27:15.529Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-30T09:27:15.626Z"
   },
   {
    "duration": 85,
    "start_time": "2022-05-30T09:27:15.632Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-30T09:27:15.721Z"
   },
   {
    "duration": 28,
    "start_time": "2022-05-30T09:27:15.732Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-30T09:27:15.762Z"
   },
   {
    "duration": 17002,
    "start_time": "2022-05-30T09:27:15.784Z"
   },
   {
    "duration": 239998,
    "start_time": "2022-05-30T09:27:32.789Z"
   },
   {
    "duration": 22,
    "start_time": "2022-05-30T09:31:32.789Z"
   },
   {
    "duration": 897,
    "start_time": "2022-05-30T09:31:32.813Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-30T09:31:33.714Z"
   },
   {
    "duration": 1632,
    "start_time": "2022-05-30T09:31:33.721Z"
   },
   {
    "duration": 14686,
    "start_time": "2022-05-30T09:31:35.355Z"
   },
   {
    "duration": 658,
    "start_time": "2022-05-30T09:31:50.043Z"
   },
   {
    "duration": 44947,
    "start_time": "2022-05-30T09:31:50.703Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T09:32:35.652Z"
   },
   {
    "duration": 44,
    "start_time": "2022-05-30T09:32:35.657Z"
   },
   {
    "duration": 141,
    "start_time": "2022-05-30T09:32:35.703Z"
   },
   {
    "duration": 89,
    "start_time": "2022-05-30T09:32:35.846Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-30T09:32:35.937Z"
   },
   {
    "duration": 208,
    "start_time": "2022-05-30T09:32:35.944Z"
   },
   {
    "duration": 176,
    "start_time": "2022-05-30T09:32:36.154Z"
   },
   {
    "duration": 133,
    "start_time": "2022-05-30T09:32:36.331Z"
   },
   {
    "duration": 25,
    "start_time": "2022-05-30T09:32:36.466Z"
   },
   {
    "duration": 54,
    "start_time": "2022-05-30T09:32:36.499Z"
   },
   {
    "duration": 59764,
    "start_time": "2022-05-30T09:32:36.555Z"
   },
   {
    "duration": 925,
    "start_time": "2022-05-30T09:33:36.321Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-30T09:33:37.249Z"
   },
   {
    "duration": 21281,
    "start_time": "2022-05-30T09:33:37.263Z"
   },
   {
    "duration": 56956,
    "start_time": "2022-05-30T09:33:58.546Z"
   },
   {
    "duration": 193052,
    "start_time": "2022-05-30T09:34:55.503Z"
   },
   {
    "duration": 680286,
    "start_time": "2022-05-30T09:38:08.557Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-30T09:49:28.844Z"
   },
   {
    "duration": 264,
    "start_time": "2022-05-30T09:49:28.852Z"
   },
   {
    "duration": 244806,
    "start_time": "2022-05-30T09:49:29.120Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-30T09:53:33.928Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-30T09:53:33.990Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
