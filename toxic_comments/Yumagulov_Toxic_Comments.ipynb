{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» c BERT (и без BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import roc_curve \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from nltk.corpus import stopwords as nltk_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Константы\n",
    "RS = 12345 # random state\n",
    "TS = .25 # test size\n",
    "FR_DOWNSAMPLE = 0.1 # fraction downsample\n",
    "FR_DOWNSAMPLE_CLASS = 0.1 # fraction downsample for class\n",
    "MAX_WORDS = 100 # maximum words in sentences\n",
    "CRIT_F1 = .75\n",
    "MXL = 50 # max lenght BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  toxic\n",
       "6        COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "12  Hey... what is it..\\n@ | talk .\\nWhat is it......      1\n",
       "16  Bye! \\n\\nDon't look, come or think of comming ...      1\n",
       "42  You are gay or antisemmitian? \\n\\nArchangel WH...      1\n",
       "43           FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.101679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.302226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic\n",
       "count  159571.000000\n",
       "mean        0.101679\n",
       "std         0.302226\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_comm = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "df_comm.info()\n",
    "display(df_comm.head())\n",
    "display(df_comm.query('toxic==1').head()) # А что насчет токсичных комментов?\n",
    "display(df_comm.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер комментариев (в символах): 6 - 5000\n",
      "Количество токсичных комментариев 16225 из общего числа 159571 (10.17%)\n"
     ]
    }
   ],
   "source": [
    "df_comm['len'] = df_comm['text'].apply(len)\n",
    "print('Размер комментариев (в символах):', df_comm['len'].min(),'-',df_comm['len'].max())\n",
    "df_comm = df_comm.drop('len', axis=1)\n",
    "cnt = df_comm[df_comm['toxic']==1]['toxic'].count()\n",
    "all = df_comm.shape[0]\n",
    "print(f'Количество токсичных комментариев {cnt} из общего числа {all} ({np.round(100 * cnt / all, 2)}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Надо сбалансировать классы - т.к. мы предсказываем токсичность, то уменьшим количество нетоксичных комментов в выборке\n",
    "\n",
    "def downsample(df_in, ftr, trg, fraction):\n",
    "    features_zeros = df_in[df_in[trg] == 0][ftr]\n",
    "    features_ones = df_in[df_in[trg] == 1][ftr]\n",
    "    target_zeros = df_in[df_in[trg] == 0][trg]\n",
    "    target_ones = df_in[df_in[trg] == 1][trg]\n",
    "\n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=RS)] + [features_ones]) \n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=RS)] + [target_ones]) \n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=RS)\n",
    "    \n",
    "    df_out = pd.DataFrame()\n",
    "    df_out[ftr] = features_downsampled\n",
    "    df_out[trg] = target_downsampled\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер выборки ДО: (159571, 2)\n",
      "Размер выборки ПОСЛЕ: (30560, 2)\n"
     ]
    }
   ],
   "source": [
    "# Удаляем нетоксичные комментарии\n",
    "print('Размер выборки ДО:', df_comm.shape)\n",
    "\n",
    "df_comm = downsample(df_in=df_comm, ftr='text', trg='toxic', fraction=FR_DOWNSAMPLE_CLASS)\n",
    "\n",
    "print('Размер выборки ПОСЛЕ:',df_comm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мы удалили 10% нетоксичных комментариев. Проверяем что получилось:\n",
      "Количество токсичных комментариев 16225 из общего числа 30560 (53.0%)\n",
      "Выборка сбалансирована!\n"
     ]
    }
   ],
   "source": [
    "print(f'Мы удалили {round(FR_DOWNSAMPLE_CLASS*100)}% нетоксичных комментариев. Проверяем что получилось:')\n",
    "cnt = df_comm[df_comm['toxic']==1]['toxic'].count()\n",
    "all = df_comm.shape[0]\n",
    "prc = np.round(100 * cnt / all, 0)\n",
    "print(f'Количество токсичных комментариев {cnt} из общего числа {all} ({prc}%)')\n",
    "ppp = int(np.round(prc / 10, 0))\n",
    "if ppp == 5:\n",
    "    print('Выборка сбалансирована!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для исследования берем 10% от сбалансированной выборки.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3056 entries, 0 to 3055\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    3056 non-null   object\n",
      " 1   toxic   3056 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 47.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Сначала потренируемся на малом объеме данных\n",
    "print(f'Для исследования берем {round(FR_DOWNSAMPLE*100)}% от сбалансированной выборки.')\n",
    "df_comm = df_comm.sample(frac=FR_DOWNSAMPLE, random_state=RS).reset_index(drop=True)\n",
    "df_comm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверим как изменился % токсичных комментарив после уменьшения выборки:\n",
      "Количество токсичных комментариев 1624 из общего числа 3056 (53.14%)\n",
      "Выборка сбалансирована!\n"
     ]
    }
   ],
   "source": [
    "print('Проверим как изменился % токсичных комментарив после уменьшения выборки:')\n",
    "cnt = df_comm[df_comm['toxic']==1]['toxic'].count()\n",
    "all = df_comm.shape[0]\n",
    "print(f'Количество токсичных комментариев {cnt} из общего числа {all} ({np.round(100 * cnt / all, 2)}%)')\n",
    "ppp = int(np.round(prc / 10, 0))\n",
    "if ppp == 5:\n",
    "    print('Выборка сбалансирована!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вариант с BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 5.25 µs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5965da24f8844cd8bd3f57c3c65779d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155ecb2373954622b2732767a8091b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068abc44ef8d41ca924b7d4a9a6bf206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fb0002ffdf4b3296731a5c3fabd94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb601a1112df49be90c98c9aa5023c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "#tokenizer = transformers.BertTokenizer(vocab_file='/datasets/ds_bert/vocab.txt')\n",
    "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "tokenized = df_comm['text'].apply(lambda x: tokenizer.encode(x, truncation=True, max_length=MXL, add_special_tokens=True))\n",
    "\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values]) \n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "#config = transformers.BertConfig.from_json_file('/datasets/ds_bert/bert_config.json')\n",
    "#model = transformers.BertModel.from_pretrained('/datasets/ds_bert/rubert_model.bin', config=config)\n",
    "model = transformers.DistilBertModel.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 8.11 µs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee1e338ce5341f7ba67c0199f515f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 8.11 µs\n",
      "Размер выборки features: 3000\n",
      "Размер выборки target: 3056\n",
      "Что-то пошло не так - куда-то подевалась часть признаков. Отбрасываем лишние таргеты.\n",
      "Размер выборки target (cut): 3000\n",
      "Разделяем выборку на обучающую и тестовую:\n",
      "-- размер обучающей выборки: 2250 признаков и 2250 таргетов\n",
      "-- размер тестовой выборки: 750 признаков и 750 таргетов\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "bert_features = np.concatenate(embeddings)\n",
    "l1 = len(bert_features)\n",
    "print('Размер выборки features:', l1)\n",
    "bert_target = df_comm['toxic']\n",
    "l2 = len(bert_target)\n",
    "print('Размер выборки target:', l2)\n",
    "\n",
    "if l1 < l2:\n",
    "    print('Что-то пошло не так - куда-то подевалась часть признаков. Отбрасываем лишние таргеты.')\n",
    "    bert_target = bert_target[:l1]\n",
    "    print('Размер выборки target (cut):',len(bert_target))\n",
    "elif l1 > l2:\n",
    "    print('Что-то пошло не так - куда-то подевалась часть таргетов. Отбрасываем лишние признаки.')\n",
    "    bert_features = bert_features[:l2]\n",
    "    print('Размер выборки features target (cut):',len(bert_features))\n",
    "\n",
    "print('Разделяем выборку на обучающую и тестовую:')\n",
    "bert_features_train, bert_features_test, bert_target_train, bert_target_test = train_test_split(bert_features, bert_target, test_size=0.25, random_state=RS)\n",
    "print('-- размер обучающей выборки:', bert_features_train.shape[0], 'признаков и', len(bert_target_train), 'таргетов')\n",
    "print('-- размер тестовой выборки:', bert_features_test.shape[0], 'признаков и', len(bert_target_test), 'таргетов')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вариант без BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверяем работу Mystem (с POS):\n",
      "Исходная фраза: The striped bats are hanging on their feet for best\n",
      "Лемматизированная Mystem: The striped bats are hanging on their feet for best\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def lemmatize_m(text):\n",
    "    m = Mystem()\n",
    "    lemm_list = m.lemmatize(text)\n",
    "    lemm_text = \"\".join(lemm_list)\n",
    "    return lemm_text\n",
    "\n",
    "ttt = \"The striped bats are hanging on their feet for best\"\n",
    "print('Проверяем работу Mystem (с POS):')\n",
    "print('Исходная фраза:', ttt)\n",
    "print('Лемматизированная Mystem:', lemmatize_m(ttt))\n",
    "\n",
    "def clear_text_eng(text):\n",
    "    clear_text = re.sub(r'[^a-zA-Z ]', ' ', text) \n",
    "    clear_text = \" \".join(clear_text.split())\n",
    "    return clear_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:\n",
    "Mystem не подходит для лемматизации английских текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверяем работу nltk (с POS):\n",
      "Исходная фраза: The striped bats are hanging on their feet for best\n",
      "Лемматизированная nltk (с POS): The strip bat be hang on their foot for best\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_eng_nltk(sentence):\n",
    "    word_list = nltk.word_tokenize(sentence)\n",
    "# ограничиваем максимум анализируемых слов в комментарии      \n",
    "    l = MAX_WORDS\n",
    "    if len(word_list)<MAX_WORDS:\n",
    "        l = len(word_list)\n",
    "    word_list = word_list[:l] \n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in word_list])\n",
    "#    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    return lemmatized_output\n",
    "\n",
    "print('Проверяем работу nltk (с POS):')\n",
    "print('Исходная фраза:', ttt)\n",
    "print('Лемматизированная nltk (с POS):', lemmatize_eng_nltk(ttt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 7.15 µs\n",
      "Очищаем комментарии...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liar \\n\\nThis guy is such a thief and a liar! ...</td>\n",
       "      <td>1</td>\n",
       "      <td>liar This guy is such a thief and a liar He sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"\\n\\nOf course, of course, Pharos, I am famili...</td>\n",
       "      <td>0</td>\n",
       "      <td>Of course of course Pharos I am familiar with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My Thoughts \\n\\nYou're a jackass.\\n\\nDoes this...</td>\n",
       "      <td>1</td>\n",
       "      <td>My Thoughts You re a jackass Does this look fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>. I should become a detective for figuring all...</td>\n",
       "      <td>1</td>\n",
       "      <td>I should become a detective for figuring all t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GIMME GIMME \\n\\nI wanted all of you BASTARDS t...</td>\n",
       "      <td>1</td>\n",
       "      <td>GIMME GIMME I wanted all of you BASTARDS to kn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  liar \\n\\nThis guy is such a thief and a liar! ...      1   \n",
       "1  \"\\n\\nOf course, of course, Pharos, I am famili...      0   \n",
       "2  My Thoughts \\n\\nYou're a jackass.\\n\\nDoes this...      1   \n",
       "3  . I should become a detective for figuring all...      1   \n",
       "4  GIMME GIMME \\n\\nI wanted all of you BASTARDS t...      1   \n",
       "\n",
       "                                          clear_text  \n",
       "0  liar This guy is such a thief and a liar He sh...  \n",
       "1  Of course of course Pharos I am familiar with ...  \n",
       "2  My Thoughts You re a jackass Does this look fa...  \n",
       "3  I should become a detective for figuring all t...  \n",
       "4  GIMME GIMME I wanted all of you BASTARDS to kn...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лемматизируем комментарии с nltk...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "      <th>nltk_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liar \\n\\nThis guy is such a thief and a liar! ...</td>\n",
       "      <td>1</td>\n",
       "      <td>liar This guy is such a thief and a liar He sh...</td>\n",
       "      <td>liar This guy be such a thief and a liar He sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"\\n\\nOf course, of course, Pharos, I am famili...</td>\n",
       "      <td>0</td>\n",
       "      <td>Of course of course Pharos I am familiar with ...</td>\n",
       "      <td>Of course of course Pharos I be familiar with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My Thoughts \\n\\nYou're a jackass.\\n\\nDoes this...</td>\n",
       "      <td>1</td>\n",
       "      <td>My Thoughts You re a jackass Does this look fa...</td>\n",
       "      <td>My Thoughts You re a jackass Does this look fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>. I should become a detective for figuring all...</td>\n",
       "      <td>1</td>\n",
       "      <td>I should become a detective for figuring all t...</td>\n",
       "      <td>I should become a detective for figure all tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GIMME GIMME \\n\\nI wanted all of you BASTARDS t...</td>\n",
       "      <td>1</td>\n",
       "      <td>GIMME GIMME I wanted all of you BASTARDS to kn...</td>\n",
       "      <td>GIM ME GIM ME I want all of you BASTARDS to kn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  liar \\n\\nThis guy is such a thief and a liar! ...      1   \n",
       "1  \"\\n\\nOf course, of course, Pharos, I am famili...      0   \n",
       "2  My Thoughts \\n\\nYou're a jackass.\\n\\nDoes this...      1   \n",
       "3  . I should become a detective for figuring all...      1   \n",
       "4  GIMME GIMME \\n\\nI wanted all of you BASTARDS t...      1   \n",
       "\n",
       "                                          clear_text  \\\n",
       "0  liar This guy is such a thief and a liar He sh...   \n",
       "1  Of course of course Pharos I am familiar with ...   \n",
       "2  My Thoughts You re a jackass Does this look fa...   \n",
       "3  I should become a detective for figuring all t...   \n",
       "4  GIMME GIMME I wanted all of you BASTARDS to kn...   \n",
       "\n",
       "                                           nltk_text  \n",
       "0  liar This guy be such a thief and a liar He sh...  \n",
       "1  Of course of course Pharos I be familiar with ...  \n",
       "2  My Thoughts You re a jackass Does this look fa...  \n",
       "3  I should become a detective for figure all tha...  \n",
       "4  GIM ME GIM ME I want all of you BASTARDS to kn...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "print('Очищаем комментарии...')\n",
    "df_comm['clear_text'] = df_comm['text'].apply(clear_text_eng)\n",
    "display(df_comm.head())\n",
    "print('Лемматизируем комментарии с nltk...')\n",
    "df_comm['nltk_text'] = df_comm['clear_text'].apply(lemmatize_eng_nltk)\n",
    "display(df_comm.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.72 µs\n",
      "Проверяем работу spacy:\n",
      "Исходная фраза: The striped bats are hanging on their feet for best\n",
      "Лемматизированная spacy: the stripe bat be hang on their foot for good\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemmatize_eng_spacy(sentence):\n",
    "    doc = nlp(sentence)\n",
    "# ограничиваем максимум анализируемых слов в комментарии    \n",
    "    l = MAX_WORDS\n",
    "    if len(doc)<MAX_WORDS:\n",
    "        l = len(doc)\n",
    "    doc = doc[0:l]\n",
    "    txt = \" \".join([token.lemma_ for token in doc])\n",
    "    return txt\n",
    "\n",
    "print('Проверяем работу spacy:')\n",
    "print('Исходная фраза:', ttt)\n",
    "print('Лемматизированная spacy:', lemmatize_eng_spacy(ttt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.48 µs\n",
      "Лемматизируем комментарии со spacy...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "      <th>nltk_text</th>\n",
       "      <th>spacy_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liar \\n\\nThis guy is such a thief and a liar! ...</td>\n",
       "      <td>1</td>\n",
       "      <td>liar This guy is such a thief and a liar He sh...</td>\n",
       "      <td>liar This guy be such a thief and a liar He sh...</td>\n",
       "      <td>liar this guy be such a thief and a liar he sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"\\n\\nOf course, of course, Pharos, I am famili...</td>\n",
       "      <td>0</td>\n",
       "      <td>Of course of course Pharos I am familiar with ...</td>\n",
       "      <td>Of course of course Pharos I be familiar with ...</td>\n",
       "      <td>of course of course Pharos I be familiar with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My Thoughts \\n\\nYou're a jackass.\\n\\nDoes this...</td>\n",
       "      <td>1</td>\n",
       "      <td>My Thoughts You re a jackass Does this look fa...</td>\n",
       "      <td>My Thoughts You re a jackass Does this look fa...</td>\n",
       "      <td>my thought you re a jackass do this look famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>. I should become a detective for figuring all...</td>\n",
       "      <td>1</td>\n",
       "      <td>I should become a detective for figuring all t...</td>\n",
       "      <td>I should become a detective for figure all tha...</td>\n",
       "      <td>I should become a detective for figure all tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GIMME GIMME \\n\\nI wanted all of you BASTARDS t...</td>\n",
       "      <td>1</td>\n",
       "      <td>GIMME GIMME I wanted all of you BASTARDS to kn...</td>\n",
       "      <td>GIM ME GIM ME I want all of you BASTARDS to kn...</td>\n",
       "      <td>GIMME GIMME I want all of you bastards to know...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  liar \\n\\nThis guy is such a thief and a liar! ...      1   \n",
       "1  \"\\n\\nOf course, of course, Pharos, I am famili...      0   \n",
       "2  My Thoughts \\n\\nYou're a jackass.\\n\\nDoes this...      1   \n",
       "3  . I should become a detective for figuring all...      1   \n",
       "4  GIMME GIMME \\n\\nI wanted all of you BASTARDS t...      1   \n",
       "\n",
       "                                          clear_text  \\\n",
       "0  liar This guy is such a thief and a liar He sh...   \n",
       "1  Of course of course Pharos I am familiar with ...   \n",
       "2  My Thoughts You re a jackass Does this look fa...   \n",
       "3  I should become a detective for figuring all t...   \n",
       "4  GIMME GIMME I wanted all of you BASTARDS to kn...   \n",
       "\n",
       "                                           nltk_text  \\\n",
       "0  liar This guy be such a thief and a liar He sh...   \n",
       "1  Of course of course Pharos I be familiar with ...   \n",
       "2  My Thoughts You re a jackass Does this look fa...   \n",
       "3  I should become a detective for figure all tha...   \n",
       "4  GIM ME GIM ME I want all of you BASTARDS to kn...   \n",
       "\n",
       "                                          spacy_text  \n",
       "0  liar this guy be such a thief and a liar he sh...  \n",
       "1  of course of course Pharos I be familiar with ...  \n",
       "2  my thought you re a jackass do this look famil...  \n",
       "3  I should become a detective for figure all tha...  \n",
       "4  GIMME GIMME I want all of you bastards to know...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "print('Лемматизируем комментарии со spacy...')\n",
    "df_comm['spacy_text'] = df_comm['clear_text'].apply(lemmatize_eng_spacy)\n",
    "display(df_comm.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cначала детально пройдемся по spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сначала детально пройдемся по spacy\n",
    "#spacy_text = df_comm['spacy_text'].values.astype('U')\n",
    "spacy_text = df_comm['spacy_text']\n",
    "target = df_comm['toxic']\n",
    "\n",
    "spacy_text_train, spacy_text_test, target_spacy_train, target_spacy_test = train_test_split(spacy_text, target, test_size=TS, random_state=RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "features_spacy_train = count_tf_idf.fit_transform(spacy_text_train) \n",
    "features_spacy_test = count_tf_idf.transform(spacy_text_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 5.01 µs\n",
      "accuracy_score: 0.8573298429319371\n",
      "f1_score: 0.8556291390728478\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "#solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "#class_weight='balanced'\n",
    "model_spacy = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=100, class_weight=None, random_state=RS, C=10) #т.к. классы несбалансированы\n",
    "model_spacy.fit(features_spacy_train, target_spacy_train)\n",
    "\n",
    "pred_spacy = model_spacy.predict(features_spacy_test)\n",
    "print('accuracy_score:', accuracy_score(target_spacy_test, pred_spacy))\n",
    "print('f1_score:', f1_score(target_spacy_test, pred_spacy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примечание:\n",
    "А до балансировки классов (с class_weight='balanced') было:\n",
    "* accuracy_score: 0.93\n",
    "* f1_score: 0.46153846153846156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вероятности отрицательного и положительного (токсичного) результатов:\n",
      "[[5.84335411e-03 9.94156646e-01]\n",
      " [3.79641201e-02 9.62035880e-01]\n",
      " [9.43205982e-01 5.67940181e-02]\n",
      " [7.79041883e-01 2.20958117e-01]\n",
      " [1.19164024e-01 8.80835976e-01]\n",
      " [6.65080774e-01 3.34919226e-01]\n",
      " [9.23100412e-01 7.68995877e-02]\n",
      " [3.92439071e-01 6.07560929e-01]\n",
      " [3.15027922e-02 9.68497208e-01]\n",
      " [9.67038992e-04 9.99032961e-01]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = model_spacy.predict_proba(features_spacy_test) \n",
    "print('Вероятности отрицательного и положительного (токсичного) результатов:')\n",
    "print(probabilities[:10])  \n",
    "\n",
    "probabilities_one = probabilities[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.00 | Точность = 0.492, Полнота = 1.000\n",
      "Порог = 0.02 | Точность = 0.512, Полнота = 0.997\n",
      "Порог = 0.04 | Точность = 0.528, Полнота = 0.997\n",
      "Порог = 0.06 | Точность = 0.543, Полнота = 0.992\n",
      "Порог = 0.08 | Точность = 0.555, Полнота = 0.992\n",
      "Порог = 0.10 | Точность = 0.566, Полнота = 0.984\n",
      "Порог = 0.12 | Точность = 0.585, Полнота = 0.984\n",
      "Порог = 0.14 | Точность = 0.596, Полнота = 0.979\n",
      "Порог = 0.16 | Точность = 0.607, Полнота = 0.976\n",
      "Порог = 0.18 | Точность = 0.627, Полнота = 0.973\n",
      "Порог = 0.20 | Точность = 0.637, Полнота = 0.960\n",
      "Порог = 0.22 | Точность = 0.661, Полнота = 0.957\n",
      "Порог = 0.24 | Точность = 0.682, Полнота = 0.952\n",
      "Порог = 0.26 | Точность = 0.700, Полнота = 0.949\n",
      "Порог = 0.28 | Точность = 0.717, Полнота = 0.939\n",
      "Порог = 0.30 | Точность = 0.726, Полнота = 0.931\n",
      "Порог = 0.32 | Точность = 0.748, Полнота = 0.918\n",
      "Порог = 0.34 | Точность = 0.759, Полнота = 0.907\n",
      "Порог = 0.36 | Точность = 0.778, Полнота = 0.902\n",
      "Порог = 0.38 | Точность = 0.791, Полнота = 0.888\n",
      "Порог = 0.40 | Точность = 0.799, Полнота = 0.886\n",
      "Порог = 0.42 | Точность = 0.801, Полнота = 0.878\n",
      "Порог = 0.44 | Точность = 0.810, Полнота = 0.872\n",
      "Порог = 0.46 | Точность = 0.822, Полнота = 0.870\n",
      "Порог = 0.48 | Точность = 0.835, Полнота = 0.862\n",
      "Порог = 0.50 | Точность = 0.852, Полнота = 0.859\n",
      "Порог = 0.52 | Точность = 0.854, Полнота = 0.840\n",
      "Порог = 0.54 | Точность = 0.865, Полнота = 0.832\n",
      "Порог = 0.56 | Точность = 0.882, Полнота = 0.816\n",
      "Порог = 0.58 | Точность = 0.885, Полнота = 0.798\n",
      "Порог = 0.60 | Точность = 0.892, Полнота = 0.787\n",
      "Порог = 0.62 | Точность = 0.899, Полнота = 0.782\n",
      "Порог = 0.64 | Точность = 0.905, Полнота = 0.763\n",
      "Порог = 0.66 | Точность = 0.916, Полнота = 0.750\n",
      "Порог = 0.68 | Точность = 0.922, Полнота = 0.726\n",
      "Порог = 0.70 | Точность = 0.927, Полнота = 0.707\n",
      "Порог = 0.72 | Точность = 0.946, Полнота = 0.697\n",
      "Порог = 0.74 | Точность = 0.955, Полнота = 0.673\n",
      "Порог = 0.76 | Точность = 0.957, Полнота = 0.657\n",
      "Порог = 0.78 | Точность = 0.955, Полнота = 0.628\n",
      "Порог = 0.80 | Точность = 0.961, Полнота = 0.593\n",
      "Порог = 0.82 | Точность = 0.963, Полнота = 0.559\n",
      "Порог = 0.84 | Точность = 0.961, Полнота = 0.527\n",
      "Порог = 0.86 | Точность = 0.959, Полнота = 0.503\n",
      "Порог = 0.88 | Точность = 0.962, Полнота = 0.476\n",
      "Порог = 0.90 | Точность = 0.971, Полнота = 0.452\n",
      "Порог = 0.92 | Точность = 0.987, Полнота = 0.410\n",
      "Порог = 0.94 | Точность = 0.986, Полнота = 0.378\n",
      "Порог = 0.96 | Точность = 0.992, Полнота = 0.316\n",
      "Порог = 0.98 | Точность = 1.000, Полнота = 0.258\n"
     ]
    }
   ],
   "source": [
    "for threshold in np.arange(0, 1, 0.02):\n",
    "    predicted_test = probabilities_one > threshold \n",
    "    precision = precision_score(target_spacy_test, predicted_test)\n",
    "    recall = recall_score(target_spacy_test, predicted_test)\n",
    "\n",
    "    print(\"Порог = {:.2f} | Точность = {:.3f}, Полнота = {:.3f}\".format(\n",
    "        threshold, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(target_spacy_test, probabilities_one)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.step(recall, precision, where='post')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Кривая Precision-Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(target_spacy_test, probabilities_one) \n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-кривая')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка в численном виде: 0.9228380675586751\n"
     ]
    }
   ],
   "source": [
    "auc_roc = roc_auc_score(target_spacy_test, probabilities_one) \n",
    "print('Оценка в численном виде:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примечание:\n",
    "А до балансировки классов (с class_weight='balanced') было: 0.8056120965396918"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Воочию посмотрим как совпадают с истиной результаты предсказаний:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>toxic</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>MuZemike also MuZemike be a dirty little faggo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>hey why the fuck do you have your talk page se...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>please take your request for assistance in edi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Cleanup POV I clean up the article a little bi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>again not half jokingly how do I remove the pi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>y u remuv my post AGANE EY you NIGGUR I say I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>no source no evidence this be anything save Or...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>Dingley just to put you in the picture Trident...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>hi Phill the Shill oh and you know what you ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>Feydey be a complete fucking fag I see that he...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    txt  toxic  pred\n",
       "459   MuZemike also MuZemike be a dirty little faggo...      1     1\n",
       "1667  hey why the fuck do you have your talk page se...      1     1\n",
       "92    please take your request for assistance in edi...      0     0\n",
       "277   Cleanup POV I clean up the article a little bi...      0     0\n",
       "2770  again not half jokingly how do I remove the pi...      1     1\n",
       "2006  y u remuv my post AGANE EY you NIGGUR I say I ...      1     0\n",
       "1720  no source no evidence this be anything save Or...      0     0\n",
       "831   Dingley just to put you in the picture Trident...      1     1\n",
       "1721  hi Phill the Shill oh and you know what you ca...      1     1\n",
       "1554  Feydey be a complete fucking fag I see that he...      1     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "А теперь только токсичные:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>toxic</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>MuZemike also MuZemike be a dirty little faggo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>hey why the fuck do you have your talk page se...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>again not half jokingly how do I remove the pi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>y u remuv my post AGANE EY you NIGGUR I say I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>Dingley just to put you in the picture Trident...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    txt  toxic  pred\n",
       "459   MuZemike also MuZemike be a dirty little faggo...      1     1\n",
       "1667  hey why the fuck do you have your talk page se...      1     1\n",
       "2770  again not half jokingly how do I remove the pi...      1     1\n",
       "2006  y u remuv my post AGANE EY you NIGGUR I say I ...      1     0\n",
       "831   Dingley just to put you in the picture Trident...      1     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Воочию посмотрим как совпадают с истиной результаты предсказаний:')\n",
    "tst = pd.DataFrame()\n",
    "tst['txt'] = spacy_text_test\n",
    "tst['toxic'] = np.array(target_spacy_test)\n",
    "tst['pred'] = pred_spacy\n",
    "display(tst.head(10))\n",
    "print('А теперь только токсичные:')\n",
    "display(tst.query('toxic==1').head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы:\n",
    "1. Осталась довольно большая доля ложно-отрицательных (FN) предсказаний. Часть токсичных комментариев не будет распознана."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь сделаем обзор по всем остальным вариантам представления текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для модели LogisticRegression определенные GridSearchCV: {'C': 10, 'class_weight': None, 'max_iter': 50, 'penalty': 'l2', 'solver': 'saga'}\n",
      "CPU times: user 59.3 s, sys: 367 ms, total: 59.7 s\n",
      "Wall time: 59.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {'max_iter': [50, 100, 200],\n",
    "          'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
    "          'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "          'class_weight': [None, 'balanced'], \n",
    "          'C': [1, 10]}\n",
    "\n",
    "lr = LogisticRegression(multi_class='auto', random_state=RS)\n",
    "lr_model = GridSearchCV(lr, params, scoring='f1', cv=5)\n",
    "lr_model.fit(features_spacy_train, target_spacy_train)\n",
    "\n",
    "print(\"Лучшие параметры для модели LogisticRegression определенные GridSearchCV:\", lr_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.48 µs\n",
      "Исследуем модель LogisticRegression на значениях столбца: clear_text\n",
      "-- модель обучена\n",
      "-- есть предсказания\n",
      "-- accuracy_score: 0.8377\n",
      "-- f1_score: 0.8342\n",
      "\n",
      "Исследуем модель LogisticRegression на значениях столбца: nltk_text\n",
      "-- модель обучена\n",
      "-- есть предсказания\n",
      "-- accuracy_score: 0.839\n",
      "-- f1_score: 0.8367\n",
      "\n",
      "Исследуем модель LogisticRegression на значениях столбца: spacy_text\n",
      "-- модель обучена\n",
      "-- есть предсказания\n",
      "-- accuracy_score: 0.8586\n",
      "-- f1_score: 0.8568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "# пройдемся по всем типам текстов\n",
    "\n",
    "text_type = ['clear', 'nltk', 'spacy']\n",
    "res = []\n",
    "\n",
    "for iii in range(len(text_type)):\n",
    "    exam_clmn = '{}_text'.format(text_type[iii])\n",
    "    print('Исследуем модель LogisticRegression на значениях столбца:', exam_clmn)\n",
    "    exam_text = df_comm[exam_clmn].values.astype('U')\n",
    "    target = df_comm['toxic']\n",
    "\n",
    "    text_train, text_test, target_train, target_test = train_test_split(exam_text, target, test_size=TS, random_state=RS)\n",
    "\n",
    "    features_train = count_tf_idf.fit_transform(text_train) \n",
    "    features_test = count_tf_idf.transform(text_test) \n",
    "    \n",
    "    model_exam = LogisticRegression(multi_class='auto', solver='saga', penalty='l2', max_iter=50, class_weight=None, random_state=RS, C=10) #т.к. классы несбалансированы\n",
    "    model_exam.fit(features_train, target_train)\n",
    "    print('-- модель обучена')\n",
    "    \n",
    "    pred = model_exam.predict(features_test)\n",
    "    print('-- есть предсказания')\n",
    "    \n",
    "    acc = np.round(accuracy_score(target_test, pred), 4)\n",
    "    f1 = np.round(f1_score(target_test, pred), 4)\n",
    "    print('-- accuracy_score:', acc)\n",
    "    print('-- f1_score:', f1)\n",
    "    res.append({'Тип текста': text_type[iii], \n",
    "                'accuracy_score': acc,\n",
    "                'f1_score': f1}) \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Тип текста</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clear</td>\n",
       "      <td>0.8377</td>\n",
       "      <td>0.8342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nltk</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>0.8367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spacy</td>\n",
       "      <td>0.8586</td>\n",
       "      <td>0.8568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Тип текста  accuracy_score  f1_score\n",
       "0      clear          0.8377    0.8342\n",
       "1       nltk          0.8390    0.8367\n",
       "2      spacy          0.8586    0.8568"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = pd.DataFrame(res)\n",
    "display(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы:\n",
    "1. <s>NLTK дал самый лучший результат.</s> Результат нестабилен - в этот раз лучший результат у spacy.\n",
    "2. Лемматизация дает незначительный прирост качества модели по сравнению с очищенным текстом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение\n",
    "### Вариант с BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.44 µs\n",
      "Сначала наугад протестируем модель CatBoostClassifier (параметры отличаются от тех, что будут использованы далее):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f815907f820>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "print('Сначала наугад протестируем модель CatBoostClassifier (параметры отличаются от тех, что будут использованы далее):')\n",
    "\n",
    "model_cb = CatBoostClassifier(bootstrap_type='MVS', depth=4, grow_policy='Depthwise', iterations=100, learning_rate=0.03, silent=True, random_seed=RS)\n",
    "model_cb.fit(bert_features_train, bert_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 98.9 µs\n",
      "cross_val_score: [0.824 0.84  0.848]\n",
      "accuracy_score: 0.856\n",
      "f1_score: 0.864321608040201\n",
      "{'iterations': 100, 'learning_rate': 0.03, 'depth': 4, 'random_seed': 12345, 'silent': True, 'bootstrap_type': 'MVS', 'grow_policy': 'Depthwise'}\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "pred_cb = model_cb.predict(bert_features_test)\n",
    "print('cross_val_score:', cross_val_score(model_cb, bert_features_test, bert_target_test, cv=3))\n",
    "print('accuracy_score:', accuracy_score(bert_target_test, pred_cb))\n",
    "print('f1_score:', f1_score(bert_target_test, pred_cb))\n",
    "print(model_cb.get_params(deep=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> В предыдущий раз (с RuBERT) было:\n",
    "<li> cross_val_score: [0.756 0.784 0.752]\n",
    "<li> accuracy_score: 0.76\n",
    "<li> f1_score: 0.7721518987341771\n",
    "<div> <b>Результат значительно улучшился! F1=0.864321608040201</b></div>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для модели RandomForestClassifier определенные GridSearchCV: {'max_depth': 10, 'min_samples_leaf': 2, 'n_estimators': 200}\n",
      "CPU times: user 3min 11s, sys: 937 ms, total: 3min 12s\n",
      "Wall time: 3min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {'max_depth': [4, 8, 10],\n",
    "          'n_estimators': range(80, 240, 40),\n",
    "         'min_samples_leaf': [1, 2]}\n",
    "\n",
    "rf = RandomForestClassifier(class_weight=None, random_state=RS)\n",
    "rf_model = GridSearchCV(rf, params, scoring='f1', cv=3)\n",
    "rf_model.fit(bert_features_train, bert_target_train)\n",
    "\n",
    "print(\"Лучшие параметры для модели RandomForestClassifier определенные GridSearchCV:\", rf_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Идут вычисления по модели LogisticRegression: {'C': 10, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 50, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 12345, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.8707\n",
      "-- f1_score: 0.8771\n",
      "\n",
      "Идут вычисления по модели DecisionTreeClassifier: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 12345, 'splitter': 'best'}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.7867\n",
      "-- f1_score: 0.799\n",
      "\n",
      "Идут вычисления по модели RandomForestClassifier: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False, 'random_state': 12345, 'verbose': 0, 'warm_start': False}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.8427\n",
      "-- f1_score: 0.8518\n",
      "\n",
      "Идут вычисления по модели CatBoostClassifier: {'iterations': 200, 'learning_rate': 0.15, 'depth': 16, 'random_seed': 12345, 'silent': True, 'bootstrap_type': 'MVS', 'grow_policy': 'Lossguide'}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.8733\n",
      "-- f1_score: 0.8814\n",
      "\n",
      "Идут вычисления по модели LGBMClassifier: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.848\n",
      "-- f1_score: 0.8579\n",
      "\n",
      "Идут вычисления по модели XGBClassifier: {'objective': 'binary:logistic', 'use_label_encoder': True, 'base_score': None, 'booster': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'enable_categorical': False, 'gamma': None, 'gpu_id': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_delta_step': None, 'max_depth': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': None, 'num_parallel_tree': None, 'predictor': None, 'random_state': None, 'reg_alpha': None, 'reg_lambda': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
      "[09:47:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.8613\n",
      "-- f1_score: 0.869\n",
      "\n",
      "Идут вычисления по модели DummyClassifier: {'constant': None, 'random_state': 12345, 'strategy': 'prior'}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.5293\n",
      "-- f1_score: 0.6922\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>Время_обучения</th>\n",
       "      <th>Время_предсказания</th>\n",
       "      <th>Гиперпараметры</th>\n",
       "      <th>Модель_пригодна</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.8707</td>\n",
       "      <td>0.8771</td>\n",
       "      <td>1.04s</td>\n",
       "      <td>0.01s</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'dual': False,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.7867</td>\n",
       "      <td>0.7990</td>\n",
       "      <td>1.44s</td>\n",
       "      <td>0.0s</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.8427</td>\n",
       "      <td>0.8518</td>\n",
       "      <td>6.81s</td>\n",
       "      <td>0.06s</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.8733</td>\n",
       "      <td>0.8814</td>\n",
       "      <td>145.04s</td>\n",
       "      <td>0.02s</td>\n",
       "      <td>{'iterations': 200, 'learning_rate': 0.15, 'de...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.8480</td>\n",
       "      <td>0.8579</td>\n",
       "      <td>393.2s</td>\n",
       "      <td>0.02s</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.8613</td>\n",
       "      <td>0.8690</td>\n",
       "      <td>132.31s</td>\n",
       "      <td>0.19s</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>0.5293</td>\n",
       "      <td>0.6922</td>\n",
       "      <td>0.0s</td>\n",
       "      <td>0.0s</td>\n",
       "      <td>{'constant': None, 'random_state': 12345, 'str...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Модель  accuracy_score  f1_score Время_обучения  \\\n",
       "0      LogisticRegression          0.8707    0.8771          1.04s   \n",
       "1  DecisionTreeClassifier          0.7867    0.7990          1.44s   \n",
       "2  RandomForestClassifier          0.8427    0.8518          6.81s   \n",
       "3      CatBoostClassifier          0.8733    0.8814        145.04s   \n",
       "4          LGBMClassifier          0.8480    0.8579         393.2s   \n",
       "5           XGBClassifier          0.8613    0.8690        132.31s   \n",
       "6         DummyClassifier          0.5293    0.6922           0.0s   \n",
       "\n",
       "  Время_предсказания                                     Гиперпараметры  \\\n",
       "0              0.01s  {'C': 10, 'class_weight': None, 'dual': False,...   \n",
       "1               0.0s  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...   \n",
       "2              0.06s  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...   \n",
       "3              0.02s  {'iterations': 200, 'learning_rate': 0.15, 'de...   \n",
       "4              0.02s  {'boosting_type': 'gbdt', 'class_weight': None...   \n",
       "5              0.19s  {'objective': 'binary:logistic', 'use_label_en...   \n",
       "6               0.0s  {'constant': None, 'random_state': 12345, 'str...   \n",
       "\n",
       "   Модель_пригодна  \n",
       "0             True  \n",
       "1             True  \n",
       "2             True  \n",
       "3             True  \n",
       "4             True  \n",
       "5             True  \n",
       "6            False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 10s, sys: 5.38 s, total: 11min 16s\n",
      "Wall time: 11min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "models = [LogisticRegression(multi_class='auto', solver='saga', penalty='l2', max_iter=50, class_weight=None, random_state=RS, C=10),          \n",
    "          DecisionTreeClassifier(class_weight=None, max_depth=8, random_state=RS),\n",
    "          RandomForestClassifier(class_weight=None, n_estimators=200, max_depth=10, min_samples_leaf=2, random_state=RS),\n",
    "          CatBoostClassifier(bootstrap_type='MVS', depth=16, grow_policy='Lossguide', iterations=200, learning_rate=0.15, silent=True, random_seed=RS),\n",
    "          LGBMClassifier(),\n",
    "          XGBClassifier(),\n",
    "          DummyClassifier(strategy='prior', random_state=RS)]\n",
    "\n",
    "bert_results = []\n",
    "\n",
    "for md in models:\n",
    "    print(f'Идут вычисления по модели {md.__class__.__name__}:', md.get_params(deep=False))\n",
    "    t1 = datetime.now() # Засекли время начала обучения\n",
    "    md.fit(bert_features_train, bert_target_train)\n",
    "    t2 = datetime.now() # Время окончания обучения и начала предсказания\n",
    "    print('-- модель обучена')\n",
    "    bert_pred = md.predict(bert_features_test)\n",
    "    t3 = datetime.now() # Время окончания предсказания\n",
    "    print('-- получены предсказания')\n",
    "    t4 = t2 - t1 # Время обучения\n",
    "    t5 = t3 - t2 # Время предсказания\n",
    "    dt1 = str(np.round(t4.total_seconds(), 2))+'s' # Время обучения в секундах\n",
    "    dt2 = str(np.round(t5.total_seconds(), 2))+'s' # Время предсказания в секундах\n",
    "    \n",
    "    md_acc = np.round(accuracy_score(bert_target_test, bert_pred), 4)\n",
    "    md_f1 = np.round(f1_score(bert_target_test, bert_pred), 4)\n",
    "    \n",
    "    print('-- accuracy_score:', md_acc)\n",
    "    print('-- f1_score:', md_f1)\n",
    "    bert_results.append({'Модель': md.__class__.__name__, \n",
    "                         'accuracy_score': md_acc,\n",
    "                         'f1_score': md_f1,\n",
    "                         'Время_обучения': dt1,\n",
    "                         'Время_предсказания': dt2,                    \n",
    "                         'Гиперпараметры': md.get_params(deep=False),\n",
    "                         'Модель_пригодна': md_f1>=CRIT_F1,\n",
    "                         'pred': bert_pred}) \n",
    "    print('')\n",
    "              \n",
    "bert_results = pd.DataFrame(bert_results)\n",
    "display(bert_results.drop('pred', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель (при работе с BERT): CatBoostClassifier\n"
     ]
    }
   ],
   "source": [
    "bert_best_mod = bert_results.sort_values(by = 'f1_score', ascending = False).reset_index(drop=True).head(1)\n",
    "print('Лучшая модель (при работе с BERT):', bert_best_mod.loc[0, 'Модель'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вариант без BERT (на данных NLTK+TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.68 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "nltk_text = df_comm['nltk_text'].values.astype('U')\n",
    "nltk_target = df_comm['toxic']\n",
    "\n",
    "nltk_text_train, nltk_text_test, nltk_target_train, nltk_target_test = train_test_split(nltk_text, nltk_target, test_size=TS, random_state=RS)\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords) \n",
    "nltk_features_train = count_tf_idf.fit_transform(nltk_text_train) \n",
    "nltk_features_test = count_tf_idf.transform(nltk_text_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Идут вычисления по модели LogisticRegression: {'C': 10, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 50, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 12345, 'solver': 'saga', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.839\n",
      "-- f1_score: 0.8367\n",
      "\n",
      "Идут вычисления по модели DecisionTreeClassifier: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 12345, 'splitter': 'best'}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.6466\n",
      "-- f1_score: 0.7115\n",
      "\n",
      "Идут вычисления по модели RandomForestClassifier: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False, 'random_state': 12345, 'verbose': 0, 'warm_start': False}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.6963\n",
      "-- f1_score: 0.7542\n",
      "\n",
      "Идут вычисления по модели CatBoostClassifier: {'iterations': 200, 'learning_rate': 0.15, 'depth': 16, 'random_seed': 12345, 'silent': True, 'bootstrap_type': 'MVS', 'grow_policy': 'Lossguide'}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.8233\n",
      "-- f1_score: 0.8085\n",
      "\n",
      "Идут вычисления по модели LGBMClassifier: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.7984\n",
      "-- f1_score: 0.7974\n",
      "\n",
      "Идут вычисления по модели XGBClassifier: {'objective': 'binary:logistic', 'use_label_encoder': True, 'base_score': None, 'booster': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'enable_categorical': False, 'gamma': None, 'gpu_id': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_delta_step': None, 'max_depth': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': None, 'num_parallel_tree': None, 'predictor': None, 'random_state': None, 'reg_alpha': None, 'reg_lambda': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
      "[09:52:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.8024\n",
      "-- f1_score: 0.7989\n",
      "\n",
      "Идут вычисления по модели DummyClassifier: {'constant': None, 'random_state': 12345, 'strategy': 'prior'}\n",
      "-- модель обучена\n",
      "-- получены предсказания\n",
      "-- accuracy_score: 0.4921\n",
      "-- f1_score: 0.6596\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>Время_обучения</th>\n",
       "      <th>Время_предсказания</th>\n",
       "      <th>Гиперпараметры</th>\n",
       "      <th>Модель_пригодна</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.05s</td>\n",
       "      <td>0.0s</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'dual': False,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.6466</td>\n",
       "      <td>0.7115</td>\n",
       "      <td>0.05s</td>\n",
       "      <td>0.0s</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.6963</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>0.41s</td>\n",
       "      <td>0.04s</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.8233</td>\n",
       "      <td>0.8085</td>\n",
       "      <td>49.71s</td>\n",
       "      <td>0.02s</td>\n",
       "      <td>{'iterations': 200, 'learning_rate': 0.15, 'de...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.7984</td>\n",
       "      <td>0.7974</td>\n",
       "      <td>141.76s</td>\n",
       "      <td>0.01s</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.8024</td>\n",
       "      <td>0.7989</td>\n",
       "      <td>52.54s</td>\n",
       "      <td>0.08s</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>0.4921</td>\n",
       "      <td>0.6596</td>\n",
       "      <td>0.0s</td>\n",
       "      <td>0.0s</td>\n",
       "      <td>{'constant': None, 'random_state': 12345, 'str...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Модель  accuracy_score  f1_score Время_обучения  \\\n",
       "0      LogisticRegression          0.8390    0.8367          0.05s   \n",
       "1  DecisionTreeClassifier          0.6466    0.7115          0.05s   \n",
       "2  RandomForestClassifier          0.6963    0.7542          0.41s   \n",
       "3      CatBoostClassifier          0.8233    0.8085         49.71s   \n",
       "4          LGBMClassifier          0.7984    0.7974        141.76s   \n",
       "5           XGBClassifier          0.8024    0.7989         52.54s   \n",
       "6         DummyClassifier          0.4921    0.6596           0.0s   \n",
       "\n",
       "  Время_предсказания                                     Гиперпараметры  \\\n",
       "0               0.0s  {'C': 10, 'class_weight': None, 'dual': False,...   \n",
       "1               0.0s  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...   \n",
       "2              0.04s  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...   \n",
       "3              0.02s  {'iterations': 200, 'learning_rate': 0.15, 'de...   \n",
       "4              0.01s  {'boosting_type': 'gbdt', 'class_weight': None...   \n",
       "5              0.08s  {'objective': 'binary:logistic', 'use_label_en...   \n",
       "6               0.0s  {'constant': None, 'random_state': 12345, 'str...   \n",
       "\n",
       "   Модель_пригодна  \n",
       "0             True  \n",
       "1            False  \n",
       "2             True  \n",
       "3             True  \n",
       "4             True  \n",
       "5             True  \n",
       "6            False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 1s, sys: 1.81 s, total: 4min 2s\n",
      "Wall time: 4min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "models = [LogisticRegression(multi_class='auto', solver='saga', penalty='l2', max_iter=50, class_weight=None, random_state=RS, C=10),          \n",
    "          DecisionTreeClassifier(class_weight=None, max_depth=8, random_state=RS),\n",
    "          RandomForestClassifier(class_weight=None, n_estimators=200, max_depth=10, min_samples_leaf=2, random_state=RS),\n",
    "          CatBoostClassifier(bootstrap_type='MVS', depth=16, grow_policy='Lossguide', iterations=200, learning_rate=0.15, silent=True, random_seed=RS),\n",
    "          LGBMClassifier(),\n",
    "          XGBClassifier(),\n",
    "          DummyClassifier(strategy='prior', random_state=RS)]\n",
    "\n",
    "tf_idf_results = []\n",
    "\n",
    "for md in models:\n",
    "    print(f'Идут вычисления по модели {md.__class__.__name__}:', md.get_params(deep=False))\n",
    "    t1 = datetime.now() # Засекли время начала обучения\n",
    "    md.fit(nltk_features_train, nltk_target_train)\n",
    "    t2 = datetime.now() # Время окончания обучения и начала предсказания\n",
    "    print('-- модель обучена')\n",
    "    nltk_pred = md.predict(nltk_features_test)\n",
    "    t3 = datetime.now() # Время окончания предсказания\n",
    "    print('-- получены предсказания')\n",
    "    t4 = t2 - t1 # Время обучения\n",
    "    t5 = t3 - t2 # Время предсказания\n",
    "    dt1 = str(np.round(t4.total_seconds(), 2))+'s' # Время обучения в секундах\n",
    "    dt2 = str(np.round(t5.total_seconds(), 2))+'s' # Время предсказания в секундах\n",
    "    \n",
    "    md_acc = np.round(accuracy_score(nltk_target_test, nltk_pred), 4)\n",
    "    md_f1 = np.round(f1_score(nltk_target_test, nltk_pred), 4)\n",
    "    \n",
    "    print('-- accuracy_score:', md_acc)\n",
    "    print('-- f1_score:', md_f1)\n",
    "    tf_idf_results.append({'Модель': md.__class__.__name__, \n",
    "                           'accuracy_score': md_acc,\n",
    "                           'f1_score': md_f1,\n",
    "                           'Время_обучения': dt1,\n",
    "                           'Время_предсказания': dt2,                    \n",
    "                           'Гиперпараметры': md.get_params(deep=False),\n",
    "                           'Модель_пригодна': md_f1>=CRIT_F1,\n",
    "                           'pred': nltk_pred}) \n",
    "    print('')\n",
    "              \n",
    "tf_idf_results = pd.DataFrame(tf_idf_results)\n",
    "display(tf_idf_results.drop('pred', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель (при работе с TF-IDF): LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "tf_idf_best_mod = tf_idf_results.sort_values(by = 'f1_score', ascending = False).reset_index(drop=True).head(1)\n",
    "print('Лучшая модель (при работе с TF-IDF):', tf_idf_best_mod.loc[0, 'Модель'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сравним результаты BERT и TF-IDF:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>f1_score_NLTK_TF_IDF</th>\n",
       "      <th>f1_score_BERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.8771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.7115</td>\n",
       "      <td>0.7990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>0.8518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.8085</td>\n",
       "      <td>0.8814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.7974</td>\n",
       "      <td>0.8579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.7989</td>\n",
       "      <td>0.8690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>0.6596</td>\n",
       "      <td>0.6922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Модель  f1_score_NLTK_TF_IDF  f1_score_BERT\n",
       "0      LogisticRegression                0.8367         0.8771\n",
       "1  DecisionTreeClassifier                0.7115         0.7990\n",
       "2  RandomForestClassifier                0.7542         0.8518\n",
       "3      CatBoostClassifier                0.8085         0.8814\n",
       "4          LGBMClassifier                0.7974         0.8579\n",
       "5           XGBClassifier                0.7989         0.8690\n",
       "6         DummyClassifier                0.6596         0.6922"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Сравним результаты BERT и TF-IDF:')\n",
    "delta = tf_idf_results.drop(['pred', 'Модель_пригодна', 'Гиперпараметры', 'Время_предсказания', 'Время_обучения', 'accuracy_score'], axis=1)\n",
    "delta = delta.rename(columns={\"f1_score\": \"f1_score_NLTK_TF_IDF\"})\n",
    "delta['f1_score_BERT'] = bert_results['f1_score']\n",
    "display(delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "1. Балансировка классов оказала решающее действие на качество модели - метрика f1 подросла примерно в 2 раза.\n",
    "2. <s>При заданных параметрах метод TF-IDF дает признаки для предсказания немного лучше чем в результате работы BERT. Возможно, дело в том, что для BERT используется ограничение длинны MXL=50.</s>После применения DistilBert метрика F1 стала чуть лучше (0.88 против 0.85) чем для метода TF-IDF, но скорость работы последнего выше.\n",
    "3. <s>Модель CatBoostClassifier на обоих типах признаков дала примерно одинаковые значения</s>Модель CatBoostClassifier дала лучшее значение на данных подготвленных BERT (F1=0.8814), а модель LogisticRegression на признаках подгтовленных spacy+TF-IDF дала самый лучший результат (F1=0.8556 на данных подготовленных spacy и 0.8367 на данных подгоовленных NLTK)."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 4462,
    "start_time": "2022-05-25T11:14:49.856Z"
   },
   {
    "duration": 2134,
    "start_time": "2022-05-25T11:14:55.676Z"
   },
   {
    "duration": 781,
    "start_time": "2022-05-25T11:15:41.520Z"
   },
   {
    "duration": 26,
    "start_time": "2022-05-25T11:17:43.774Z"
   },
   {
    "duration": 530,
    "start_time": "2022-05-25T11:20:43.299Z"
   },
   {
    "duration": 713,
    "start_time": "2022-05-25T11:22:09.035Z"
   },
   {
    "duration": 7425,
    "start_time": "2022-05-25T11:23:04.848Z"
   },
   {
    "duration": 1800,
    "start_time": "2022-05-25T11:23:36.153Z"
   },
   {
    "duration": 1306,
    "start_time": "2022-05-25T11:23:47.086Z"
   },
   {
    "duration": 1286,
    "start_time": "2022-05-25T11:23:55.876Z"
   },
   {
    "duration": 3186,
    "start_time": "2022-05-25T11:24:13.361Z"
   },
   {
    "duration": 126,
    "start_time": "2022-05-25T11:26:20.040Z"
   },
   {
    "duration": 57,
    "start_time": "2022-05-25T11:26:46.450Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-25T11:27:26.552Z"
   },
   {
    "duration": 2196,
    "start_time": "2022-05-25T11:27:27.932Z"
   },
   {
    "duration": 24,
    "start_time": "2022-05-25T11:27:31.601Z"
   },
   {
    "duration": 16320,
    "start_time": "2022-05-25T11:27:32.713Z"
   },
   {
    "duration": 51,
    "start_time": "2022-05-25T11:27:53.682Z"
   },
   {
    "duration": 53,
    "start_time": "2022-05-25T11:28:34.498Z"
   },
   {
    "duration": 11811,
    "start_time": "2022-05-26T07:39:58.756Z"
   },
   {
    "duration": 2249,
    "start_time": "2022-05-26T07:40:10.569Z"
   },
   {
    "duration": 27,
    "start_time": "2022-05-26T07:40:12.820Z"
   },
   {
    "duration": 18469,
    "start_time": "2022-05-26T07:40:15.682Z"
   },
   {
    "duration": 53580,
    "start_time": "2022-05-26T07:40:34.153Z"
   },
   {
    "duration": 279,
    "start_time": "2022-05-26T07:41:34.431Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-26T07:42:05.748Z"
   },
   {
    "duration": 739,
    "start_time": "2022-05-26T08:00:36.487Z"
   },
   {
    "duration": 4095,
    "start_time": "2022-05-26T08:00:56.034Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-26T08:02:16.169Z"
   },
   {
    "duration": 2910,
    "start_time": "2022-05-26T08:02:23.422Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-26T08:20:34.871Z"
   },
   {
    "duration": 75,
    "start_time": "2022-05-26T08:24:00.083Z"
   },
   {
    "duration": 161,
    "start_time": "2022-05-26T08:24:11.743Z"
   },
   {
    "duration": 211,
    "start_time": "2022-05-26T08:24:36.362Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-26T08:24:41.229Z"
   },
   {
    "duration": 1259,
    "start_time": "2022-05-26T08:24:42.261Z"
   },
   {
    "duration": 888,
    "start_time": "2022-05-26T08:26:13.447Z"
   },
   {
    "duration": 33,
    "start_time": "2022-05-26T08:26:15.808Z"
   },
   {
    "duration": 807,
    "start_time": "2022-05-26T08:26:21.373Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-26T08:28:08.410Z"
   },
   {
    "duration": 845,
    "start_time": "2022-05-26T08:28:13.559Z"
   },
   {
    "duration": 27,
    "start_time": "2022-05-26T08:28:16.760Z"
   },
   {
    "duration": 210175,
    "start_time": "2022-05-26T08:28:21.420Z"
   },
   {
    "duration": 124776,
    "start_time": "2022-05-26T08:32:30.088Z"
   },
   {
    "duration": 503,
    "start_time": "2022-05-26T08:51:39.457Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-26T08:54:57.511Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-26T08:55:01.297Z"
   },
   {
    "duration": 48,
    "start_time": "2022-05-26T08:55:03.168Z"
   },
   {
    "duration": 1724,
    "start_time": "2022-05-26T08:55:39.250Z"
   },
   {
    "duration": 23,
    "start_time": "2022-05-26T08:56:49.296Z"
   },
   {
    "duration": 463,
    "start_time": "2022-05-26T08:57:13.020Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-26T08:57:14.827Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-26T08:57:16.138Z"
   },
   {
    "duration": 127,
    "start_time": "2022-05-26T08:57:17.552Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-26T08:57:49.055Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-26T08:58:24.951Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-26T09:00:52.286Z"
   },
   {
    "duration": 3307,
    "start_time": "2022-05-26T09:01:21.018Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-26T09:02:23.517Z"
   },
   {
    "duration": 635,
    "start_time": "2022-05-26T09:05:34.155Z"
   },
   {
    "duration": 201,
    "start_time": "2022-05-26T09:07:04.401Z"
   },
   {
    "duration": 509,
    "start_time": "2022-05-26T09:07:54.337Z"
   },
   {
    "duration": 28,
    "start_time": "2022-05-26T09:12:17.947Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-26T09:15:26.418Z"
   },
   {
    "duration": 871,
    "start_time": "2022-05-26T09:23:36.820Z"
   },
   {
    "duration": 26,
    "start_time": "2022-05-26T09:23:40.676Z"
   },
   {
    "duration": 3745,
    "start_time": "2022-05-26T09:23:55.055Z"
   },
   {
    "duration": 907,
    "start_time": "2022-05-26T09:24:04.747Z"
   },
   {
    "duration": 7365,
    "start_time": "2022-05-26T09:24:05.939Z"
   },
   {
    "duration": 246,
    "start_time": "2022-05-26T10:18:32.121Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-26T10:19:01.390Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-26T10:27:30.417Z"
   },
   {
    "duration": 88,
    "start_time": "2022-05-26T10:27:43.918Z"
   },
   {
    "duration": 84,
    "start_time": "2022-05-26T10:28:50.200Z"
   },
   {
    "duration": 82,
    "start_time": "2022-05-26T10:35:05.556Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-26T10:35:09.805Z"
   },
   {
    "duration": 79,
    "start_time": "2022-05-26T10:35:11.878Z"
   },
   {
    "duration": 80,
    "start_time": "2022-05-26T10:36:46.636Z"
   },
   {
    "duration": 76,
    "start_time": "2022-05-26T10:37:57.838Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-26T10:38:30.408Z"
   },
   {
    "duration": 68,
    "start_time": "2022-05-26T10:38:34.136Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-26T10:47:11.406Z"
   },
   {
    "duration": 76,
    "start_time": "2022-05-26T10:47:12.108Z"
   },
   {
    "duration": 75,
    "start_time": "2022-05-26T10:47:29.585Z"
   },
   {
    "duration": 58,
    "start_time": "2022-05-26T10:47:53.114Z"
   },
   {
    "duration": 26,
    "start_time": "2022-05-26T10:48:30.389Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-26T10:48:58.223Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-26T10:49:05.403Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-26T10:50:25.748Z"
   },
   {
    "duration": 34,
    "start_time": "2022-05-26T10:52:27.606Z"
   },
   {
    "duration": 40,
    "start_time": "2022-05-26T10:52:28.599Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-26T10:52:31.284Z"
   },
   {
    "duration": 66,
    "start_time": "2022-05-26T10:52:47.600Z"
   },
   {
    "duration": 38,
    "start_time": "2022-05-26T10:53:48.638Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-26T10:53:50.855Z"
   },
   {
    "duration": 3360,
    "start_time": "2022-05-27T08:12:35.478Z"
   },
   {
    "duration": 2488,
    "start_time": "2022-05-27T08:12:38.840Z"
   },
   {
    "duration": 25,
    "start_time": "2022-05-27T08:12:42.777Z"
   },
   {
    "duration": 21802,
    "start_time": "2022-05-27T08:12:46.857Z"
   },
   {
    "duration": 119818,
    "start_time": "2022-05-27T08:13:12.347Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T08:15:16.677Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T08:15:22.428Z"
   },
   {
    "duration": 813,
    "start_time": "2022-05-27T08:15:23.724Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T08:15:27.871Z"
   },
   {
    "duration": 1633,
    "start_time": "2022-05-27T08:15:29.201Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T08:15:30.836Z"
   },
   {
    "duration": 5661,
    "start_time": "2022-05-27T08:15:34.149Z"
   },
   {
    "duration": 1056,
    "start_time": "2022-05-27T08:15:44.356Z"
   },
   {
    "duration": 11968,
    "start_time": "2022-05-27T08:15:45.413Z"
   },
   {
    "duration": 24,
    "start_time": "2022-05-27T08:15:59.871Z"
   },
   {
    "duration": 91,
    "start_time": "2022-05-27T08:16:02.147Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-27T08:16:04.673Z"
   },
   {
    "duration": 1406,
    "start_time": "2022-05-27T08:16:13.472Z"
   },
   {
    "duration": 2711,
    "start_time": "2022-05-27T08:16:16.648Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-27T08:17:24.371Z"
   },
   {
    "duration": 123,
    "start_time": "2022-05-27T08:19:38.960Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-27T08:19:42.454Z"
   },
   {
    "duration": 4108,
    "start_time": "2022-05-27T08:19:53.355Z"
   },
   {
    "duration": 5942,
    "start_time": "2022-05-27T08:19:59.624Z"
   },
   {
    "duration": 543,
    "start_time": "2022-05-27T08:20:38.942Z"
   },
   {
    "duration": 313,
    "start_time": "2022-05-27T08:21:01.796Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T08:23:11.240Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T08:24:03.477Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T08:24:07.010Z"
   },
   {
    "duration": 306,
    "start_time": "2022-05-27T08:25:18.343Z"
   },
   {
    "duration": 322,
    "start_time": "2022-05-27T08:25:20.715Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T08:25:21.956Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T08:28:51.621Z"
   },
   {
    "duration": 416,
    "start_time": "2022-05-27T08:29:17.487Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-27T08:30:26.856Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T08:30:27.688Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T08:31:29.796Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T08:31:55.571Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-27T08:33:16.746Z"
   },
   {
    "duration": 116,
    "start_time": "2022-05-27T08:45:29.248Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-27T08:45:30.499Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-27T08:46:01.613Z"
   },
   {
    "duration": 27,
    "start_time": "2022-05-27T08:46:52.052Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T08:47:28.454Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-27T08:49:19.361Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T08:49:32.358Z"
   },
   {
    "duration": 21,
    "start_time": "2022-05-27T08:50:35.320Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-27T08:50:59.507Z"
   },
   {
    "duration": 47,
    "start_time": "2022-05-27T08:52:56.828Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-27T08:53:07.726Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-27T08:53:20.729Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-27T08:56:11.473Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-27T08:57:06.684Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-27T08:58:30.942Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-27T08:58:42.275Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-27T08:59:14.671Z"
   },
   {
    "duration": 717,
    "start_time": "2022-05-27T09:00:53.031Z"
   },
   {
    "duration": 12015,
    "start_time": "2022-05-27T09:00:56.428Z"
   },
   {
    "duration": 71,
    "start_time": "2022-05-27T09:01:21.770Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-27T09:01:42.702Z"
   },
   {
    "duration": 50,
    "start_time": "2022-05-27T09:04:57.502Z"
   },
   {
    "duration": 63,
    "start_time": "2022-05-27T09:05:16.256Z"
   },
   {
    "duration": 77,
    "start_time": "2022-05-27T09:05:35.052Z"
   },
   {
    "duration": 54,
    "start_time": "2022-05-27T09:05:52.556Z"
   },
   {
    "duration": 1197,
    "start_time": "2022-05-27T09:06:16.174Z"
   },
   {
    "duration": 12672,
    "start_time": "2022-05-27T09:06:18.853Z"
   },
   {
    "duration": 74,
    "start_time": "2022-05-27T09:06:36.058Z"
   },
   {
    "duration": 62,
    "start_time": "2022-05-27T09:38:06.778Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-27T09:38:16.310Z"
   },
   {
    "duration": 70,
    "start_time": "2022-05-27T09:38:39.334Z"
   },
   {
    "duration": 56,
    "start_time": "2022-05-27T09:38:55.985Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T09:41:59.574Z"
   },
   {
    "duration": 862,
    "start_time": "2022-05-27T09:42:00.217Z"
   },
   {
    "duration": 44,
    "start_time": "2022-05-27T09:42:03.842Z"
   },
   {
    "duration": 84,
    "start_time": "2022-05-27T09:42:54.525Z"
   },
   {
    "duration": 82,
    "start_time": "2022-05-27T09:43:04.207Z"
   },
   {
    "duration": 81,
    "start_time": "2022-05-27T09:43:34.036Z"
   },
   {
    "duration": 81,
    "start_time": "2022-05-27T09:44:32.239Z"
   },
   {
    "duration": 79,
    "start_time": "2022-05-27T09:44:49.752Z"
   },
   {
    "duration": 492,
    "start_time": "2022-05-27T10:12:04.854Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T10:12:16.944Z"
   },
   {
    "duration": 801,
    "start_time": "2022-05-27T10:12:17.731Z"
   },
   {
    "duration": 80,
    "start_time": "2022-05-27T10:12:18.694Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T10:12:21.078Z"
   },
   {
    "duration": 24,
    "start_time": "2022-05-27T10:12:21.680Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T10:12:29.534Z"
   },
   {
    "duration": 227,
    "start_time": "2022-05-27T10:12:30.142Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T10:12:31.332Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-27T10:12:32.197Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T10:12:34.911Z"
   },
   {
    "duration": 5894,
    "start_time": "2022-05-27T10:12:36.613Z"
   },
   {
    "duration": 604,
    "start_time": "2022-05-27T10:12:46.015Z"
   },
   {
    "duration": 11882,
    "start_time": "2022-05-27T10:12:48.183Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T10:13:03.743Z"
   },
   {
    "duration": 69,
    "start_time": "2022-05-27T10:13:04.783Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-27T10:13:52.760Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-27T10:14:25.311Z"
   },
   {
    "duration": 46,
    "start_time": "2022-05-27T10:16:57.591Z"
   },
   {
    "duration": 68,
    "start_time": "2022-05-27T10:17:10.326Z"
   },
   {
    "duration": 78,
    "start_time": "2022-05-27T10:17:27.207Z"
   },
   {
    "duration": 44,
    "start_time": "2022-05-27T10:18:15.399Z"
   },
   {
    "duration": 46,
    "start_time": "2022-05-27T10:18:19.671Z"
   },
   {
    "duration": 47,
    "start_time": "2022-05-27T10:18:23.671Z"
   },
   {
    "duration": 91,
    "start_time": "2022-05-27T10:19:52.103Z"
   },
   {
    "duration": 74,
    "start_time": "2022-05-27T10:20:05.655Z"
   },
   {
    "duration": 63,
    "start_time": "2022-05-27T10:20:12.458Z"
   },
   {
    "duration": 78,
    "start_time": "2022-05-27T10:20:20.503Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T11:26:48.915Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T11:31:13.489Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T11:32:17.771Z"
   },
   {
    "duration": 58,
    "start_time": "2022-05-27T11:32:35.330Z"
   },
   {
    "duration": 60,
    "start_time": "2022-05-27T11:33:04.516Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T11:33:12.154Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-27T11:34:33.512Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T11:34:49.348Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T11:35:03.197Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T11:35:11.371Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T11:35:42.683Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-27T11:37:37.692Z"
   },
   {
    "duration": 41,
    "start_time": "2022-05-27T11:38:38.748Z"
   },
   {
    "duration": 62,
    "start_time": "2022-05-27T11:39:19.543Z"
   },
   {
    "duration": 99,
    "start_time": "2022-05-27T11:39:44.498Z"
   },
   {
    "duration": 494,
    "start_time": "2022-05-27T11:40:59.273Z"
   },
   {
    "duration": 143,
    "start_time": "2022-05-27T11:41:41.951Z"
   },
   {
    "duration": 135,
    "start_time": "2022-05-27T11:44:31.784Z"
   },
   {
    "duration": 130,
    "start_time": "2022-05-27T11:45:18.982Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T11:46:29.831Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-27T11:53:45.290Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T11:53:50.838Z"
   },
   {
    "duration": 198,
    "start_time": "2022-05-27T11:53:56.910Z"
   },
   {
    "duration": 182,
    "start_time": "2022-05-27T11:54:11.298Z"
   },
   {
    "duration": 1164,
    "start_time": "2022-05-27T11:55:05.503Z"
   },
   {
    "duration": 3301,
    "start_time": "2022-05-27T11:55:07.481Z"
   },
   {
    "duration": 1104,
    "start_time": "2022-05-27T11:55:58.471Z"
   },
   {
    "duration": 2993,
    "start_time": "2022-05-27T11:56:00.883Z"
   },
   {
    "duration": 58,
    "start_time": "2022-05-27T11:58:34.260Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-27T11:58:48.960Z"
   },
   {
    "duration": 30,
    "start_time": "2022-05-27T12:01:53.371Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T12:02:23.144Z"
   },
   {
    "duration": 39,
    "start_time": "2022-05-27T12:02:32.291Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T12:03:23.954Z"
   },
   {
    "duration": 32,
    "start_time": "2022-05-27T12:03:43.895Z"
   },
   {
    "duration": 36,
    "start_time": "2022-05-27T12:05:02.674Z"
   },
   {
    "duration": 34,
    "start_time": "2022-05-27T12:05:16.921Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T12:06:22.143Z"
   },
   {
    "duration": 34,
    "start_time": "2022-05-27T12:06:30.717Z"
   },
   {
    "duration": 36,
    "start_time": "2022-05-27T12:09:32.772Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T12:10:11.147Z"
   },
   {
    "duration": 50,
    "start_time": "2022-05-27T12:10:17.421Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T12:10:44.571Z"
   },
   {
    "duration": 54,
    "start_time": "2022-05-27T12:11:01.143Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T12:15:00.973Z"
   },
   {
    "duration": 23,
    "start_time": "2022-05-27T12:15:09.072Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-27T12:15:58.071Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-27T12:16:06.113Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T12:24:59.910Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T12:26:49.007Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T12:26:50.555Z"
   },
   {
    "duration": 925,
    "start_time": "2022-05-27T12:26:51.774Z"
   },
   {
    "duration": 79,
    "start_time": "2022-05-27T12:26:53.784Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T12:27:02.995Z"
   },
   {
    "duration": 33,
    "start_time": "2022-05-27T12:27:04.220Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-27T12:27:15.585Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T12:27:35.251Z"
   },
   {
    "duration": 51,
    "start_time": "2022-05-27T12:27:35.889Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-27T12:27:59.952Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-27T12:28:16.383Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-27T12:28:41.745Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-27T12:29:55.755Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T12:30:57.421Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T12:30:58.090Z"
   },
   {
    "duration": 825,
    "start_time": "2022-05-27T12:30:58.992Z"
   },
   {
    "duration": 88,
    "start_time": "2022-05-27T12:31:02.670Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T12:31:05.053Z"
   },
   {
    "duration": 54,
    "start_time": "2022-05-27T12:31:11.305Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-27T12:31:14.474Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-27T12:31:34.288Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T12:31:35.371Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T12:32:06.011Z"
   },
   {
    "duration": 257,
    "start_time": "2022-05-27T12:32:07.052Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T12:32:08.386Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-27T12:32:11.104Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T12:32:13.703Z"
   },
   {
    "duration": 19057,
    "start_time": "2022-05-27T12:32:18.151Z"
   },
   {
    "duration": 635,
    "start_time": "2022-05-27T12:32:38.912Z"
   },
   {
    "duration": 43336,
    "start_time": "2022-05-27T12:32:41.443Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T12:33:28.741Z"
   },
   {
    "duration": 164,
    "start_time": "2022-05-27T12:33:31.300Z"
   },
   {
    "duration": 106,
    "start_time": "2022-05-27T12:33:33.174Z"
   },
   {
    "duration": 55,
    "start_time": "2022-05-27T12:33:42.650Z"
   },
   {
    "duration": 65,
    "start_time": "2022-05-27T12:34:41.285Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T12:35:28.121Z"
   },
   {
    "duration": 134,
    "start_time": "2022-05-27T12:35:38.947Z"
   },
   {
    "duration": 126,
    "start_time": "2022-05-27T12:35:50.231Z"
   },
   {
    "duration": 139,
    "start_time": "2022-05-27T12:35:59.217Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-27T12:36:02.930Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T12:52:32.598Z"
   },
   {
    "duration": 29,
    "start_time": "2022-05-27T12:53:17.795Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T12:56:12.304Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T12:56:15.446Z"
   },
   {
    "duration": 890,
    "start_time": "2022-05-27T12:56:17.232Z"
   },
   {
    "duration": 78,
    "start_time": "2022-05-27T12:56:21.073Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T12:56:21.872Z"
   },
   {
    "duration": 62,
    "start_time": "2022-05-27T12:56:23.676Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-27T12:56:26.031Z"
   },
   {
    "duration": 22,
    "start_time": "2022-05-27T12:56:27.390Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T12:56:30.035Z"
   },
   {
    "duration": 6699,
    "start_time": "2022-05-27T12:56:31.184Z"
   },
   {
    "duration": 515193,
    "start_time": "2022-05-27T12:56:40.893Z"
   },
   {
    "duration": 34,
    "start_time": "2022-05-27T13:05:38.346Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-27T13:06:47.851Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-27T13:11:13.512Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T13:11:48.109Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T13:11:49.394Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T13:11:51.276Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T13:11:54.387Z"
   },
   {
    "duration": 19710,
    "start_time": "2022-05-27T13:11:55.886Z"
   },
   {
    "duration": 699,
    "start_time": "2022-05-27T13:12:21.304Z"
   },
   {
    "duration": 44500,
    "start_time": "2022-05-27T13:12:24.943Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T13:14:54.701Z"
   },
   {
    "duration": 158,
    "start_time": "2022-05-27T13:14:56.330Z"
   },
   {
    "duration": 130,
    "start_time": "2022-05-27T13:15:01.154Z"
   },
   {
    "duration": 114,
    "start_time": "2022-05-27T13:15:02.642Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T13:15:16.945Z"
   },
   {
    "duration": 139,
    "start_time": "2022-05-27T13:15:20.410Z"
   },
   {
    "duration": 147,
    "start_time": "2022-05-27T13:15:25.374Z"
   },
   {
    "duration": 123,
    "start_time": "2022-05-27T13:15:28.682Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-27T13:15:32.504Z"
   },
   {
    "duration": 28,
    "start_time": "2022-05-27T13:16:10.490Z"
   },
   {
    "duration": 1356,
    "start_time": "2022-05-27T13:16:16.014Z"
   },
   {
    "duration": 5320,
    "start_time": "2022-05-27T13:16:18.852Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T13:16:39.554Z"
   },
   {
    "duration": 1281,
    "start_time": "2022-05-27T13:16:41.025Z"
   },
   {
    "duration": 1392,
    "start_time": "2022-05-27T13:16:49.140Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T13:17:06.475Z"
   },
   {
    "duration": 5650,
    "start_time": "2022-05-27T13:22:07.316Z"
   },
   {
    "duration": 1440,
    "start_time": "2022-05-27T13:22:20.152Z"
   },
   {
    "duration": 1420,
    "start_time": "2022-05-27T13:22:51.025Z"
   },
   {
    "duration": 1854,
    "start_time": "2022-05-27T13:23:33.225Z"
   },
   {
    "duration": 4529,
    "start_time": "2022-05-27T13:23:36.146Z"
   },
   {
    "duration": 2061,
    "start_time": "2022-05-27T13:23:57.507Z"
   },
   {
    "duration": 6309,
    "start_time": "2022-05-27T13:24:00.751Z"
   },
   {
    "duration": 22,
    "start_time": "2022-05-27T13:24:45.480Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-27T13:25:30.815Z"
   },
   {
    "duration": 3130,
    "start_time": "2022-05-27T13:26:22.052Z"
   },
   {
    "duration": 3656,
    "start_time": "2022-05-27T13:26:54.293Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T13:27:05.340Z"
   },
   {
    "duration": 23,
    "start_time": "2022-05-27T13:27:58.771Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T13:28:03.679Z"
   },
   {
    "duration": 3283,
    "start_time": "2022-05-27T13:28:48.709Z"
   },
   {
    "duration": 3885,
    "start_time": "2022-05-27T13:28:57.954Z"
   },
   {
    "duration": 46,
    "start_time": "2022-05-27T13:29:15.362Z"
   },
   {
    "duration": 3011,
    "start_time": "2022-05-27T13:29:19.824Z"
   },
   {
    "duration": 38,
    "start_time": "2022-05-27T13:29:23.480Z"
   },
   {
    "duration": 18052,
    "start_time": "2022-05-27T13:38:15.105Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T13:40:46.628Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T13:40:56.471Z"
   },
   {
    "duration": 24,
    "start_time": "2022-05-27T13:41:32.186Z"
   },
   {
    "duration": 57143,
    "start_time": "2022-05-27T13:47:17.047Z"
   },
   {
    "duration": 134249,
    "start_time": "2022-05-27T13:48:31.011Z"
   },
   {
    "duration": 33,
    "start_time": "2022-05-27T13:50:55.983Z"
   },
   {
    "duration": 59,
    "start_time": "2022-05-27T13:56:20.953Z"
   },
   {
    "duration": 461915,
    "start_time": "2022-05-27T13:56:59.254Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T14:05:31.755Z"
   },
   {
    "duration": 254,
    "start_time": "2022-05-27T14:07:48.978Z"
   },
   {
    "duration": 70,
    "start_time": "2022-05-27T14:13:00.257Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-27T14:15:11.512Z"
   },
   {
    "duration": 3436,
    "start_time": "2022-05-27T14:15:17.251Z"
   },
   {
    "duration": 3396,
    "start_time": "2022-05-27T14:16:02.173Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T14:16:15.651Z"
   },
   {
    "duration": 135248,
    "start_time": "2022-05-27T14:16:21.361Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-27T14:19:13.510Z"
   },
   {
    "duration": 134470,
    "start_time": "2022-05-27T14:20:36.087Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T14:25:12.059Z"
   },
   {
    "duration": 177,
    "start_time": "2022-05-27T14:29:42.890Z"
   },
   {
    "duration": 124,
    "start_time": "2022-05-27T14:29:44.519Z"
   },
   {
    "duration": 111,
    "start_time": "2022-05-27T14:29:45.453Z"
   },
   {
    "duration": 51,
    "start_time": "2022-05-27T14:50:55.582Z"
   },
   {
    "duration": 4699,
    "start_time": "2022-05-27T14:51:13.727Z"
   },
   {
    "duration": 5291,
    "start_time": "2022-05-27T14:54:36.326Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T14:54:45.422Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-27T14:55:11.503Z"
   },
   {
    "duration": 6545,
    "start_time": "2022-05-27T14:55:30.080Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-27T14:55:38.221Z"
   },
   {
    "duration": 5517,
    "start_time": "2022-05-27T14:55:55.105Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-27T14:56:21.790Z"
   },
   {
    "duration": 168,
    "start_time": "2022-05-27T15:49:04.010Z"
   },
   {
    "duration": 4310,
    "start_time": "2022-05-27T15:49:13.988Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T15:49:18.300Z"
   },
   {
    "duration": 2517,
    "start_time": "2022-05-27T15:49:18.307Z"
   },
   {
    "duration": 100,
    "start_time": "2022-05-27T15:49:20.826Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T15:49:20.928Z"
   },
   {
    "duration": 78,
    "start_time": "2022-05-27T15:49:20.935Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-27T15:49:21.017Z"
   },
   {
    "duration": 22,
    "start_time": "2022-05-27T15:49:21.027Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T15:49:21.059Z"
   },
   {
    "duration": 7371,
    "start_time": "2022-05-27T15:49:21.068Z"
   },
   {
    "duration": 360241,
    "start_time": "2022-05-27T15:49:28.441Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-27T15:55:28.759Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-27T15:55:28.771Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-27T15:55:28.786Z"
   },
   {
    "duration": 1500,
    "start_time": "2022-05-27T15:55:28.797Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T15:55:30.298Z"
   },
   {
    "duration": 17942,
    "start_time": "2022-05-27T15:55:30.303Z"
   },
   {
    "duration": 572,
    "start_time": "2022-05-27T15:55:48.247Z"
   },
   {
    "duration": 38402,
    "start_time": "2022-05-27T15:55:48.821Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T15:56:27.225Z"
   },
   {
    "duration": 68,
    "start_time": "2022-05-27T15:56:27.231Z"
   },
   {
    "duration": 146,
    "start_time": "2022-05-27T15:56:27.301Z"
   },
   {
    "duration": 113,
    "start_time": "2022-05-27T15:56:27.448Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T15:56:27.562Z"
   },
   {
    "duration": 135,
    "start_time": "2022-05-27T15:56:27.568Z"
   },
   {
    "duration": 139,
    "start_time": "2022-05-27T15:56:27.705Z"
   },
   {
    "duration": 134,
    "start_time": "2022-05-27T15:56:27.846Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-27T15:56:27.985Z"
   },
   {
    "duration": 29,
    "start_time": "2022-05-27T15:56:27.994Z"
   },
   {
    "duration": 6507,
    "start_time": "2022-05-27T15:56:28.025Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.534Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.535Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.536Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.537Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.538Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.539Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.540Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.541Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.558Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.559Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.560Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.560Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.564Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.565Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.567Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.568Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.569Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.570Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.571Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.572Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.573Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.574Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.575Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T15:56:34.576Z"
   },
   {
    "duration": 3942,
    "start_time": "2022-05-27T15:58:09.684Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-27T16:00:32.767Z"
   },
   {
    "duration": 29,
    "start_time": "2022-05-27T16:38:38.172Z"
   },
   {
    "duration": 298,
    "start_time": "2022-05-27T16:38:47.921Z"
   },
   {
    "duration": 854,
    "start_time": "2022-05-27T16:38:54.731Z"
   },
   {
    "duration": 83,
    "start_time": "2022-05-27T16:54:01.968Z"
   },
   {
    "duration": 361,
    "start_time": "2022-05-27T16:54:08.171Z"
   },
   {
    "duration": 36136,
    "start_time": "2022-05-27T16:54:13.525Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T16:56:58.819Z"
   },
   {
    "duration": 25,
    "start_time": "2022-05-27T16:58:08.372Z"
   },
   {
    "duration": 3206,
    "start_time": "2022-05-27T16:59:42.509Z"
   },
   {
    "duration": 30,
    "start_time": "2022-05-27T17:00:41.755Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-27T17:00:59.280Z"
   },
   {
    "duration": 26,
    "start_time": "2022-05-27T17:06:16.428Z"
   },
   {
    "duration": 162,
    "start_time": "2022-05-27T17:07:30.194Z"
   },
   {
    "duration": 4651,
    "start_time": "2022-05-27T17:35:19.125Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T17:35:23.778Z"
   },
   {
    "duration": 902,
    "start_time": "2022-05-27T17:35:23.784Z"
   },
   {
    "duration": 110,
    "start_time": "2022-05-27T17:35:24.689Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T17:35:24.801Z"
   },
   {
    "duration": 85,
    "start_time": "2022-05-27T17:35:24.808Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T17:35:24.897Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.905Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.906Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.907Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.909Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.910Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.911Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.912Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.913Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.913Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.914Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.916Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.916Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.917Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.918Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.919Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.920Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.921Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.959Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.960Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.961Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.962Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.963Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.965Z"
   },
   {
    "duration": 1,
    "start_time": "2022-05-27T17:35:24.965Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.966Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.968Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.969Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.970Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.972Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.974Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.975Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:24.976Z"
   },
   {
    "duration": 4506,
    "start_time": "2022-05-27T17:35:48.519Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T17:35:53.028Z"
   },
   {
    "duration": 861,
    "start_time": "2022-05-27T17:35:53.035Z"
   },
   {
    "duration": 99,
    "start_time": "2022-05-27T17:35:53.899Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T17:35:53.999Z"
   },
   {
    "duration": 77,
    "start_time": "2022-05-27T17:35:54.005Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-27T17:35:54.085Z"
   },
   {
    "duration": 23,
    "start_time": "2022-05-27T17:35:54.094Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T17:35:54.119Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.125Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.127Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.128Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.129Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.130Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.132Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.133Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.134Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.159Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.161Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.162Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.163Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.164Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.165Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.167Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.168Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.170Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.171Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.172Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.174Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.175Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.176Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.177Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.178Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.179Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.180Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.181Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.182Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.184Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-27T17:35:54.185Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-27T17:36:15.976Z"
   },
   {
    "duration": 6241,
    "start_time": "2022-05-27T17:36:19.923Z"
   },
   {
    "duration": 418900,
    "start_time": "2022-05-27T17:37:00.666Z"
   },
   {
    "duration": 359,
    "start_time": "2022-05-27T17:44:10.390Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-27T17:45:02.789Z"
   },
   {
    "duration": 927,
    "start_time": "2022-05-27T17:45:30.325Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T17:45:40.797Z"
   },
   {
    "duration": 55,
    "start_time": "2022-05-27T17:45:43.149Z"
   },
   {
    "duration": 38,
    "start_time": "2022-05-27T17:46:02.381Z"
   },
   {
    "duration": 1520,
    "start_time": "2022-05-27T17:46:28.410Z"
   },
   {
    "duration": 13373,
    "start_time": "2022-05-27T17:46:49.565Z"
   },
   {
    "duration": 685,
    "start_time": "2022-05-27T17:47:05.996Z"
   },
   {
    "duration": 38797,
    "start_time": "2022-05-27T17:47:09.266Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-27T17:47:48.065Z"
   },
   {
    "duration": 94,
    "start_time": "2022-05-27T17:47:48.070Z"
   },
   {
    "duration": 171,
    "start_time": "2022-05-27T17:47:52.598Z"
   },
   {
    "duration": 73,
    "start_time": "2022-05-27T17:47:53.782Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T17:48:11.887Z"
   },
   {
    "duration": 115,
    "start_time": "2022-05-27T17:48:14.386Z"
   },
   {
    "duration": 148,
    "start_time": "2022-05-27T17:48:17.557Z"
   },
   {
    "duration": 164,
    "start_time": "2022-05-27T17:48:20.387Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T17:48:22.017Z"
   },
   {
    "duration": 52,
    "start_time": "2022-05-27T17:48:35.688Z"
   },
   {
    "duration": 4599,
    "start_time": "2022-05-27T17:48:52.694Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-27T17:49:04.477Z"
   },
   {
    "duration": 19205,
    "start_time": "2022-05-27T17:50:48.576Z"
   },
   {
    "duration": 86343,
    "start_time": "2022-05-27T17:51:14.128Z"
   },
   {
    "duration": 399312,
    "start_time": "2022-05-27T17:53:55.584Z"
   },
   {
    "duration": 242105,
    "start_time": "2022-05-27T18:00:39.777Z"
   },
   {
    "duration": 425,
    "start_time": "2022-05-27T18:04:41.884Z"
   },
   {
    "duration": 503,
    "start_time": "2022-05-27T18:05:13.081Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T18:05:49.529Z"
   },
   {
    "duration": 230,
    "start_time": "2022-05-27T18:06:06.679Z"
   },
   {
    "duration": 60,
    "start_time": "2022-05-27T18:06:13.170Z"
   },
   {
    "duration": 209,
    "start_time": "2022-05-27T18:07:33.926Z"
   },
   {
    "duration": 46582,
    "start_time": "2022-05-27T18:07:36.812Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T18:08:30.591Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T18:08:49.588Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-27T18:08:54.816Z"
   },
   {
    "duration": 4497,
    "start_time": "2022-05-27T18:23:15.808Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T18:23:20.307Z"
   },
   {
    "duration": 908,
    "start_time": "2022-05-27T18:23:20.315Z"
   },
   {
    "duration": 105,
    "start_time": "2022-05-27T18:23:21.226Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T18:23:21.332Z"
   },
   {
    "duration": 75,
    "start_time": "2022-05-27T18:23:21.338Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-27T18:23:21.417Z"
   },
   {
    "duration": 41,
    "start_time": "2022-05-27T18:23:21.426Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-27T18:23:21.469Z"
   },
   {
    "duration": 6919,
    "start_time": "2022-05-27T18:23:21.479Z"
   },
   {
    "duration": 419787,
    "start_time": "2022-05-27T18:23:28.400Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-27T18:30:28.259Z"
   },
   {
    "duration": 954,
    "start_time": "2022-05-27T18:30:28.277Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T18:30:29.234Z"
   },
   {
    "duration": 1649,
    "start_time": "2022-05-27T18:30:29.240Z"
   },
   {
    "duration": 14016,
    "start_time": "2022-05-27T18:30:30.891Z"
   },
   {
    "duration": 616,
    "start_time": "2022-05-27T18:30:44.908Z"
   },
   {
    "duration": 39985,
    "start_time": "2022-05-27T18:30:45.526Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T18:31:25.512Z"
   },
   {
    "duration": 105,
    "start_time": "2022-05-27T18:31:25.517Z"
   },
   {
    "duration": 140,
    "start_time": "2022-05-27T18:31:25.623Z"
   },
   {
    "duration": 69,
    "start_time": "2022-05-27T18:31:25.765Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T18:31:25.836Z"
   },
   {
    "duration": 124,
    "start_time": "2022-05-27T18:31:25.858Z"
   },
   {
    "duration": 136,
    "start_time": "2022-05-27T18:31:25.983Z"
   },
   {
    "duration": 115,
    "start_time": "2022-05-27T18:31:26.121Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T18:31:26.238Z"
   },
   {
    "duration": 39,
    "start_time": "2022-05-27T18:31:26.260Z"
   },
   {
    "duration": 4200,
    "start_time": "2022-05-27T18:31:26.301Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-27T18:31:30.503Z"
   },
   {
    "duration": 17474,
    "start_time": "2022-05-27T18:31:30.513Z"
   },
   {
    "duration": 49392,
    "start_time": "2022-05-27T18:31:47.989Z"
   },
   {
    "duration": 351680,
    "start_time": "2022-05-27T18:32:37.383Z"
   },
   {
    "duration": 287312,
    "start_time": "2022-05-27T18:38:29.064Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-27T18:43:16.378Z"
   },
   {
    "duration": 224,
    "start_time": "2022-05-27T18:43:16.384Z"
   },
   {
    "duration": 46360,
    "start_time": "2022-05-27T18:43:16.610Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-27T18:44:02.971Z"
   },
   {
    "duration": 36,
    "start_time": "2022-05-27T18:44:02.978Z"
   },
   {
    "duration": 5218,
    "start_time": "2022-05-28T18:56:59.050Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-28T18:57:04.270Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-28T18:57:30.784Z"
   },
   {
    "duration": 1403,
    "start_time": "2022-05-28T18:57:52.079Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-28T18:57:56.344Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-28T18:58:02.944Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-28T18:59:20.480Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-28T18:59:30.014Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-28T18:59:40.203Z"
   },
   {
    "duration": 7285,
    "start_time": "2022-05-29T16:14:40.156Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T16:14:47.443Z"
   },
   {
    "duration": 3335,
    "start_time": "2022-05-29T16:14:47.450Z"
   },
   {
    "duration": 92,
    "start_time": "2022-05-29T16:14:53.710Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T16:14:57.071Z"
   },
   {
    "duration": 57,
    "start_time": "2022-05-29T16:15:00.504Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-29T16:15:02.570Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-29T16:15:05.114Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-29T16:15:07.056Z"
   },
   {
    "duration": 17242,
    "start_time": "2022-05-29T16:15:08.536Z"
   },
   {
    "duration": 301878,
    "start_time": "2022-05-29T16:15:37.513Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-29T16:21:54.317Z"
   },
   {
    "duration": 831,
    "start_time": "2022-05-29T16:22:00.004Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T16:22:04.293Z"
   },
   {
    "duration": 1710,
    "start_time": "2022-05-29T16:22:06.279Z"
   },
   {
    "duration": 16353,
    "start_time": "2022-05-29T16:22:12.986Z"
   },
   {
    "duration": 929,
    "start_time": "2022-05-29T16:22:31.809Z"
   },
   {
    "duration": 44487,
    "start_time": "2022-05-29T16:22:34.941Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T16:23:22.821Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T16:23:25.521Z"
   },
   {
    "duration": 143,
    "start_time": "2022-05-29T16:23:28.547Z"
   },
   {
    "duration": 76,
    "start_time": "2022-05-29T16:23:34.780Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-29T16:23:49.082Z"
   },
   {
    "duration": 127,
    "start_time": "2022-05-29T16:23:49.989Z"
   },
   {
    "duration": 155,
    "start_time": "2022-05-29T16:23:55.380Z"
   },
   {
    "duration": 158,
    "start_time": "2022-05-29T16:23:57.877Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T16:24:06.646Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-29T16:24:13.022Z"
   },
   {
    "duration": 16219,
    "start_time": "2022-05-29T16:24:19.855Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-29T16:24:36.079Z"
   },
   {
    "duration": 21388,
    "start_time": "2022-05-29T16:25:09.256Z"
   },
   {
    "duration": 62165,
    "start_time": "2022-05-29T16:26:09.065Z"
   },
   {
    "duration": 497,
    "start_time": "2022-05-29T16:54:07.954Z"
   },
   {
    "duration": 30,
    "start_time": "2022-05-29T17:04:56.506Z"
   },
   {
    "duration": 197522,
    "start_time": "2022-05-29T17:05:08.502Z"
   },
   {
    "duration": 44890,
    "start_time": "2022-05-29T17:08:45.729Z"
   },
   {
    "duration": 34379,
    "start_time": "2022-05-29T17:10:20.613Z"
   },
   {
    "duration": 53657,
    "start_time": "2022-05-29T17:12:27.831Z"
   },
   {
    "duration": 577837,
    "start_time": "2022-05-29T17:16:46.808Z"
   },
   {
    "duration": 961,
    "start_time": "2022-05-29T17:26:56.483Z"
   },
   {
    "duration": 716724,
    "start_time": "2022-05-29T17:27:18.602Z"
   },
   {
    "duration": 50499,
    "start_time": "2022-05-29T17:40:12.844Z"
   },
   {
    "duration": 760,
    "start_time": "2022-05-29T17:42:19.622Z"
   },
   {
    "duration": 4703,
    "start_time": "2022-05-29T17:42:45.544Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T17:42:50.249Z"
   },
   {
    "duration": 832,
    "start_time": "2022-05-29T17:42:50.256Z"
   },
   {
    "duration": 84,
    "start_time": "2022-05-29T17:42:51.090Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T17:42:51.176Z"
   },
   {
    "duration": 77,
    "start_time": "2022-05-29T17:42:51.182Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-29T17:42:51.263Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-29T17:42:51.274Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-29T17:42:51.293Z"
   },
   {
    "duration": 8971,
    "start_time": "2022-05-29T17:42:51.301Z"
   },
   {
    "duration": 208496,
    "start_time": "2022-05-29T17:43:00.274Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-29T17:46:28.771Z"
   },
   {
    "duration": 787,
    "start_time": "2022-05-29T17:46:28.789Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T17:46:29.579Z"
   },
   {
    "duration": 1436,
    "start_time": "2022-05-29T17:46:29.585Z"
   },
   {
    "duration": 12631,
    "start_time": "2022-05-29T17:46:31.022Z"
   },
   {
    "duration": 616,
    "start_time": "2022-05-29T17:46:43.654Z"
   },
   {
    "duration": 36099,
    "start_time": "2022-05-29T17:46:44.272Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-29T17:47:20.373Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-29T17:47:20.377Z"
   },
   {
    "duration": 93,
    "start_time": "2022-05-29T17:47:20.387Z"
   },
   {
    "duration": 66,
    "start_time": "2022-05-29T17:47:20.482Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T17:47:20.560Z"
   },
   {
    "duration": 127,
    "start_time": "2022-05-29T17:47:20.566Z"
   },
   {
    "duration": 130,
    "start_time": "2022-05-29T17:47:20.695Z"
   },
   {
    "duration": 113,
    "start_time": "2022-05-29T17:47:20.827Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-29T17:47:20.942Z"
   },
   {
    "duration": 26,
    "start_time": "2022-05-29T17:47:20.948Z"
   },
   {
    "duration": 51810,
    "start_time": "2022-05-29T17:47:20.975Z"
   },
   {
    "duration": 775,
    "start_time": "2022-05-29T17:48:12.787Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-29T17:48:13.563Z"
   },
   {
    "duration": 17326,
    "start_time": "2022-05-29T17:48:13.575Z"
   },
   {
    "duration": 48888,
    "start_time": "2022-05-29T17:48:30.903Z"
   },
   {
    "duration": 87613,
    "start_time": "2022-05-29T17:49:19.793Z"
   },
   {
    "duration": 413480,
    "start_time": "2022-05-29T17:50:47.408Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T17:57:40.890Z"
   },
   {
    "duration": 263,
    "start_time": "2022-05-29T17:57:40.898Z"
   },
   {
    "duration": 139906,
    "start_time": "2022-05-29T17:57:41.163Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-29T18:00:01.071Z"
   },
   {
    "duration": 40,
    "start_time": "2022-05-29T18:00:01.078Z"
   },
   {
    "duration": 312076,
    "start_time": "2022-05-29T18:00:01.124Z"
   },
   {
    "duration": 190579,
    "start_time": "2022-05-29T18:06:00.541Z"
   },
   {
    "duration": 173653,
    "start_time": "2022-05-29T18:09:38.966Z"
   },
   {
    "duration": 363499,
    "start_time": "2022-05-29T18:13:16.985Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T18:19:20.486Z"
   },
   {
    "duration": 218,
    "start_time": "2022-05-29T18:19:43.094Z"
   },
   {
    "duration": 89924,
    "start_time": "2022-05-29T18:19:47.485Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-29T18:21:50.665Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-29T18:23:09.446Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-29T18:23:57.012Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-29T18:24:39.425Z"
   },
   {
    "duration": 13879,
    "start_time": "2022-05-30T09:26:58.406Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-30T09:27:12.287Z"
   },
   {
    "duration": 3233,
    "start_time": "2022-05-30T09:27:12.295Z"
   },
   {
    "duration": 94,
    "start_time": "2022-05-30T09:27:15.529Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-30T09:27:15.626Z"
   },
   {
    "duration": 85,
    "start_time": "2022-05-30T09:27:15.632Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-30T09:27:15.721Z"
   },
   {
    "duration": 28,
    "start_time": "2022-05-30T09:27:15.732Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-30T09:27:15.762Z"
   },
   {
    "duration": 17002,
    "start_time": "2022-05-30T09:27:15.784Z"
   },
   {
    "duration": 239998,
    "start_time": "2022-05-30T09:27:32.789Z"
   },
   {
    "duration": 22,
    "start_time": "2022-05-30T09:31:32.789Z"
   },
   {
    "duration": 897,
    "start_time": "2022-05-30T09:31:32.813Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-30T09:31:33.714Z"
   },
   {
    "duration": 1632,
    "start_time": "2022-05-30T09:31:33.721Z"
   },
   {
    "duration": 14686,
    "start_time": "2022-05-30T09:31:35.355Z"
   },
   {
    "duration": 658,
    "start_time": "2022-05-30T09:31:50.043Z"
   },
   {
    "duration": 44947,
    "start_time": "2022-05-30T09:31:50.703Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-30T09:32:35.652Z"
   },
   {
    "duration": 44,
    "start_time": "2022-05-30T09:32:35.657Z"
   },
   {
    "duration": 141,
    "start_time": "2022-05-30T09:32:35.703Z"
   },
   {
    "duration": 89,
    "start_time": "2022-05-30T09:32:35.846Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-30T09:32:35.937Z"
   },
   {
    "duration": 208,
    "start_time": "2022-05-30T09:32:35.944Z"
   },
   {
    "duration": 176,
    "start_time": "2022-05-30T09:32:36.154Z"
   },
   {
    "duration": 133,
    "start_time": "2022-05-30T09:32:36.331Z"
   },
   {
    "duration": 25,
    "start_time": "2022-05-30T09:32:36.466Z"
   },
   {
    "duration": 54,
    "start_time": "2022-05-30T09:32:36.499Z"
   },
   {
    "duration": 59764,
    "start_time": "2022-05-30T09:32:36.555Z"
   },
   {
    "duration": 925,
    "start_time": "2022-05-30T09:33:36.321Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-30T09:33:37.249Z"
   },
   {
    "duration": 21281,
    "start_time": "2022-05-30T09:33:37.263Z"
   },
   {
    "duration": 56956,
    "start_time": "2022-05-30T09:33:58.546Z"
   },
   {
    "duration": 193052,
    "start_time": "2022-05-30T09:34:55.503Z"
   },
   {
    "duration": 680286,
    "start_time": "2022-05-30T09:38:08.557Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-30T09:49:28.844Z"
   },
   {
    "duration": 264,
    "start_time": "2022-05-30T09:49:28.852Z"
   },
   {
    "duration": 244806,
    "start_time": "2022-05-30T09:49:29.120Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-30T09:53:33.928Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-30T09:53:33.990Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
