<h2>toxic_comments</h2>
<ul>
<li><b>Тема:</b> Определение токсичных комментариев
<li><b>Описание:</b> Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 
<li><b>Сферы деятельности:</b> Интернет-магазин  
<li><b>Направление:</b> Data Scientist, Machine Learning
<li><b>Навыки и инструменты:</b> python, pandas, sklearn, numpy, nltk, spacy, bert, datetime, catboost, xgboost, lightgbm, машинное обучение
<li><b>Задачи проекта:</b> Необходимо построить модель, которая будет классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок. 
<li><b>Итог проекта:</b> Были исследованы и подготовлены данные для обучения и тестирования модели. Была определена наилучшая модель для классификации комментариев, укладывающаяся в заданный критерий (F1=>0.75) .
<li><b>Статус проекта:</b> успешно завершен 
<li><b>Ссылка на файл проекта:</b> https://github.com/Jonzzi/yandex_practicum/blob/main/toxic_comments/Yumagulov_Toxic_Comments.ipynb
